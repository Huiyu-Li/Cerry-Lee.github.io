<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>法国记忆</title>
      <link href="/2021/09/14/Diary/2021-9-14-%E6%B3%95%E5%9B%BD%E8%AE%B0%E5%BF%86/"/>
      <url>/2021/09/14/Diary/2021-9-14-%E6%B3%95%E5%9B%BD%E8%AE%B0%E5%BF%86/</url>
      
        <content type="html"><![CDATA[<blockquote><p>谨以此文为天地，记录我在法国的点点滴滴，也感恩这些经历，像长居夜空的远辰，教会我如何更好地生活。</p><p>我感恩此生的幸运，也感谢自己的执着，能让我在不算晚的年纪里，换一个国度，经历一段全新的生活。不管未来阴晴圆缺，我只知道，我会成长很多，会懂得保护自己，温暖他人。</p></blockquote><h2 id="20191001"><a href="#20191001" class="headerlink" title="20191001"></a>20191001</h2><p>今天抱回了一把尤克里里，截止到目前，被子和尤克里里，两个可以曲线相遇的载体，都被我抱回了家。哈哈，今天又去团长家蹭了一顿饭。<br>回来的马路上，夜月星空，光影婆娑，掏出小琴，当即开了一场音乐party，也是够可以的。当然，蚊子也发现，有音乐助兴，咬人都格外带劲。<br>此后的许多记忆，照片和细节，适合装进另一个channel, 等到阳光满怀的某一天，送给故事的主角。<br>如果你们发现我零度的外表下依然有颗温热的心，那是因为有人予我温暖呵护，有人替我遮风挡雨。如果你发现我时常予人玫瑰，那只不过是我借花献佛，在你承接温暖的同时，不让忘记对照顾我的人说一声感谢。</p><h2 id="20190930"><a href="#20190930" class="headerlink" title="20190930"></a>20190930</h2><p>今天，送走了Jaume（我的第一位同办公室的同事），而我加入了一个新的大家庭。离别难免会有些伤感，因为Jaume实在太好了。哈哈，我的手机里还留了一张这位暖男的帅照。<br>回想一下从初见到熟悉，这一个月发生了好多变化。我刚来的时候，右手边的工位是空的，但我知道是有人存在的。突然有一天，工位的主人出现了，除了say hello, 并没有太多交流。因为初到陌生的世界，我似乎还不太适应。后来某一天，我对Jaume说，My boss is so busy。。。Jaume教会了我看老板的calendar。再后来，师姐说，Jaume人很好，我对师姐的信任，以及师姐对Jaume的认可，让我对Jaume的信任瞬间攀升。Jaume也的确帮过我很多，我在Jaume身上看到的那份耐心，让我学到很多。Santi是Jaume的好哥们，经常过来找Jaume喝咖啡。刚开始，我总是say no， 感谢Santi不厌其烦地邀请，让我很快融入了这个世界。虽然Santi的幽默我还是只能搞懂一半，但stone的故事真的把我给笑懵了。一转眼之间，我们三个在露台上喝咖啡的场景成了暖阳下一去不复返的光影。还记得在师兄的答辩聚会上，Jaume现场给大家来了个高阶汉语。全场惊呆，嗯，原来你是这样的Jaume。</p><p>晚上去打球了，脱胎换骨，唯有运动。<br>我好久没有这样剧烈运动过了，也好久没有这样玩的这样开心了。<br>虽然只有一场球的缘分，和法国小姐姐的遇见都充满了美好。</p><h2 id="20190929"><a href="#20190929" class="headerlink" title="20190929"></a>20190929</h2><p>昨天师兄的毕业晚会，今天师姐的华丽亮相。<br>师兄说：“看你师姐这法语，就和法国人一样”。我这文盲，着实羡慕。<br>实验室有师兄师姐一唱一和，每天无限欢乐。</p><h2 id="20190925"><a href="#20190925" class="headerlink" title="20190925"></a>20190925</h2><p>生命中有太多可遇不可求的遇见，就像蛛网晨露，仅在清晨的那一刻，阳光正好，白露未晞，沉寂了一夜的蛛网，裹满了闪闪发光的璎珞。<br>我在等待所有不期而遇，也在和所有美好双向奔赴。<br>今天是第一个没有宅在家里的周末，Not a Gloomy Sunday, It’s a Wonderful Saturday.<br>早上，爱乐乐团团长开车载我去尼斯，从Nick Factory Store到CAP3000，沿途经过蔚蓝色海岸。那一瞬间，我想有辆车，每周带好友去看海。<br>逛街最开心的两件事，是帮团长找到了心仪的外套，而我抱走了仅有的一双粉色鞋子。看，买东西，从来都要靠缘分。<br>听团长将乐团的故事，我满是惊讶，一个人可以和自己的爱好一起，把平凡的日子过成诗，大概就是这个样子。往昔用心走过的所有时光，遇见的所有人，这一生，都会是难以忘怀的。<br>回到家，看到团长做饭，是我货真价实的惊呆时刻。<br>葱姜花椒熟油，漏斗过滤，我此刻还能记得那份香气。</p><p>师姐说下午炖好羊排等我们回来，但我们没有安排好时间，错过了师姐的羊排。师姐送上来了两个蒜香鸡翅和尤克里里的调音器。师姐和团长，每一句话都是满满的段子。<br>感谢师姐替我想到了所有的细节，能在新的开始里，遇见师姐，是我此前无法奢求的幸运。<br>团长说，照顾不好师姐的学妹，都过不了师姐这一关。师姐对我这么好，连团长都嫉妒了。</p><p>我想说，我好久没有遇到这样舒服的聊天了。</p><h2 id="20190921"><a href="#20190921" class="headerlink" title="20190921"></a>20190921</h2><p>我本以为今天会过的很惨。恰逢团圆节，而我独自一个人在异乡，你说凄凉不凄凉？<br>果不其然，早上第一件事，是面条煮了一半，遭遇了停电。我很聪明地打开了门口的电箱，却发现开关全是开着的，懵了。<br>早饭没吃，上学去了。这一个中秋，注定难以忘怀。<br>下午，看到师姐发的邮件，很是感动。我没想过今天可以吃到月饼，更何况，是如此好吃的月饼。<br>阳光午后，初秋佳节，美味相约。<br>我知道也许常被细节感动的我总是太过认真，也许我的感恩一文不值，但我贪恋把美好留在心中的温暖，我总相信是这些细小的美好，装点了宜居世界，温暖了冰封的心灵。</p><p>也是下午，开小差点开了“爱乐乐团”团长的朋友圈，很独特，很执著，很是震撼。在这个摇滚年代里，已经很难遇见执著而又遵从自己内心的人了。能用心喜欢一件事，有一片心灵的净土，是一件很幸福的事情。但我更相信，是一个把人生活成自我的人，才更有能量。当然，我对人家的了解并不深刻，以上也只是我的感受。</p><blockquote><p>我也曾固执地写过这样的话：我感恩遇到的每一个人，经历的每一件事，受到的每一点触动。<br>也许事情的本来面目并非我所感受到的模样，但它在我心底留下的印记，弥足珍贵。<br>我不想细究事情本来的样子，也不想理解背后的错综复杂，它曾到访过我的生命，并留下些许动动，给我带来改变的缘由，让我拥有许多新鲜感受，抑或是重新起步的勇气，已经足够。</p></blockquote><p>我不怕犯错，也不怕被欺骗，我记不住不愉快，只能记得住温暖，哪怕现实打碎了我的水晶球，我还会再住进新的童话，你说我执迷不悟也好，说我年少无知也罢，我喜欢温暖与阳光，贪恋美好与幸福，我不在乎对与错，只在乎明天过的好不好。</p><p>我想说，不要轻易放弃一个留下美好的机会，你的一点温暖，也许足以照亮整个冬天。如果你也喜欢被爱，被温暖，要相信，很多人都喜欢，留一份美好，大家可以相互取暖。</p><h2 id="20190915"><a href="#20190915" class="headerlink" title="20190915"></a>20190915</h2><p>听到法语版的《追忆似水年华》，从前奏，到正文，我真的沉醉了。<br>只可惜，目前的我还一句也听不懂，只能当作催眠曲。<br>不过，为了一本书，学会一门新的语言，这种冲动的带来的意外，我完全可以做到。</p><p>20190919，今天第一次下山，山下好热闹。好想在某个夏夜里，去海边吹吹晚风，或在某个夕阳下，去街角散步。<br>有人说，未来找工作，必须要学好法语，我突然感觉自己做不到，面对未来，有些焦虑，也有些畏惧。<br>但转念一想，我可以为了看《似水年华》，而把法语学得很棒。没有那么多功利心，内心总会充满很多勇气和自信。所以呀，从小到大沉迷小说里的虚幻世界，也许就是太渴望现实中追寻不到的温暖阳光了。戒不掉的习惯，是疗伤的养心殿。</p><h2 id="20210914"><a href="#20210914" class="headerlink" title="20210914"></a>20210914</h2><p>想开辟这份记录的缘由，是20210914这一天，碰巧赶上毕业师兄的答辩。老板在师兄的presentation结束之后，几乎一页一页地和师兄校对PPT. 从来只在乎细节地我，对此格外感触深刻。我喜欢老板这份认真的态度！！反观自己也一样，不管是做哪一件事，既然选择了，就认真地走下去吧，要不然，浪费的可是自己地时光呢。</p><h2 id="20210910"><a href="#20210910" class="headerlink" title="20210910"></a>20210910</h2><p>第一次参加 Jounal Club, 会议结束末尾，NA带头鼓掌，一如既往地呆萌，身处大boss的段位，绝对是暖男的剧本。<br>我第一被他萌到是面试的时候，被问到法签大概多久可以办好，一无所知的我随口说了句：six month. NA立马摸了摸自己的小心脏。<br>再次被萌到是走廊里遇见这位大忙人，很不乐意地带上口罩，出门去接水。</p><h2 id="20210909"><a href="#20210909" class="headerlink" title="20210909"></a>20210909</h2><p>20210909，上午是Newcomers Seminar。I‘m completely new! No frends, no aquiantance, so when I show myself at the seminar, lonely makes my feel uncomfortable. but it just ok, let’s try to talk with someone.<br>我转头看了一下右边的男孩，他似乎和我一样形单影只，无所适从。他是我认识的第一个newcomer, Teo. 事实证明，他是一位非常可靠的队友， I feel so glad to meet him.<br>Teo会说法语，英语和一点spanish, 喜欢做饭，音乐和政治。我们都想当老师，都喜欢badminton。<br>最刺激的部分是team quiz，我们的名次除了稳居第一，也会上下浮动。如果你最近参加过team activity，你一定记得作为一个team荣誉与共的幸福和激动。最wonderful的部分，是我们最终赢得了冠军，It incredible and unbelivable, right? We need to foot on the stage! Teo从手机上调出了一首胜利的歌曲，瞬间嗨翻全场。<br>每个winners的礼物抱在怀中，今天我们四个萍水相逢的小伙伴，是全场最亮的仔！</p><p>下午，和HR LV见面。很显然，她清楚地记得我们地约定，当我在打印室遇见她地时候，她已经知道我在找她，这种被确认的感觉让人很舒服。<br>初次见面，她问我时候记得她。当然印象深刻，因为她在我的赴法行程中帮过我很多，让我很是感激。<br>不到一个小时的聊天，她的条理，细致和耐心让我印象深刻。逐条地过我合同，备忘录，耐心地解答我的疑问，反复核对。这也许就是法式工作的温暖之处吧，慢工出细活，不急躁，免除错。像我这样的急性子，这绝对是锻炼心智的好地方。</p><h2 id="20210907"><a href="#20210907" class="headerlink" title="20210907"></a>20210907</h2><p>周一没有逮到老板，周二逮了一上午，近乎崩溃。我发现老板的电话，可以打到你永远等不到结束。Crazy!<br>还好老板在会议结束后找了我，我们利用10分钟的空隙，把我所有的疑问过了一遍。这是我对老板好感攀升的转折点，一个人在学术思维上的清晰和独特，最令人震撼。</p><h2 id="20210903"><a href="#20210903" class="headerlink" title="20210903"></a>20210903</h2><p>第一次见到 Jauma, 和我同office的小伙伴，Spanish，热心，开朗，细致。教会我许多最基本的生活知识，充卡，看老板的日程，租房，关窗。。。<br>很幸运能认识一位法国小能手。<br>Jauma形影不离的小伙伴Sandiago，是个开朗幽默的大男孩，是师兄卸任以后最后Chairman特质的人，喜欢串门，喜欢打招呼，喜欢微笑。从实验室门口骑自行车到校门，碰到几位熟人，就可以停下几次，或者索性唠嗑结束再启程。</p><h2 id="20210902"><a href="#20210902" class="headerlink" title="20210902"></a>20210902</h2><p>第一次见到师兄师姐，幸运的是三届同盟了。<br>师兄是Chairman, social达人，乐于助人，活跃气氛。以行云流水的速度帮我约医生，真的非常感谢。<br>师姐陪我跑步，送我回家，陪我逛超市，教会我许多省钱技能。<br>能在遥远的异乡遇见你们，难得而又幸运。</p><h2 id="20210830"><a href="#20210830" class="headerlink" title="20210830"></a>20210830</h2><p>第一次见到老板真人，令我印象深刻地当然是被夸的那句，你英语很好。哈哈，just ok. 不过被夸当然会心情很好。<br>老板 just show me around, 很明显，他很少逛校园，看到新的咖啡亭，像发现了新大陆。<br>20210902，第一天上班，再次见到老板，很耐心地帮我组装电脑。<br>“You don’t want to jont me for lunch?” 这样的邀请我哪好意思拒绝，自然是follow了。<br>先是去accept office拿了工卡。但我身上没带钱，老板又陪我回实验室去了钱包。但意外的是，我的卡充不了钱。更意外的是，餐厅不收现金。所以我的第一顿饭，折腾来，折腾去，还是老板请客。老板很official地说了一句，You need to pay me back. Oh, my god, 我惊呆了。<br>不过到现在，我也没找到机会Pay back，哈哈哈，先欠着吧，某个良辰吉日再说。</p><p>第一个显示器没反应，第二个显示器用了一周就坏了，第三个显示器还没用足5分钟，就冒烟了。。。第四个显示器，是个小方屏。but it’s just Ok, I don’t care. Maybe i will have a new one in other days.<br>老板依旧亲历亲为，很有耐心，让我学到很多。能想到把所有钥匙拿出来，试一遍，这种耐心也不是一般人会有的。</p>]]></content>
      
      
      <categories>
          
          <category> Diary </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Life </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>小米10S Google Play 安装手记</title>
      <link href="/2021/05/06/Knowledge/2021-5-6-GooglePlay%E5%AE%89%E8%A3%85/"/>
      <url>/2021/05/06/Knowledge/2021-5-6-GooglePlay%E5%AE%89%E8%A3%85/</url>
      
        <content type="html"><![CDATA[<blockquote><p>本文主要为了帮助出国旅行或读书的小伙伴。<br>本文虽然很短，但我却被一张Google Map虐了3h。。。我太难了。。。</p></blockquote><h2 id="出国流量问题"><a href="#出国流量问题" class="headerlink" title="出国流量问题"></a>出国流量问题</h2><p>出国的旅途中，建议使用<strong>小米全球上网</strong>。<br>到达目的地后，买当地的电话卡。</p><h2 id="Google-Play"><a href="#Google-Play" class="headerlink" title="Google Play"></a>Google Play</h2><p>虽然网上有很多教程，但基本原理就是安装 <strong>Google 服务框架、Google Play Service、Google Play 商店</strong>三件套。<br>小伙伴们遇到最多的问题大概是，小米应用商店可以直接下载Google Play，但是打开之后却是<strong>无法连接服务器</strong>。<br>明明我的手机&gt;设置&gt;（搜索）<strong>谷歌基础服务</strong>已经打开了呀？<br>明明我的<strong>网络</strong>没有问题呀？<br>可怎么就是<strong>无法连接服务器</strong>呢！！！</p><h4 id="Step1-手机也需要VPN支持"><a href="#Step1-手机也需要VPN支持" class="headerlink" title="Step1: 手机也需要VPN支持"></a>Step1: 手机也需要VPN支持</h4><p>推荐使用蓝灯安卓版，有免费流量。</p><h4 id="Step2-Google服务框架-Google-Play-Service-Google-Play-Store"><a href="#Step2-Google服务框架-Google-Play-Service-Google-Play-Store" class="headerlink" title="Step2:  Google服务框架+ Google Play Service+ Google Play Store"></a>Step2:  Google服务框架+ Google Play Service+ Google Play Store</h4><p>强烈安利这个<a href="https://github.com/hideuvpn/android-google-play-store" target="_blank" rel="noopener">网址</a></p><h4 id="Step3-手机重启，登录Google-Play"><a href="#Step3-手机重启，登录Google-Play" class="headerlink" title="Step3: 手机重启，登录Google Play"></a>Step3: 手机重启，登录Google Play</h4><p>现在，就可以从Google Play下载应用了，比如，Google Map。</p>]]></content>
      
      
      <categories>
          
          <category> Knowledge </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Google Play </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Unconditional Love</title>
      <link href="/2021/04/26/Diary/2021-4-26-UnconditionalLove/"/>
      <url>/2021/04/26/Diary/2021-4-26-UnconditionalLove/</url>
      
        <content type="html"><![CDATA[<div id="hbe-security">  <div class="hbe-input-container">  <input type="password" class="hbe-form-control" id="pass" placeholder="The birthday of Cerry." />    <label for="pass">The birthday of Cerry.</label>    <div class="bottom-line"></div>  </div></div><div id="decryptionError" style="display: none;">Incorrect Password!</div><div id="noContentError" style="display: none;">No content to display!</div><div id="encrypt-blog" style="display:none">U2FsdGVkX1886vrqOFAsbOx9L4QoZp780Rhntqrjse5HLZGuRvtgR7A4M06mwX3Ne3noyY3bke2GRYyqYef81i0ztRIXfnFCPCEko4fRIM7E4boTiezcy6etsiuXW/PsnNL1MWl/j1Nv5jjl/91Vc3GjU9b6mMfF8qjxzdbrCSDy7Ox6YEA/6Uh0i3Xi2rnbu2PSrExTqFom/y0bhgx5rzTlAX39ximHE5OvKmqHFGQBFAFVukHWTp8x1sTt1K5HSj82nf47qlI2+ij8yOUe0T6RwOSkQKyFQskXj0pMcilQiJkU4jhJoSv1S8CQ3KXWtAXomLtL6A+NtmBg2mYFfaebJbg22m8NkNHJxVeT6OFdKXnzdVcesCzbyro+VwVAMI9KY3Jz07tCv/XbfF4WmlJqJQ989+TkztNFUgslwOBJsNK5cF3SbczYBclz0WZlP/6e+eLkMrvewIJ18oBTVo1u/iYCHSX4RLjrpF/BUAozmWutt4f3VFPD2ro9ujKGFdRmpEKJKrz4pllRwEEymtkPrAiJJhtrITXAN0ktFAcJqF6hNVfLh64rr4vHgsauGvdru8Rqf33/DY9Tm0/T+PZkWTtRJpGcf6Xoy+y/OJPFe1gE4YRtCbTkgXui+bxsp8KhfbOFY0UZ/mMLTGz+vRJkZimwSoR6KbTmCHNLtnmHJInOpbVU/CZsIMYihng7+LVYOzay3KemjACe2p7Os4bzPlEcTFpNkDhZwaCXWWthRDee0pAd6B77+E40ykTyyEO5SXMoyZhXeoON2f4jcJeSds8L1dRsqq6FyEivjQvcY5XobCtHTME18r/IByJdAt9bby6q0KymzVmu8bvAS2aDpmcLJDeVERmEBNmyjNwlK7h38hRb9RI4YCGFyTL91YhNdt7qY86Tijh8GNBqzyXf6/2QJi88tYcnk8paMrOeh4xN494gcYPjF4J8yrRLxaIDET2jiOWG2OmFFI3W+OE1Ey0j7/Zebd8oi2Y6PTB7W9eW+yZMbYIu+Z70GWppDQ9Yb+CnmfGRNuY1AcXRpPMLANR5mZIH3g/IcrZp+jgoHcggHR4D3c56N+2lYUbAP4GzHdmdfHE9RSRD8lCLnLu04ZqJ66jrOVe0GEX+hW8UtwC3N8zgILkr0Sj+6jqKvNzTIfDt0Cc48ugX36/+9WEipgtdsRUMho3UlVxwPwb1Lh9kdWbxh0m6LDnNdVBU6lZAdlYs1M9BGDINruEXVnR1pP54gIO1ftvYe91woeMSp2kYnDoYxSGu4bqxS3BwDisqhgyjTqPbvew3JFMRbA1U5TYVzykp/S5C/DEldnbMCaASSJlZQSQxYd1J4jEUiWlTCoNqh79GwkH0WDlsZQ/s4vCRKpjKgyPMERUikbeyPFV0KheO6Eqrp4Un4+eSDU84ZwN9Xn1U8ZEuKopjrBxCMnlXGtABcEtZjHTAWGtDk4oV6TS1CL92B4M/RBLUx0d+xozbkZKUI/J+pDqkhytrQ53jU6yZ92lKZsi2vv86jYBJowH9lkU2txu16yus3oe0zMH5Y2j98RfyGIIiNHmeYUIAZ/syMDcbs9kzR+TKN67giar4l89Rh9RvKblRkNG3gAplpGbRRpQ+oR9jshIO1gSmrhb6ml5CUK5OxW2ScD8DetqaJbjr3Ju3ULMC/VyAM4mscC0ZmZyxY++Aa5sDGpj9JajTu/9hjPVIQ8UVZJHj0zbgGrTh+YxJo13qN9L07iwjUucZHcpLwanqGNSTdz1dPuEjq7SZe+j+6xSMggTCEeKyiXXILph0x80ua7Phq3DX9KywztuBPq/8OlWqwOdDvedjnRlbBVuph7cN8MgsAhiQ7+VnMXtkvpgSGwyoRAjH1jHsHc+W6TB87c7oY3dex+vrzNEFxxMOfsr3isCoqADQwgNwqAIGLhb5Abk+GSh39sXVtSipo4n0D46FxaRYy6oc4O+BO8lpOxMD500Co3oKuNy3guYbCw9dtpcKckrCMDIAIDjtaQu3Y2iW5guBuM+mUW8urKaVlMy/p82DccpPtsfSpXrJFNvqjYZfQyOyAzjjMIlm5cibyFVhM8iwTaRnAoO3HgcZS/8VRfLWc9dbkQjZKw5LY8lIpM/awQpvuRGQcFU7P4yjljAk+anTMaBjuxpMTPDmj2zaTaDMLoT7OdzaBAKp4CWcaZOSxUpFzIT0/gTjGLFEmKxVs//94UEVDcC9nRNTvHEJRwf+nQV9xTi2OE3+H+aGinxn2qRaLJOlnl3l86ynavw86ThOnkxGHLyI2Gc1bS4VzdlZOGA6e7N+dZI9tnSDMN9JRObsYFzEX3XnjJVxiKUyLiJgASFY+weIL8yoownu/m5sxG91U3Lx4H5HdL35JffOf+HOgw39tsgI/3kwhhaOb5BYRRMq+m2baBn66m8yEMlCsZxBYRN2WI0ZkTrO0/MNtIMmqMhom4uBgiXV0vVTRxcGkgrQEWX9TgCjwmQQpLjBMzeZpop988L6MdouhHEA3/T8O8qmsW6KMhdbcO1TxKPmRcGN5p8NiFl1q9xZpparMeohoN3QlSQ6B0xbUuBGpjZMMVWqeWoQlG8zL5cGKA2HpcuTRxZ2hm53ykD3RxIERbtA/uS3P0hcE9864uNeeCC0yqBAjyXj0W5U1KDwnwwaO7Ox8NNHMfB7aMGJyu1rQeXaoHmrD/54QssVod1+sFpsjomvBhst/25be2mdVuOV+5ufH7rzPx0qo8ljlUWLfGkvvDN/3HWU5RJhUquaGn5SZbXPviJBvWUn4/GLuzCbtlBM0tRxftAVpwMBliK5CO2LmzlPrBSyA7UrENegYUP/4HmMDP9iQDnnylm0tVMnGaJ6CQ30jQoKL21z5+lSbR4coKElOIiyffLBvEwrmCnDB4i30RCJ27KlomrTJ4UaJFL9S1LLJdhp8NT0VJ5/ZA/4cP6iTI/oV+prgnGCeyCvYwYDaXdM+Wawt+Qijocht5GdT6ytCzZU5ZpT6hFRD/J2+mNoIVFG6pMbsEJxa1/mHk2GEsBHg55LKMZzUIVs75w3op2kOyGJI1gP1ahYthSt9VIG1uV2/XmmpuQEnaI/Ia/5gAVdhNv7JlaUj5f7T7uZkaOSn47zpFz0pbtqKQ6BID2HXhSeI5heKtM+/zcwT/dQ+Xzls9jZ4XvFBbKiWk4QL/W6iX+MW/6MfqIeTIeyAdSYOUq2LUGbLOL/t23TcV+OyOJ8JjcJ7IOfmojwtMSVbofgDP0Cu08z6x2406GY896BTW1TGS8KfDQX43Mz4lU11VBfq/nPlZ/olgvA1dMsE7lROmttnbswakQhcofZtogYRSuP0f/RklXUc2F4+LHGMJjjUqdVoqnKrjdPPW2kFoDve4XZQFWh3NVNCx1ffG9kp+vGILtTGXNLUJgkFO9BSuH3rLRSTKunzqHcaLlO3HcpOgoY8wYZlh5UNRDSyA0sPeFEdut6+UVZnqj0OMytm+oSrX8XvUNWkOzp6BhynTW0VXYule+HW5wJ900RY5imkuvHtdQp4F14rX7pJh48NrAApBz3en4qKrByIYOR2QlxFgCm6UG+4bP+PDM7OjLwafImX+2vjYHdAA1hrwKzKmBNjl1nCiP1b2PySJS12fGo8CQSuv2wxvuKwsej1d5o5LBdXxxxMSbX6N0+poV5qr7SE9txdWzF846u6+5l2XLi3ab+ovcawrV3YPBQa+IBegbNKIO9CBHG+wzXm8xTovz7st0i7hib1+3pwf6nU1LvrPWuLdMvofD3PcMqD+hKvDcoFgvOekwySJ8V5GnnSavKJm3ZVXKEktlCqSZGzFSES88kFYJ2rpGCuxH1Kz4cefAGmBnGV90Sg+RGWHh4w5Qp8Bvwi2QCVkJ4fAmX7G22rtNjfTGeF6xTlQK4jpc/DyhBVXKXHX2UB5Y9S3u0b/7XGEYYedwhsuQvzlLvp8x4UWQdTJhEmx2943Rne4sF/XIeN/sz4AeqhomHjNUYKVWJca7y2/7HHaFJm3eRHz6lE3nm/EEuJ4+a1auRgt3nFrMuqTwZdt4u/iOy8wbqK+7Z6/wgQOq9jd2RFeQ/QAq6C3i0UIkO0Roe2KYBp4zNeh6gZXxmX4H7FQYDYi1QIqfQRt2R6HlthunPMq2ocaqn2abDymH8+z6k8M6rgG3mJvqbXpBPIRBw/M3aSOJI8gR6NHl6sucWnG6DGOUijKfgpabd5c9BT+TUDMf9oYt/6pUvg/6+cer9COEkZ7NZDtpxZLIuKxbm3rwaeTLma9DA0nrmcIYeEkLsWzBrWK4QYNPDSZtowsav5j/yTiWe+wyhKfhYVUBuolgeejde6c4bActw3LEfx52BQa2FNWrzNaZP2zMNkESk1sjlfxxAfrae9NND6qIICGmK0kCSDm933PHumPyjObmLAzQCTSbE5L1gokkqW0L/wVUMffof09F+4E1QHfWFVueGbSMwgewRziNgIBCgX83R/8NdV2uvtH6WWodvKT1r27pRMBB7LoVrZl7nyn7kMB59IOQohGQhmkNgeAY4RqWy6Df7glCvBG0xAgoI3miAcpW4b6p40fly/AkIUzxJrolJkf7N4c3TzeNG/vZXLp+3ii70pODVG953lPG+JiY+magYZLZ/dpA03AzOj6pZEu27/LfYpqlRontDIaH9RmoIGuU+m9m/tkRYE31jlVHkR+cBwF7iXlwCj9KJY7CVHi8QgdDq9cmQPsivW/sX4CRTxU7J6aQMXJfAF/eR9PQcx7lrtDuLPLtnmoJN5w6XeCpEbHsAdbtYHqxUk0MhIWjE3xXYFdc8m0QLvhqbJwtTZFa3Dd6F+yI2UWt6T7j8CFg+dZ7Wa+xZgHX35LJ7F7jhmnDgz0wamAgu+dpwzFXI8uoOug75ZKR9rMQYQXiud+FOkqrREHiN51W4PxWU7D+WZoVU2p5NRwNYjGsKSY922Kc69+tLNig1ZDq6uq2YrtiOQiUTeBSsYq08MulGWItqQGvmvbBUB6xtR8+p/+WjFHz82O6x7qU6fhtmudWNdJGz0vn/Qne3endQB7YKnBFuKK3YvzmLZdLp6hN++uI5KbUsjE7O9JVwuaL09LzF6BvmUymfHmwtPVLnLnMuCVo21AcgZIGNtJB7nUueAHlY5/cI6yTTZFdWczXILio3U4VF+ROYsWNWun5EFP6Ubv56z3SAXbnq3SejOav/DHEmMc7nYwUljBM7j9/9bgQ2TFQU9qGMpg+V2JYOQ9/CLC2vspqJ9GTO5BxmlcfFx33/GMHFW9sPeBpZbbYakzQGWsFoKXUS/+2V62+/VrQ5J/pADl5f/UsZ0qrcmgN+9HS0JivPSdJ/s/NgmE2jMyVBsX2Zg405x1yKXuAvTDgTVIaRzUW/KUQxyIccXckluDdr0QWImNf6L7nQUyShQ3rmnqrmcvavoyG5pyEwl4kYU4oIwj4ATKwDIRgg4KLkGIE5dH1Npjw8snNNROQErhlz72IlrQ6ae6RmMJe7gInDvpWxdbslzDqUXpkpzIoOS8XdPqXJogu4oPp0aAgLtEbEE4HFmtAYCFzP5wyezqbywvWTQOHUr3IjnxG355FqKaKDYaC168IucYFwFYyBgj+vAaEbHTOUV+PhBt1Iyh6uLD7ucNIk8VCO1AjqztN1b8/m+hTQhMuUfk0EXnXqRryiPskkMsl84OgK6qEIo0kV/hc4fQrdAnbyf4wtl6o+9faBoRTpdFnnLVwIEfGJ7mV+1Gz0Ti7QrMg8uuooFpCu8AowSgaPrkbTPEVAZG6uPfojJDtZ0zel0q8nO9ajJHhH6mv9cWXFZkQy3QYLDJvwHfwgFpeGfnN3MagdtC44Yal5hRofLIF9kchbJyRBjQkf4ygFIgEldQqQ69BTO9AycyQqKOOqa57wyr0OVxT+uIwI0R43HliWbTGsjFJxcyV2dhQmTKRDWR15VAAZJLMwR5LUlDNhR+5yWMBqbyDenz4D++GcOK3rz8KrjNEw3HiJ8NX2HEXAiKbMfWmkuoKg8flbI5aT8n8cLsjW2+VQu9QpRI6s6fke3jK2MaPYHUSZjGq4qvgGQ+bfVpzCO5DswbPjXglXcSeW6Sc/Ons5D1R70wHfrRquLVzZLfGfCLDp0BpFxdU+3563o4WWKB/5CHkSl+9opgsbgiaLhK7hKyJFL0yY9LVLBG+vAGSDcjTkFdIdLCI+Ezej8YA8WUWhpIfs147JzZqCJfkp0gA6hzZOdd9usv4/FYjXmk6xVVQvtKFiWxT7fbObYwPsKvyShm5zuV+9/T4kxZ3xbDjIFrLqDV336v4aBWefmyEkMsYcH4EeJOzIAoKqtsOl2AvIo+vZdKXauHzwbtjHNJe4rPVXMS86bHbIcKe5J3/HqMjLh0e2VHeohGaApwD4xBAHwW1LTeggzP7HdXbt2+BYn7Ypls+m3q9PKxk3sYRwk4r20Ghz+CG+Z/KhT7vsVBKa+l3DJwu062FKzMMqKk+1zPZNIJklMaFMAbAoZ/m9VPX+WL5DoKJL3igDhIGrplzlJYRXjwmYgQq3YgUEI3c6Kf0beUf7puEzMzS1mqtmlZjATEgLq/+DwIk6IzSImBJ7p23/UhEKkIUdq5czHORofOiEb+N7mvVPdWjKirGJOmaIRSCbUZdN5E7mqxOT2LFCBEOg7795DJOMgsUg2H46gxqNAa8+hsHajA5Rea8kzGYA9traofPaMomGdsYCoYSaNWvLwkTMv+AY61h3Ci/EWAilIGaK3/PC4qKa78lHfG0FAKczyOppNWRIuI1ZhuW4Q/IlrPvdJKHP6MH8UMkNOvicOV8edzJj+Scawg4s7ACM9QFgU6yaBoD/FWYj8NvOkY2mclxxPVZ4VAhdsA9CLghIyViBZpECf2LzKvrC12B67aTm4pF5Rc4vCvhfMrb/8HvonAoXoGQFS18ii0OGoUtwn1EIN5wYGlbChZbYuRNU7+snsJKE7pC8daCsvQW9mixPt7JFJP04tx5jrG21NhgyskQgucixvOWJKm4YJL4pXdLI1vMUW3/i2FA6Dwc9tu8PUMK2QI21owcc4Q6v/2n1jFqYiKFXTZv3qVuFD6bGQ9Q06QobuJAomxNSVl81+VPng0GEMVUwN0IYsiSZ0Rf/FvOXdUtUpGMXGRF3o6gb0vMDk72AO1LrF88o1G3V1m1GwS/BNk7Q2/DaBVMZNwAL3UOVTGeZseCdQw3RsDRN4ldGjslHvzGsmhtu0PRC6q7srPSK5FwnlvHK1ZpRS+4EwTVpJw5s9q3etFRVrJrjSUhPltKs6J60rqggtFPvSYUzNiJD6m7ABhDZzICdyij7xMqp8tLS7aqjbJkeagkHI9sTHfNSm2pS0qeDyhZw3+4MlF7U8uMgTVE1wY8jw5iFXnjDA3KECWd87heagtM9zy+1yUkkyh7bDcPKIXQa16YM+t1CxZpxDXn8YDqSKy/4czi1x/P4IPFhM86wMt9Tn7SXMG6yjfvaBvAfEA4NqL9MhVouHApfMobQfK81GYN6eMXVH6GQKp2jluaGPS4wTJx5SGQ0prpTfhm4ZRzKMkAF0DIi+isKS7Zp4IcoELwlmaWBhovBFoCw0UeFwnhZhMEX6t9YOriWquEqUbX6Kf2b17mB1SFFOhVckAGsCqCQyKRAMNLRxKy7D3JFpQ5tegtBTrvWOqqhFAiv1vu2bvjHqK3t9it0SDbUhlz4gCM8+MuifqqLN6nrU8FLMsv0Hr54LUtMi7I3aSbydWfsZtbOOXkOfJZhZKRtuL5FSCPcDAGUKvISirwrXuRObXnIECfosasnoSbdmpctbqQ/3IDAGJJPhYyPYpXauzNiZ0tcl6gYRUuWRVC4SJGJw4rRzUDblu44mix3xPiYy30VmRjKYX22HsghjEfiGhoqRJfAsWdOzzA7YP0DPbUFgVhFCq0ijIkO09dVJT/sxk+Bs+yl2nlWFAJzv0+XtANjdXh2NrBS+3yy9SXIlkAsCK1YebCK+MizMlsbqqJHEp7u5hE4iL74Q7Ulukkf2ue0pms6FJ+htCiNIO0sEBJtgUj/JmUlx+qM80dljwE5USQgY+en8b8Uu3VtcS145cE0nrv6t0mR1+CogO/7pTfAlyhf6gOYJpV2aihlslKnwah0x30mengtvCLY7HLed9OdfCSsk8bcupCnRqBhxZCtdrCLgSPz4nemBvmPAdb18FJgFKFI7NU/JrOa0L8ntYt9qfAwFCkOCFjaNwtO2bFCsXr/73A4UKSKU64lXF39WBU2sozL/z4nuhRTYjSmmkmPSqbmBXc7P6i+jW54wpRf095VXPf2tGLQ0PSmKblAi3k2pEZRPsiLlEAAGS6L4Tq7A+hzxzMkdiHe3E9BVPyAOoRzilRShCkORgCoOVGCaJJnVNMCj0ahFhRiHth/8cjBTcNJOr38Iuph3VWdiql3w8+QD+VEQjkyC4zkurz6zocwofLabZqYlZfr4fXzZNKI+F9ST/AtShExiHnpo8JTFl8T5Ov4ILyCQ1g93YZNBUgBtEoYloshwZYB6eFdGpJxEcy9QQIxIsNfJI4RzhVzbpdsRnc3mAp8rMPAnia+j5G+I0LGlhCdXPdV8Rx7bmLzog65P1AzJr82B9o9lgGJo9IdOKW+aK683KLjlsQt4Zi+q8kOI8zpwjDAQQTEPGXEKUamrM7Az52bBe5/Twm2XmsQt+nMziaWTEV1BRBLajJRDOZcZvrvZz/mibNixprMmY6OLJJoBAzXCaZR68rDcTD0fcnXZAEzSFxTWMFf3Ti2UFuitbmPtlWhgGh6SlKcRjXp+RTDkkoFzhVMkcb9BLCs9HZIneoz9wgYRtCfLcqOxbja97fWoMHHa2dqdq/FPOHFwrxATWro+8XB6D+P1kZTyuNZI8kCUJwpRNE3wwyLPsUZWcUNGIo6wQm6jz5LEirKrJmdnH/05xXKhqaGu3dYHuKtPxUWMnLMMYDSIOppaTLehv2tL8VdougqKeGu4+kPNu6CcfbrI8VWJQuf9viu/YCr7MjqOdQKKPYj//DB4flUUnqbJy2EkJ2F2le7qNK2StVbP3o0vXfL5Dw+7cn2dSypga4t/n0srticFO7ImsJm219DRzdBsOozlJHHjho83fiOsX7yGNKIToLQ85l6jjVRW7FZKfRdlqbNn4Emiy63gW/P8k9iiCir2b/dwgC2kOSOxMv5NpUvitdBxj5RlSNjCffJt6kHvO+qfKZRyemZbmSfFvMsANjxj6TcubsieeBCPjn/ppDmjgkqBUdC2HHao/BdLLyDhE2lykn49UVOVIRxW3ATMhpD9nUs/sg88ZARWp7gg1ew+Ve6hlb9S1aR+pBwe5JvKgJM6O/Vx4CDjnhr+adUQiv0H/pbeBOlzZXc6wl4D4A+JoZXN3m1NyKRB8ZTRnKJWfFLomytBzdIRJwRNSPzzn38vi6G8k319ECqPfhCNkTzKnGHgVLVeuFtEBmeEBJw8BpsECZ19wX0RFxlqdLXP9O6gt3fRB1E9BIhZsyA9lSwXHr+FkqCDaOTsk/IsAQiE5T6581IGPDj6/ms0xXQXdI6Lcn6wiFEns+NyCqZlnpft30Kh+exitRQfWo25XjwQYp/+3SvTciSXOcQcY0XhkIP18ILvmJuCx/XwdKfectJCHcpIi41cliG14ug4CvMNVZH6emFy+YMQHiSuObHbAVl8CvhRUErueayfFR28WhQ9T0soNkKhl9sexd53ruIhD8RtFLZZDlsK/2IDcOgUfjKgKLtf0IQap2XI541tl0sbFazz6lQpUqhFM9nZ/1jWiPSsyl/O4jUT+6DTz1yMmGzm7O9ZLTa/5ksqoXAW0ALcYQzXGxQJjkE52+sdVHTCIX5QWa/PoPUhXomj4Bt/aMk+iVH7UMk3Zktx4UUHDO9tlLzx4d00sDm5QhtD5Q6Ar7xZJmsq097ctdAjEm2TR9PFkDZR983Z2rm1GtYFVDbztssbd39XmU/TsBRKlXYOSX/5GT03hT4k3Y872vXp+ysj17v5dTQZ3RXKnCdGFfPWxAntN+wkMZlVQFeNJM2jkFgZv5fYkrlJ7371ciAZH1csEJwnEblg+EN9QQ8g1EfZXzPHK8XmTORH/H97aZ2djiTXAqS4xkKlh+l3Sc9GNZ9rx/p0cD7Y4x6y4iL8Js4sLYa5iwLLWbSgoIWX0MTg/31GUvLsuRGvkH/Z4DANAgEwAargKxSe6QEb6+wr/stNGvB0hyg+lghJYN3ehAcZ0LHcvixZJUTUTtUK6Rh5M/WsvMOuWQDd4hNg2QDC/BMBlUPvzxWRX4gou+gJyywGRwEf4Lhp4X832x6HuPtZfes8ISI0mmE9m84H+CvQ2Nc8/+FUvQ/Dmuwu1dJ6Fit9sR1OoFFeb6DJe/AkEn+YJgb2dkXYzqhBTYQ57PNeiNlWrIbzUA4HSMeHv/Eo09LZ5aazsCR4sZebE6FbWpAX+v01x2377fCoE1Jxxst9CX8gGyZiBb+Eak6U3HEIQAz3l5CFcxo+dEVuVjJBw1wnjA5C1W/KnWa6VmEOx4UXBmXrAE8odNBukLxadUgJP981zo+JATLIpw+lhpq6VRjjYpMTcK1hllFCvnY4ovv0okYx7VmIBdlqs4LuunDskhJOU72dYvTJIHk6P3nEMW/RLlPqZyb3rvVCGAHw+UZFayTEKomF9R5rVfHPeb0yO0xBDbX05TMxHYGrUPAV9I6fVUgRQAdKeztTrfrZDSdRkt6MxXxi/FfhDYUCTTtqydwB52CtHi7DulVS1TwVBBGjXgSHfCMNoC/8tCPDnb2tpFI9Sh/mqZwINrea0prjDoxfFBStkJR46EdEH3KWk0MCAVXCKyo/qhePTcMb2YvdsRdWECTbKWK4ZnHoxDxD3zAH0syg2XTe+JA10YD2PWu2GURpSJw/fhcyXzTzM6tzQt7uQz+yqC0S5kKx+gyui7rbDxi643k+P25e55w9SfzhrNb1OaHI69Dtv44xSpzIYPKyBZGKrwM9WjKKZiHnf7idZB4FYsLtR22xaMlJlXvemE0m2y45wsyB1a2bK+zUfxvUcwS6LRKNYn/d94HIGG34JPWOpyoXfb5QofCt00hRVVIne/RTTNI/FMNPUKa03naXnm60lGgeuU0Gwws61M5lIrzkX2hzbGovRgczsP+kCEg4eg2LpYDGuOQS+hFunBvIMxYuQnP9iYvtZSyoq1dvPsrIM/tK/yiiDOIOh38/KrdyUljeOmRR2AXxOoYQeF5oZjlW70l6t1K52itcK/zrrpOfrru4OBA0swM7JDyqmP+m8K0yvoWpY38GAgXyv7szlgpR6lEggp9f6ty3Hl218r+4x6lUHYMFvk/NPIdlQKUY3wmG2T8Bvy46mxZ/LFu8meT6lv54Kvrj6RlHBJONARD65agGW5BHRi7IRR3+oN9fAkZOFZgIL/uULLXx9yAt0keDs1NYQ2Iz0CpDZNOIbgaTnuzk1Wu7o6VML/VnLNtuAYHeVSbHxXcwq3+rWxypYJGL6BzTaY20ZQtjdOCXKjYF/SFdGURXmE/23qXOVyGOzVr3jETgYKFZs/7hWY3rne4L2RedYPqURphomUWoW4CQOHAuegTXuC31/GtVJt65ih+0uIR+IR+cicVYh/4sF4Kbs+IMFwCrpen2Vjve3TqadPXQj6EU3GQmKSST+yr6cJ1nD/5fm9aazTjU/E2jkGRHw1f17UV2ugpZFIoZyznyNa3meGXuhSK5iLAxr3tjQWBi4Rewk60pQxPWSbSLpTyxM8KH5L2hwUQThL9g06D1RWajKFu0lS2Eo4/8PxXyLkuZtUVFxfHjaJT6EDlN3Y9bB3psoi9jv3mZWBkeAE3DuNDZGMz2aIm7Uco8TFwuhWNrcdcZj6gS4C6Jk9vCSoJC5Q2mksg7+cnxdE5fCCyVcn6OqZQNgVxQenbqhqMv03/p4qluffXB2sbZjadQeieKD3XDSyn7EHnBWhNVxrlZqMaKe+Z6GnA47fYxw9gIMRVjIuC29liotLSKfx12zROVij5Kg8gnAso9ZtdigY7mQ6udkQHgl/qojGn4nONY9H2namJuHgokATtKx4VdOM8y/0mpG9V7dhy3iHmr6OnvEWCiHVa1/vihRKrcEdcA9whXi2jNwSHie+D2rfLio2lMuYPwEzuOB2ALNdqhUImFPtUdEajy8IRqgimNYHabnpo3lyQW/rfpJlC1nlOAkIBzCE7yOhfBbKGXIBk4qNfYcf2NHFqDz4ys3euFMGmFlW6hlfVenf8d1VqDYnAhQ9P3hU+DVYrlbPA8Thd2/asbG+RodtOxd2MJ3/XXHtDlC2oDttxynRQ9iWqzis8IZXyBAnUOfKTlxHwf+4bP67/aJFltjIiAYD3/mJnCvtLt/MX2+dPe9KcoUQ+tnO10zFvkPoU8Zc60WVWRfJinM1ZkdU+Ks4y+BmPy7X9f8gos9EajIMbXXgdzMoquXedqJXyxSRDpLHDAIctvGhFU7oSiqHuSnS/ksZGwKMcwv0jjIU5eBNnWIx4mXyevXwaZ1Y8V31T50YN5jNjQrQgr8DT6D7xkKUk6lqSJW+8O+Dj0T+q0rLpYeed1Uwtzfgce5eYKA1Lt/jdoHMkhRhMDxx2nWUuNc31LBdss9IPYytTmyUF9CuDaY09NP+nSd/3xyfD5BR2jERdNWKqFz9nQQTXR8dpIyazrPVoghc+lsPSlIbi/10H10b3v0T1hVl+V0tQRmo1rlkpgCw/C/nF6lU5T9Pe0zCNvFahzUx4WYgemrzBSNsUGgO7hbKQr5r1N+k+Z61XNNKB3TpLLKMd2VZkPNdq5fQsGdIvXmLtEIYRdNK5M3e+woRT4T/ykpWlkf/utAi/8yZL8VhtSH20UKYmne11K79vpi/AzGz+bSSbn7MbwqAZdWXY1LuwCzJv9KhDxh1Lv1v2ihn6upQRDIucf39P3yNxduRGyY5geiklwoT8ClhXFcsGGW1NGFXeFg8Cm6WJgbM5URlWo/MKVcn3P489o5BZSzfP5T6aWiY4xtjSntEb/MBWR4rl2x1WT2StzKEFtUgKQ+F9AVQQcBfjHD0Eiawv+j9FjmG1dyeJQuSjEqefwQw0NjFNaTmssc3R3jcHdjFtgaiblho3SMDf3cgHgZVAGN8tRStrlK+zbygUYXhqiWuXIGPUXJ8QsZuX214tiGIPTWBQExZOrSixyg1XaQv/z89zzetSw0ih22gBtVAEXhRnM0yY2Z5IP7T2xOqJzZ8E0AyC41hdYiOgAcTQfQJCmXZplnQysUafbKTaTfd8DCHZh4fOjnetwET+hea0XMbadS6bwRmp6v3nhm1w1P3Ga8GIyDJT0xNCUc7y65xvBvLxIRIxXlCpZUB5moyCAWeyODKeHe0GtPf4T/2vKhXTEqzjkpHCexG8WPMzYIL17pBDImqYbiWhxlfESIcp/om58TqykhRCp+ApRrGKtFaaWHzKQe9SxJincjpMzomu2BQCQNtd1eJheqDQN/kqiQ99NmGg+do387aUwvAvN5RyH5IEw8zhXTQ28+tBnT8TlJurOYLJSscDfgg5AZzQcIQFUgBAFqC9ffAEoeSpmyRenfH7NikbOimOwWG8YvC1xvKA34/AED6soVxs+JYy6hfcyt4K8TyaI9+R75+6z3rsqJlf/3jKGeryTrJF1vYjeDCUYSHRS7OKKSn/tzxnzxogd03jct7xvjTSrQ2j4tGWYl50FUAw2ACVA2BpoB9sgGJzJjXKJw3DfUX/Hei2p3gH8GlJOFKply4JdYjpDlnoGkl2T8YWC1cZ/NE1j+mbg4flZonh2HuNAOk33kescVRP42HtWaf5Qv491SsdtmoVPMyaj3zzW8ry+Nqjqwlw1NDkU92nytykcHf1qwCJWumSU6DpAr/RHJ5+eM7hu7yq0wvWDqXxn/OEb9FFzZQ37op+hUb4HnU7WI0Lykdkvw8EEUmAgR9bAKmOeKrEm6JZXZWL7guAaUu8KVpRPv8ExNZhePHcsp23R0gtKjilK5mEDtMu3VlitD3WhNb98DBNfR/axJmdyfJVzDDu8sk8vCoqj7tHElR63zb0k0Pv9oHO+MIMDoSmoCYZts8WmkCeVBDsnS2nWXxd47qSpYEeB7WxLosUxULzkPDhuApIyCR3ASAZs6VXsOKFmg8VzbXA43wIzuiA7GsIFZCvZGX3VoiatJhOBdc95lMACu+YA11dlB0pYK985ENaD9sxgn/I5keXfm8lQQtRLn+ncM/gwQOIsssgjhnTzG9aZUzDgLgXPbSbevjFyFBiNzOEKLmWWbhOkPreosSxoufkiszyxEPOg0zauIVQlGtDuP4OZGFyOx7xuYSyOchr7UV7Z3EZf/NmvV0n5MRL6xDCeWIEIvNIpM6WIIfpW8apsOeJ854L4e8oup8zM+FzYebftIFd+Wnv/EmDlwmNu4esnRbJwcPnvwF7XtSKu6fpFFPswEE+L3Gaa6cWzmhHYyn/GFXTOsl+iC5/pdcbzvsTSGNImCX4XlhnvthKQEuS4cwa96PLjL5kPVaOF+NtHGGPBZQgWUSY6hGgLSYjGd9vuo/nmwVUCKdSCe9j3s7zaOgpi+Q0E4iXLwgMV/p24/QQ82EgW4kS/JjxWLoedFCkLaQgnJcdcv/pbK/380muv57EEuK6Z67HfjrdCGNOcjP1IbVy+UOdNTRJ4jEAWILtEOfQCCXsCjph1ttGTNPcv0f0+YOx9uer8QQtd8yTjfa3gGbeCRwDa8NR6Hh5ikc8Xo3Cu8uux6PL9Nx0LqzyrROhwe/y3N1vdGtgPoMLz792hSqqOYgyYQTbN0PvZ8vWeZKhLlBft7u8Ot+2dPxQtqahcv+kw8djEjBleefmWK/lic2CQlpZUMkMHbYMlYJxKUJYgymm8p0xZVcjTLecDULjm6PcuJFsGNk3xGGyCUSc3Dmu5p8dluZkZndebfDODHD0qgwMJQpN/pIithqHgn6F8lyJIo8MztifHJlSnbX/ZmGj/51PA6TwjQ4WKFJdkwKsPzsUsi2TUXBw51Z9RCssvMxbAC4OiSp8AQ9Y2yuucSsesdwSYVdIz0LZYkkweam0gGPJftffclOwdHMXr+qUSt5hCN1GR3bt7NIPFZAsM9O887u5m67jGCFst++/jm/LF2oyojF1ljFYN45ORslHE8O1GOEFFT2bSTpjLJkQlp6/EvOmC+uElroCczt5gzLVCEJPbSd3RZG0mC2GyZDFR24EIAQ0uuXzF97Sz046qzGQSZIxw5CwevhmN41Wy/kAUrbKisrl3tMwXxQOl9WcL0ZtGtoRb20KckNG/pBH3PrK8zUCboBUUl2x2xGU6NF0BMfjwQAaaL5v8M8mAlQZdQDg0SbZY6S0mmk5ZGhHy6gC1moMeYvgVCbgmWEiqEbKDq4PIl/OoX5CugBNWCpQoJq6L6eWv2rkt3jaixGhvxnKg/tohMriSD8NvUazqG7jVB/b6huSCMyDI0aQLNI94ALHHf9GiZQzxlhBnVqkihCIhEuSnj1fhp5l1sLQANCLHWypb8peCCwqMbMGWECsiV/gUfFiUUIbS/s4rDS5pkRCsGaV4XuHeUDcIgwzkREokmoFcUAMpRc+2ndFqr+5dmselLAJuvdlP8/7PS7PHRm/qvmBXD5kexGL+brwZlsYI7luKfVvBdfFOpm/RrdV33v7YBc1F0IstCjKPnSUA7EjJtwOv6OIXGIxGzjUo4ahwGzEEQBjcIuJ2WGjb5ywEYSqKXHwveRI8s/P1q9WVGo78WSmCJQbw9a4SPV9d7fXV8/B6FKwcYY4DZebtPsKUjc7LlwLNuX72givO8NL1yn9AuAG9cuFWhw9Z0kPgm/Pc0P7obUzqT275T4HJkavK1iKErssmiHiFgyaMdR56MW0Kf0/XRHZ3mAMEI4HGOk0twfFFaPdAqJ581ApX2V5Ya9Ue1w1DocGFGjreu2/5lRdgCPlUTTW0odVw5yP6RZ3SD76w90wparBrnL6zHA4l1v1CU0W1ubssM/KnVbpzZNGFgfLp5zFBeSSuyVWephgIyA9MlufNpf7tl9Mf+XtoA6In1wxZjJAknl9zCuM+mn1dnPuvUDX2Qo5Yf8GYCAgcljJgajYKX2lLnxcICakbPGEvbA21u7SUwKTmfh3kwrjcYGfJbB7WtocKuR1k/QeJNDtiiouSBAAZn2b5o03QLidEq62RCguGuYFesIIG+WDcqxTXVhKlqxR8+PGPZybnAcNC+DFs7GVXsg7ET627xlDVyHl5ISTUGzfIBrwyddaVTy3OI33avwKtGwAzJ/b8vf+TogBYL/aC3eTTQ5OfVSlVBYsUqLICua7uy2wkqdFhzG2xWdTMYnReF2MO2SlDQcGbsXyobFfFgc7TawaGYC3ciSMUBBF5zssutr7r3fMHGBX2riRf3mSMxUvl+kUje+e1nuIttd5bYennIkqd0NNRYc0OHDm8LL0ToxLzi/M42kBHUh4t14oK3Pcnv4YXztRQmSqnhhJ02zlqPR1lET4UfZPWUsHa7YWBuI9NaQikv+USBEbgRGPEUv6n2Fy6q4HT5TVjsNLyLdko8WuNTCcrN+ovVJ8puDubBQkrXZuOLq/BS7JVMUutIr1ytra01CCT5pLjo+Qyp0QcKIAIKaBHQq/PSHuWnhEqkt2hEpv3n+JlVm34GrboTwqSFbFyXvclot8H7skgR0wpgLQX5dVuMsqZLP2Bu9Ni9gtevXYLrleqyoK+xUEylanpq6nQu5DnLjfJlyG1vtPOoR2djK/MuPLiwtKQ5khh6rfNz3bTAHtHkrQp9uDfa+ZdV6rtcFHjRqB4yvCfJO/z00R9G4kB13gtvSocrcF7ajEBZNp1JFpb9tgRi40fZ8BfjnM/GTHF893x9fpgrF188m9v73YLUHGjbtyZDaAtduUshtuDNpp+/nN9qcqQkbax4aCc7wtK3ru+CCijPzwAbcEMaCvX98If/5VyfZchAHR0DG8INfH2PXibO8JYOKvja5yhLJw6ULRK1Vp7oMsVYJ8HKKUSsZTzIqFTD7YLL1YKzrydezYE1TA9QS0DZlBHuYg9xzFGFz+PuQ7t3xKawSA9N0DAe/gPNOPiUc+6REMywv+BNxWDKTSUVcy3Ixm/jDSjgNKghBeDTJDdwia+NVAjkNO2UhTKYlTTIDmUR3zU8OheAAxDrVD34oPgF1hktBqjDoUIyEzY4iUSt8yr8NZkVNlzvf/h/MxDI6ptV2FVl3kOuwXkpRPVgrm8fRYmqByHyUi+izAnOQusMJKiI1AZnpfL7tsdR04BaJZLrN/Fe4RrNcHNdjJVANWruYKsqwH2xJ5lLd8Pca1Ud3swgx6UJoqppODy3HdwZ4xL8ibt5lqvUUwvqsuyKQ006/vmi0USKQ87wjcnwxCvUxSJQu8IjyYO69o4Iwq3yv1Csq2v51SDuFN06bHlxqEQK2K1RLoQmwiK7gqMRXF4vNqDAwIRqzYN4XBMjHCoQgWsPCRIemv4ZQEGbP6hjDuWTtl6yZaL8rpso5rDE1HYPrHd1VMOd7fJa6A6P9NVLKXH/VY17BJJqhwOTbS6lzjbEZrH44DokEXkiJc3zZ99sUmeKr1i01lt2aCgX4PYACNltSNZ1tpLBeATk1saOwg7e8lgTpdwBDEyA4KrAEKTFW2885/hlqbQ06ffDr020baLrABd/U0QMELYmnbQMbV0PkAGIJYnmQGFFLOv9ucSVNv2w==</div><script src="/lib/crypto-js.js"></script><script src="/lib/blog-encrypt.js"></script><link href="/css/blog-encrypt.css" rel="stylesheet" type="text/css">]]></content>
      
      
      <categories>
          
          <category> Diary </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Love </tag>
            
            <tag> Fiction </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>流体力学</title>
      <link href="/2021/01/20/Knowledge/2021-1-20-%E6%B5%81%E4%BD%93%E5%8A%9B%E5%AD%A6/"/>
      <url>/2021/01/20/Knowledge/2021-1-20-%E6%B5%81%E4%BD%93%E5%8A%9B%E5%AD%A6/</url>
      
        <content type="html"><![CDATA[<h1 id="流体运动规律"><a href="#流体运动规律" class="headerlink" title="流体运动规律"></a>流体运动规律</h1><p>即流体流动所遵循的物理规律，它们是建立流体力学方程组的依据。<br>　　<strong>质量守恒定律</strong>　确定的流体，其质量在运动过程中不变。反映质量守恒定律的方程都称为连续性方程。<br>　　<br>　　<strong>动量变化定律 （牛顿运动定律）</strong>　确定的流体，其总动量变化率等于作用于其上的体力和面力的总和。<br>　　<br>　　<strong>能量守恒定律 (热力学第一定律)</strong>　确定的流体，其总能量（包括动能和内能）变化率等于外力（包括体力和面力）单位时间所做的功与单位时间自外部给予流体的热量之和。<br>　　<br>　　<strong>热力学第二定律 **　存在状态函数熵，用它可指出可逆运动过程的条件以及不可逆过程的方向。在可逆绝热过程中熵保持不变；而不可逆绝热过程只能朝熵增加的方向变化。<br>　　<br>　　**傅里叶传热定律</strong> 　热流密度矢量与温度梯度大小成正比而方向相反。</p><h1 id="流体力学的三大基本方程"><a href="#流体力学的三大基本方程" class="headerlink" title="流体力学的三大基本方程"></a>流体力学的三大基本方程</h1><p><strong>连续方程</strong><br><strong>动量方程</strong><br><strong>能量方程</strong><br>三大基本方程遵循着对应的守恒原理，分别为质量守恒、动量守恒和能量守恒。</p><p>参考：</p><p><a href="http://gr.xjtu.edu.cn/c/document_library/get_file?p_l_id=21242&folderId=29549&name=DLFE-2167.pdf" target="_blank" rel="noopener">第二章流体力学的基本方程 - 西安交通大学</a></p>]]></content>
      
      
      <categories>
          
          <category> Knowledge </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Fluid Mechanics </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>写给24岁的自己</title>
      <link href="/2020/04/27/Diary/2020-4-27-%E5%86%99%E7%BB%9924%E5%B2%81%E7%9A%84%E8%87%AA%E5%B7%B1/"/>
      <url>/2020/04/27/Diary/2020-4-27-%E5%86%99%E7%BB%9924%E5%B2%81%E7%9A%84%E8%87%AA%E5%B7%B1/</url>
      
        <content type="html"><![CDATA[<p>再过一个多月，我就要24岁了，或者已经25了。如果我能活到50岁，刚好一半，可如果我能活到100岁呢，才1/4那么长。<br>显然，现在已经不是第一次看懂言情剧的年代了，那时候的我才11岁，刘品言17岁，整个世界里的大人们都很大，而我也很渴望长大，希望自己不用走太久，就能见到25岁的自己。那时候的我以为，25岁的自己会像山东青年杂志的封底女郎一样潇洒，或许只是一个自由撰稿人，但起码经济独立哦，我可以去买好多书，或者去海边吹吹风，看一看书本里的世界。<br>可是我真的要25喽，开始有些害怕，因为我还是很喜欢追剧，只不过当年陪我长大的威廉们，都已经退出荧屏了，取而代之的，是比我还小的他们。93还好，96也凑合，97，98就太可怕了。突然感觉数字真的好刺眼，19，20已经成了我无法企及的字眼。<br>但是，我还是很会安慰自己。</p><blockquote><p>不要害怕对数字敏感，你才24岁，每个10年以后的你都会艳羡这样的今天：原来10年前的我是如此年轻。每个今天都是10年以后的昨天，所以你一直都很年轻。</p></blockquote><blockquote><p>当你看了一部好电影，读了一本好书，遇见了一个好人，不要因为太美好而害怕失去之后的伤感，勇敢去寻找下一次遇见。</p></blockquote><blockquote><p>你会慢慢懂得，世间无所谓永恒，没有哪一次陪伴长达终生，你要勇敢说再见，也要学会说你好。生命本没有意义，所有未来充满未知和期待，白纸上的意义依靠你去装点。万事别苛求完美，完美的背后是死亡。</p></blockquote><blockquote><p>欣赏一部新电影，打开一本新书，认识一位陌生人，每一次新的遇见，都需要用时间去培养感情，你的付出，决定了一段感情的深浅。</p></blockquote><blockquote><p>生命很短，如果可以遇见照亮心灵的萤火，就不要宁静地守候漆黑的夏夜。当然，你也要学着去做这样的萤火，点亮别人的夏夜。</p></blockquote><blockquote><p>永远不要把成功定义为人生的奋斗目标，你要去做自己最喜欢做的事。那些我们所追捧的成功人士，只是做了自己想做的事的事，仅此而已。</p></blockquote><blockquote><p>如果你有梦想，用心去呵护她。哪怕她与现世格格不入，没关系，她有你就足够。</p></blockquote><blockquote><p>以后的路还很长，你会经历很多，有温暖和阳光，也难免接受伤害，甚至跌落黑暗。世事的变迁在悄无声息地改变着每一个人，但我还是希望你能保护好自己。<br>要知道，你所看见的伤害，不是教你如何去刺杀别人，而是让你懂的，受伤的感觉很痛，你要学会体谅别人，照顾弱小。<br>很多时候，点亮一个灰色的世界，让所有充满意义，只需要一个暖心的细节，比如一句恰如其分对的鼓励，或者自己告诉自己：我相信你。<br>给自己多一点耐心，予未来多一点期待。</p></blockquote><blockquote><p>永远不要轻易否定别人的梦想，你没有这个权利，梦碎之后是扎心的黑暗；也绝不允许别人轻易打碎你的未来。每一条路认真走下去，结果都不会太差。</p></blockquote><blockquote><p>用心去理解这个世界，如果你还在依靠头衔，地位，金钱来定位一个人，那只能说明你对自己的判断力毫无自信，或者你根本没有属于自己的判断力。</p></blockquote><blockquote><p>我知道你是一个赌徒，可以允许自己失败一万次，也不想放弃哪怕万分之一的希望。所以，勇敢去赌，开启赌局是你的问题，即使输了又不代表失败，万一又赢了了呢，岂不是皆大欢喜。</p></blockquote><blockquote><p>物依稀为贵，亘古不变的真理。当大家都去保研，直博，转博的时候，考博的人就是很帅。当大家都去经历爱情的时候，为了自己的相信，永不将就的人就是很温暖。当大家都略施粉黛的时候，不会化妆的素颜反而是难得的风景线。</p></blockquote><blockquote><p>去经历，去追寻，去接受所有改变和未知，直到云卷云舒，淡定自如。<br>愿你的努力配得上你的执着，经得起时间的封藏，静心期待生命的惊喜。</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> Diary </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Heartbeats </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>用正确的方式打开生命</title>
      <link href="/2020/04/03/Diary/2020-4-3-%E7%94%A8%E6%AD%A3%E7%A1%AE%E7%9A%84%E6%96%B9%E5%BC%8F%E6%89%93%E5%BC%80%E7%94%9F%E5%91%BD/"/>
      <url>/2020/04/03/Diary/2020-4-3-%E7%94%A8%E6%AD%A3%E7%A1%AE%E7%9A%84%E6%96%B9%E5%BC%8F%E6%89%93%E5%BC%80%E7%94%9F%E5%91%BD/</url>
      
        <content type="html"><![CDATA[<h1 id="Gloomy-Sunday-Ein-Lied-von-Liebe-und-Tod"><a href="#Gloomy-Sunday-Ein-Lied-von-Liebe-und-Tod" class="headerlink" title="Gloomy Sunday - Ein Lied von Liebe und Tod"></a>Gloomy Sunday - Ein Lied von Liebe und Tod</h1><p>美好与残酷，忧郁和神秘。如果文艺的中包含着两种温度，那一定是冰火两重天。<br>在虚构的世界里短暂的游离，一半是为了逃避现实，一半是为了寻找无法到达的远方，一半是为了愉悦自己。其实，每个人的生活都像时空里的平行线，我们不在乎别人喜欢什么，也无法和另一个人交换人生，所做的一切，最终不过是为了愉悦自己。<br>有的人可能喜欢不拘小节，有的人可能喜欢精雕细琢，反正每个人有每个人的活法。有生之年，把值得记忆的事情刻进骨子里，是需要花费些时间，但路途中的感受总让人难忘。<br>每个人心中都有一个桃花源，但所需的旅途大概各有不同。</p><p>我发现忧伤和文艺，有个神秘的约定。幸福的日子里，显然拥有更多平实与安稳。</p><h1 id="North-amp-South"><a href="#North-amp-South" class="headerlink" title="North &amp; South"></a>North &amp; South</h1><p>Today, I’d like to enjoys the authentic British Accent, so i found the British television series named “North and South”. At first, it seems like anohter “Pride and Prejudice”, the old-fashioned love story between a wealthy man and a beautiful young woman.  But when I landed on the ending part, I changed my mind. The love between Magarate Hale and John Thornton is pure, warm, and respectful, not very smooth but with happy ending.<br>It made me realize that brave and kind might be the two most important thing in the world. I look forward to that man, who is not the lucky guy in the world, but he can undertand what i have went through and we can share our past as well the future together.<br>I am a little women out of cage, who are you come from mistery?<br><img src="/medias/pic_md/Diary/NorthandSouth.jpg" alt="NorthandSouth"></p><h1 id="Start-Over"><a href="#Start-Over" class="headerlink" title="Start Over"></a>Start Over</h1><p>《遇见王沥川》教会我很多事，2016年7月31日上映的好剧，我一定听过这个名字，当时却没有机会，没有心情，没有时间去停留，去品味。今年是2020年，浅尝被拒绝，被忽略的痛苦，面对未来毫无定数的恐惧，一个人躲在被窝里的孤单，把所有没有借口付诸行动的泪水都交付给了《遇见王沥川》。<br>沥川的善良，温暖，体贴；认真，低调，谦和，大概已成为当今时代的稀缺。<br>很多时候，对自己多一点耐心，对未来多一点期待，已经成了我做不到的奢求。<br>如今停下手头的工作，静下心来装点博客，已是不可多得的享受。<br>更不用说，半夜里把32开的笔记本裁开，粘成88个琴键的长度；水粉刷描上黑键；徒手折出无线谱；画好所有的唱名和音高。冲动是魔鬼，也是不惧疲惫的热情，不是吗？<br>为何不勇敢一点，在红尘客梦的高墙外，留一点空白，送自己一份自由自在。<br><img src="/medias/pic_md/Diary/StartOver.png" alt="StartOver"></p><h1 id="当幸福来敲门"><a href="#当幸福来敲门" class="headerlink" title="当幸福来敲门"></a>当幸福来敲门</h1><p>哪怕经历一万次失败，也不要放弃万分之一的希望。（2020年3月4日晚，我流着眼泪，看着镜子中的自己，奢求有人告诉我，我是对的）<br>永远不要打碎别人的梦，否定别人的未来，世界上没有哪一条路是完全行不通的，修改别人的梦想是残忍的。<br><img src="/medias/pic_md/Diary/Happyness.jpg" alt="Happyness"></p><h1 id="一生有你：小王子"><a href="#一生有你：小王子" class="headerlink" title="一生有你：小王子"></a>一生有你：小王子</h1><p>我很幸福，因为我的心里一直都有一个小王子。<br>我爱过许多人，也爱过很多事，有些已经消逝，有些依然握在手里，但它们在我心里都有属于自己的位置。<br>我经历过许多幸福，也品尝过些许苦楚，有些已经忘记，有些依然留在心底。那些永远住进脑海里的片段，不是因为他们有多重要，不能忘记。而是因为它们曾经带给我别样的体验，让我舍不得忘记。<br>不要总是用实用主义去揣摩整个世界，很多东西，曾经以为重要的，却经不起时间的洗礼；有些事情，曾经以为无足轻重的，却承载了最真挚的回忆。<br><img src="/medias/pic_md/Diary/TheLittlePrince.png" alt="TheLittlePrince"></p><h1 id="小美人鱼"><a href="#小美人鱼" class="headerlink" title="小美人鱼"></a>小美人鱼</h1><p>我想告诉我未来的女儿，现在的自己，以及所有喜欢童话的小女生，如果你是小美人鱼，就不要把自己的鱼尾巴变成人类的双腿。</p><h1 id="一个陌生女人的来信"><a href="#一个陌生女人的来信" class="headerlink" title="一个陌生女人的来信"></a><a href="https://pan.baidu.com/s/1rrdsdH-fLYesG4cJ4bd35w" target="_blank" rel="noopener">一个陌生女人的来信</a></h1><p>我从未想过, 有人会和我一样, 做过同样的傻事, 单是某些只言片语, 就已经收走了我的灵魂.</p><blockquote><p>我的一生确实是从我认识你的那一天才开始的。</p><p>这个世界只因为和你有关才存在.</p></blockquote><blockquote><p>我把这一切都告诉你, 亲爱的, 把这一切琐碎的简直可笑的事情喋喋不休地说给听,为了让你明白,你从一开始就对我这个生性腼腆, 胆怯羞涩地女孩子具有这样巨大的力量. 你自己还没有进入我的生活, 你的身边就出现了一个光圈.</p><p>我的心始终为你而紧张, 为你而颤动; 可是你对此毫无感觉, 就行你口袋里装了怀表, 你对它地紧绷的发条没有感觉一样. 这根发条在暗中耐心地数着你的钟点, 计算着你的时间, 以它听不见的心跳陪着你东奔西走, 而你在那滴答不停地几百万秒当中, 只有一次向它匆匆瞥了一眼. </p></blockquote><blockquote><p>我没有想到, 我对你的心灵来说, 无论是相隔无数地山川峡谷, 还是说在你和我那抬头仰望地目光之间只相隔你窗户的一层玻璃, 其实都是同样的遥远.</p></blockquote><blockquote><p>我是有自尊心的, 我要你一辈子想到我的时候, 心里没有忧愁. 我宁可独自承担一切后果, 也不愿变成你的累赘. 我希望你想起我来, 总是怀着爱情, 怀着感激. 在这点上, 我愿意在你结交的所有女人当中, 成为独一无二的一个. 可是当然啰, 你从来也没有想过我, 你已经把我忘得一干二净.</p></blockquote><p>你唯一能给我的，唯一给过我的，唯一让我忘不掉的，是勇气。</p><p>让我如何否定你，否定自己做过的一切，否定独自规划好的未来。</p><h2 id="后记：此栏目的前世今生"><a href="#后记：此栏目的前世今生" class="headerlink" title="后记：此栏目的前世今生"></a>后记：此栏目的前世今生</h2><blockquote><p>2019-12-12， 累了，孤单了，受伤了，我们一起去读书吧，用别人的眼睛和自己的心灵触碰世界。</p></blockquote><p>我们都渴望被爱，但时常忘记体谅别人。愿你在失去中懂得珍惜，在受伤中学会保护自己。<br>每个人都是自私的，但在自私之外，最起码要有真正的尊重、理解和支持。<br>如果可以的话，用透明的心灵，去感受平凡眼睛看不到的远方。</p><blockquote><p>2019-11-30， 每当我想你时，我会去做一件有意义的事，这是我做过的最浪漫的决定，也是对自己最大的宽慰。</p></blockquote><blockquote><p>2019/12/11，平凡的日子里，去做一件有意义的事，自己去遇见惊喜。</p></blockquote><p>今天将是我重生的日子。往昔，不留恋，不回头，不心动。<br>希望你有足够的勇气和毅力，每一天都可以不遗余力，不要着急去问值不值得，用心去付出，时间会给你最好的回答。<br>我想告诉你，不论何时何地，不管是为一个人，为一件事，还是为一个梦想，只要你想<strong>奋不顾身</strong>，不需要任何理由，也没有必要瞻前顾后。<br>抄一首诗，弹一首曲子，看一本书，画一幅画，写一点小说，听一首歌，寻找一点新鲜的遇见。。。我希望此后做的每一件事，都能静心，用心，不再是自己的人生里匆忙的过客。</p>]]></content>
      
      
      <categories>
          
          <category> Diary </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Love </tag>
            
            <tag> Life </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>果腹不只为充饥</title>
      <link href="/2020/04/01/Diary/2020-4-1-%E6%9E%9C%E8%85%B9%E4%B8%8D%E5%8F%AA%E4%B8%BA%E5%85%85%E9%A5%A5/"/>
      <url>/2020/04/01/Diary/2020-4-1-%E6%9E%9C%E8%85%B9%E4%B8%8D%E5%8F%AA%E4%B8%BA%E5%85%85%E9%A5%A5/</url>
      
        <content type="html"><![CDATA[<p>我喜欢健康的生活，几乎不喝饮料，从不乱吃零食，每天一定会做三件事：午休，吃水果，喝茶。<br>今天盘点一下一年四季适宜入口的水果吧，纵使塑料大棚一直都在，还是推荐大家多吃应季水果。</p><h1 id="春宵一刻值千金，花有清香月有阴"><a href="#春宵一刻值千金，花有清香月有阴" class="headerlink" title="春宵一刻值千金，花有清香月有阴"></a>春宵一刻值千金，花有清香月有阴</h1><h3 id="水果"><a href="#水果" class="headerlink" title="水果"></a>水果</h3><p>草莓、樱桃、桑葚、菠萝、山竹、榴莲。</p><h3 id="蔬菜"><a href="#蔬菜" class="headerlink" title="蔬菜"></a>蔬菜</h3><p>春笋 </p><h1 id="绿树阴浓夏日长，楼台倒影入池塘。"><a href="#绿树阴浓夏日长，楼台倒影入池塘。" class="headerlink" title="绿树阴浓夏日长，楼台倒影入池塘。"></a>绿树阴浓夏日长，楼台倒影入池塘。</h1><h3 id="水果-1"><a href="#水果-1" class="headerlink" title="水果"></a>水果</h3><p>西瓜、提子、桃子、李子，杏、苹果、番茄、圣女果、荔枝、百香果、芒果、石榴、龙眼、百香果、椰子、蓝莓、龙眼、哈密瓜、木瓜、葡萄、无花果、猕猴桃。</p><h1 id="深秋帘幕千家雨，落日楼台一笛风。"><a href="#深秋帘幕千家雨，落日楼台一笛风。" class="headerlink" title="深秋帘幕千家雨，落日楼台一笛风。"></a>深秋帘幕千家雨，落日楼台一笛风。</h1><h3 id="水果-2"><a href="#水果-2" class="headerlink" title="水果"></a>水果</h3><p>火龙果、梨、紫薯、红薯、南瓜、柿子、葡萄、提子、</p><h1 id="晨起开门雪满山，雪晴云淡日光寒。"><a href="#晨起开门雪满山，雪晴云淡日光寒。" class="headerlink" title="晨起开门雪满山，雪晴云淡日光寒。"></a>晨起开门雪满山，雪晴云淡日光寒。</h1><h3 id="水果-3"><a href="#水果-3" class="headerlink" title="水果"></a>水果</h3><p>橘子、橙子、丑柑、香蕉</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Cascade Net的训练</title>
      <link href="/2020/01/04/MyResearch/2020-1-4-Cascade%20Net%E7%9A%84%E8%AE%AD%E7%BB%83/"/>
      <url>/2020/01/04/MyResearch/2020-1-4-Cascade%20Net%E7%9A%84%E8%AE%AD%E7%BB%83/</url>
      
        <content type="html"><![CDATA[<p>本文主要分析Cascade Net（级联网络）的训练情况。</p><h1 id="2个网络，2个loss，梯度如何回传？"><a href="#2个网络，2个loss，梯度如何回传？" class="headerlink" title="2个网络，2个loss，梯度如何回传？"></a>2个网络，2个loss，梯度如何回传？</h1><p><img src="/medias/pic_md/MyResearch/net1net2.png" alt></p><ol><li>loss1只会优化net1;</li><li>loss2优化net1和net2。</li><li>推荐使用1个优化器，优化一个loss(loss1+loss2), 方便简洁.</li></ol><p>公共代码部分：</p><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">class</span> <span class="token class-name">Net1</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>layer1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>ConvTranspose3d<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>InstanceNorm3d<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>        <span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> input<span class="token punctuation">)</span><span class="token punctuation">:</span>        layer1 <span class="token operator">=</span> self<span class="token punctuation">.</span>layer1<span class="token punctuation">(</span>input<span class="token punctuation">)</span>        <span class="token keyword">return</span> layer1<span class="token keyword">class</span> <span class="token class-name">Net2</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>layer2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>ConvTranspose3d<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>InstanceNorm3d<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>        <span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> input<span class="token punctuation">)</span><span class="token punctuation">:</span>        layer1 <span class="token operator">=</span> self<span class="token punctuation">.</span>layer2<span class="token punctuation">(</span>input<span class="token punctuation">)</span>        <span class="token keyword">return</span> layer1loss1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>SmoothL1Loss<span class="token punctuation">(</span><span class="token punctuation">)</span>loss2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>SmoothL1Loss<span class="token punctuation">(</span><span class="token punctuation">)</span>net1 <span class="token operator">=</span> Net1<span class="token punctuation">(</span><span class="token punctuation">)</span>net2 <span class="token operator">=</span> Net2<span class="token punctuation">(</span><span class="token punctuation">)</span>input <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span>target1 <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>target2 <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="2个优化器独立优化2个Net，两个loss独立回传"><a href="#2个优化器独立优化2个Net，两个loss独立回传" class="headerlink" title="2个优化器独立优化2个Net，两个loss独立回传"></a>2个优化器独立优化2个Net，两个loss独立回传</h3><pre class=" language-python"><code class="language-python">optimizer1<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>loss_output1<span class="token punctuation">.</span>backward<span class="token punctuation">(</span>retain_graph<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># optimizer1.step()</span><span class="token keyword">for</span> name<span class="token punctuation">,</span>param <span class="token keyword">in</span> net1<span class="token punctuation">.</span>named_parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>name<span class="token punctuation">,</span>param<span class="token punctuation">.</span>grad<span class="token punctuation">)</span><span class="token keyword">for</span> name<span class="token punctuation">,</span>param <span class="token keyword">in</span> net2<span class="token punctuation">.</span>named_parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>name<span class="token punctuation">,</span>param<span class="token punctuation">.</span>grad<span class="token punctuation">)</span>optimizer2<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>loss_output2<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># optimizer2.step()</span><span class="token keyword">for</span> name<span class="token punctuation">,</span>param <span class="token keyword">in</span> net1<span class="token punctuation">.</span>named_parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>name<span class="token punctuation">,</span>param<span class="token punctuation">.</span>grad<span class="token punctuation">)</span><span class="token keyword">for</span> name<span class="token punctuation">,</span>param <span class="token keyword">in</span> net2<span class="token punctuation">.</span>named_parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>name<span class="token punctuation">,</span>param<span class="token punctuation">.</span>grad<span class="token punctuation">)</span></code></pre><p>output:</p><blockquote><p>layer1.0.weight tensor([[[[[ 0.1047, -0.0668],<br>                    [ 0.1183,  0.0265]],<br>                    [[ 0.0277,  0.1389],<br>                    [-0.0696,  0.1308]]]]])<br>layer1.0.bias tensor([-4.6566e-09])<br>layer2.0.weight None<br>layer2.0.bias None</p><p>layer1.0.weight tensor([[[[[ 0.1112, -0.0436],<br>                    [ 0.0883,  0.0262]],<br>                    [[ 0.0384,  0.1336],<br>                    [-0.1178,  0.1256]]]]])<br>layer1.0.bias tensor([-2.7940e-09])<br>layer2.0.weight tensor([[[[[ 0.0079,  0.0407],<br>                    [-0.0628,  0.0299]],<br>                    [[-0.0284, -0.0627],<br>                    [ 0.0145,  0.0101]]]]])<br>layer2.0.bias tensor([1.1642e-09])</p></blockquote><h3 id="1个优化器优化2个Net"><a href="#1个优化器优化2个Net" class="headerlink" title="1个优化器优化2个Net"></a>1个优化器优化2个Net</h3><pre class=" language-python"><code class="language-python">optimizer1 <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">{</span><span class="token string">'params'</span><span class="token punctuation">:</span> net1<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token punctuation">,</span><span class="token punctuation">{</span><span class="token string">'params'</span><span class="token punctuation">:</span> net2<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">}</span><span class="token punctuation">]</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.001</span><span class="token punctuation">)</span></code></pre><h3 id="1个优化器优化2个Net，2个loss加和回传"><a href="#1个优化器优化2个Net，2个loss加和回传" class="headerlink" title="1个优化器优化2个Net，2个loss加和回传"></a>1个优化器优化2个Net，2个loss加和回传</h3><pre class=" language-python"><code class="language-python">optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">{</span><span class="token string">'params'</span><span class="token punctuation">:</span>net1<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token punctuation">,</span><span class="token punctuation">{</span><span class="token string">'params'</span><span class="token punctuation">:</span>net2<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token punctuation">]</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.001</span><span class="token punctuation">)</span>net1<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>net2<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>output1 <span class="token operator">=</span> net1<span class="token punctuation">(</span>input<span class="token punctuation">)</span>output2 <span class="token operator">=</span> net2<span class="token punctuation">(</span>output1<span class="token punctuation">)</span>loss_output1 <span class="token operator">=</span> loss1<span class="token punctuation">(</span>output1<span class="token punctuation">,</span> target1<span class="token punctuation">)</span>loss_output2 <span class="token operator">=</span> loss2<span class="token punctuation">(</span>output2<span class="token punctuation">,</span> target2<span class="token punctuation">)</span>loss_output <span class="token operator">=</span> loss_output1<span class="token operator">+</span>loss_output2optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>loss_output1<span class="token punctuation">.</span>backward<span class="token punctuation">(</span>retain_graph<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># optimizer1.step()</span><span class="token keyword">for</span> name<span class="token punctuation">,</span>param <span class="token keyword">in</span> net1<span class="token punctuation">.</span>named_parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>name<span class="token punctuation">,</span>param<span class="token punctuation">.</span>grad<span class="token punctuation">)</span><span class="token keyword">for</span> name<span class="token punctuation">,</span>param <span class="token keyword">in</span> net2<span class="token punctuation">.</span>named_parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>name<span class="token punctuation">,</span>param<span class="token punctuation">.</span>grad<span class="token punctuation">)</span>optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>loss_output2<span class="token punctuation">.</span>backward<span class="token punctuation">(</span>retain_graph<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># optimizer2.step()</span><span class="token keyword">for</span> name<span class="token punctuation">,</span>param <span class="token keyword">in</span> net1<span class="token punctuation">.</span>named_parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>name<span class="token punctuation">,</span>param<span class="token punctuation">.</span>grad<span class="token punctuation">)</span><span class="token keyword">for</span> name<span class="token punctuation">,</span>param <span class="token keyword">in</span> net2<span class="token punctuation">.</span>named_parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>name<span class="token punctuation">,</span>param<span class="token punctuation">.</span>grad<span class="token punctuation">)</span>optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>loss_output<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># optimizer2.step()</span><span class="token keyword">for</span> name<span class="token punctuation">,</span>param <span class="token keyword">in</span> net1<span class="token punctuation">.</span>named_parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>name<span class="token punctuation">,</span>param<span class="token punctuation">.</span>grad<span class="token punctuation">)</span><span class="token keyword">for</span> name<span class="token punctuation">,</span>param <span class="token keyword">in</span> net2<span class="token punctuation">.</span>named_parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>name<span class="token punctuation">,</span>param<span class="token punctuation">.</span>grad<span class="token punctuation">)</span></code></pre><p>output:</p><blockquote><p>layer1.0.weight tensor([[[[[ 0.0281,  0.0501],<br>                    [-0.0897,  0.1292]],<br>                    [[ 0.1451,  0.0634],<br>                    [-0.0040,  0.0151]]]]])<br>layer1.0.bias tensor([9.9535e-09])<br>layer2.0.weight None<br>layer2.0.bias None</p><p>layer1.0.weight tensor([[[[[ 0.0686,  0.0366],<br>                    [ 0.0078,  0.0646]],<br>                    [[ 0.0461,  0.0027],<br>                    [-0.0182, -0.0114]]]]])<br>layer1.0.bias tensor([-1.6298e-09])<br>layer2.0.weight tensor([[[[[0.3400, 0.2140],<br>                    [0.2509, 0.2214]],<br>                    [[0.3691, 0.2921],<br>                    [0.3126, 0.2221]]]]])<br>layer2.0.bias tensor([-6.5425e-08])</p><p>layer1.0.weight tensor([[[[[ 0.0966,  0.0867],<br>                    [-0.0819,  0.1939]],<br>                    [[ 0.1912,  0.0661],<br>                    [-0.0222,  0.0037]]]]])<br>layer1.0.bias tensor([-6.0536e-09])<br>layer2.0.weight tensor([[[[[0.3400, 0.2140],<br>                    [0.2509, 0.2214]],<br>                    [[0.3691, 0.2921],<br>                    [0.3126, 0.2221]]]]])<br>layer2.0.bias tensor([-6.5425e-08])</p></blockquote><h3 id="冻结net2的参数"><a href="#冻结net2的参数" class="headerlink" title="冻结net2的参数"></a>冻结net2的参数</h3><pre class=" language-python"><code class="language-python"><span class="token keyword">for</span> param <span class="token keyword">in</span> net2<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    param<span class="token punctuation">.</span>requires_grad <span class="token operator">=</span> <span class="token boolean">False</span>optimizer1 <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">{</span><span class="token string">'params'</span><span class="token punctuation">:</span> net1<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token punctuation">,</span><span class="token punctuation">{</span><span class="token string">'params'</span><span class="token punctuation">:</span> filter<span class="token punctuation">(</span><span class="token keyword">lambda</span> p<span class="token punctuation">:</span> p<span class="token punctuation">.</span>requires_grad<span class="token punctuation">,</span> net2<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">}</span><span class="token punctuation">]</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.001</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># optimizer1 = torch.optim.Adam(net1.parameters(), lr=0.001)# since no param of frozen net2 need to be optimized, so this one is equal to the above optimizer.</span></code></pre><p>output:</p><blockquote><p>layer1.0.weight tensor([[[[[ 0.1854,  0.0710],<br>                    [-0.0503, -0.0730]],<br>                    [[ 0.0512,  0.0873],<br>                    [-0.1704,  0.0965]]]]])<br>layer1.0.bias tensor([-2.2352e-08])<br>layer2.0.weight None<br>layer2.0.bias None</p><p>layer1.0.weight tensor([[[[[ 0.2990,  0.1330],<br>                    [-0.2335, -0.1387]],<br>                    [[-0.1399,  0.1262],<br>                    [-0.2014,  0.2233]]]]])<br>layer1.0.bias tensor([-6.7055e-08])<br>layer2.0.weight None<br>layer2.0.bias None</p></blockquote><h1 id="1个网络，2个loss，梯度如何回传？"><a href="#1个网络，2个loss，梯度如何回传？" class="headerlink" title="1个网络，2个loss，梯度如何回传？"></a>1个网络，2个loss，梯度如何回传？</h1><p><img src="/medias/pic_md/MyResearch/net.png" alt></p><ol><li>loss1只会优化net1;</li><li>loss2优化net1和net2。</li><li>loss1+loss2一起回传也遵循以上原则。</li></ol><p>公共代码部分：</p><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">class</span> <span class="token class-name">Net</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>layer1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>ConvTranspose3d<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>InstanceNorm3d<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>        <span class="token punctuation">)</span>        self<span class="token punctuation">.</span>layer2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>ConvTranspose3d<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>InstanceNorm3d<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>        <span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> input<span class="token punctuation">)</span><span class="token punctuation">:</span>        layer1 <span class="token operator">=</span> self<span class="token punctuation">.</span>layer1<span class="token punctuation">(</span>input<span class="token punctuation">)</span>        layer2 <span class="token operator">=</span> self<span class="token punctuation">.</span>layer2<span class="token punctuation">(</span>layer1<span class="token punctuation">)</span>        <span class="token keyword">return</span> layer1<span class="token punctuation">,</span>layer2loss1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>SmoothL1Loss<span class="token punctuation">(</span><span class="token punctuation">)</span>loss2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>SmoothL1Loss<span class="token punctuation">(</span><span class="token punctuation">)</span>net <span class="token operator">=</span> Net<span class="token punctuation">(</span><span class="token punctuation">)</span>input <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span>target1 <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>target2 <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">)</span>optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.001</span><span class="token punctuation">)</span></code></pre><h3 id="2个loss单独回传"><a href="#2个loss单独回传" class="headerlink" title="2个loss单独回传"></a>2个loss单独回传</h3><pre class=" language-python"><code class="language-python">net<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>output1<span class="token punctuation">,</span>output2 <span class="token operator">=</span> net<span class="token punctuation">(</span>input<span class="token punctuation">)</span>loss_output1 <span class="token operator">=</span> loss1<span class="token punctuation">(</span>output1<span class="token punctuation">,</span> target1<span class="token punctuation">)</span>loss_output2 <span class="token operator">=</span> loss2<span class="token punctuation">(</span>output2<span class="token punctuation">,</span> target2<span class="token punctuation">)</span>optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>loss_output1<span class="token punctuation">.</span>backward<span class="token punctuation">(</span>retain_graph<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># optimizer1.step()</span><span class="token keyword">for</span> name<span class="token punctuation">,</span>param <span class="token keyword">in</span> net<span class="token punctuation">.</span>named_parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>name<span class="token punctuation">,</span>param<span class="token punctuation">.</span>grad<span class="token punctuation">)</span>optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>loss_output2<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># optimizer2.step()</span><span class="token keyword">for</span> name<span class="token punctuation">,</span>param <span class="token keyword">in</span> net<span class="token punctuation">.</span>named_parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>name<span class="token punctuation">,</span>param<span class="token punctuation">.</span>grad<span class="token punctuation">)</span></code></pre><p>output:</p><blockquote><p>layer1.0.weight tensor([[[[[ 0.1199,  0.1322],<br>                    [ 0.3313,  0.2889]],<br>                    [[-0.2830,  0.0982],<br>                    [ 0.2318,  0.4600]]]]])<br>layer1.0.bias tensor([-5.2154e-08])<br>layer2.0.weight None<br>layer2.0.bias None</p><p>layer1.0.weight tensor([[[[[-0.1710,  0.0898],<br>                    [ 0.0150, -0.0648]],<br>                    [[ 0.0969,  0.2731],<br>                    [ 0.1348,  0.1892]]]]])<br>layer1.0.bias tensor([-5.4948e-08])<br>layer2.0.weight tensor([[[[[0.0403, 0.0771],<br>                    [0.2339, 0.4653]],<br>                    [[0.2246, 0.4523],<br>                    [0.1780, 0.3113]]]]])<br>layer2.0.bias tensor([-4.0978e-08])</p></blockquote><h3 id="2个loss加和一起回传"><a href="#2个loss加和一起回传" class="headerlink" title="2个loss加和一起回传"></a>2个loss加和一起回传</h3><pre class=" language-python"><code class="language-python">net<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>output1<span class="token punctuation">,</span>output2 <span class="token operator">=</span> net<span class="token punctuation">(</span>input<span class="token punctuation">)</span>loss_output1 <span class="token operator">=</span> loss1<span class="token punctuation">(</span>output1<span class="token punctuation">,</span> target1<span class="token punctuation">)</span>loss_output2 <span class="token operator">=</span> loss2<span class="token punctuation">(</span>output2<span class="token punctuation">,</span> target2<span class="token punctuation">)</span>loss_output <span class="token operator">=</span> loss_output1<span class="token operator">+</span>loss_output2optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>loss_output1<span class="token punctuation">.</span>backward<span class="token punctuation">(</span>retain_graph<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># optimizer1.step()</span><span class="token keyword">for</span> name<span class="token punctuation">,</span>param <span class="token keyword">in</span> net<span class="token punctuation">.</span>named_parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>name<span class="token punctuation">,</span>param<span class="token punctuation">.</span>grad<span class="token punctuation">)</span>optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>loss_output2<span class="token punctuation">.</span>backward<span class="token punctuation">(</span>retain_graph<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># optimizer2.step()</span><span class="token keyword">for</span> name<span class="token punctuation">,</span>param <span class="token keyword">in</span> net<span class="token punctuation">.</span>named_parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>name<span class="token punctuation">,</span>param<span class="token punctuation">.</span>grad<span class="token punctuation">)</span>optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>loss_output<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># optimizer2.step()</span><span class="token keyword">for</span> name<span class="token punctuation">,</span>param <span class="token keyword">in</span> net<span class="token punctuation">.</span>named_parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>name<span class="token punctuation">,</span>param<span class="token punctuation">.</span>grad<span class="token punctuation">)</span></code></pre><p>output:</p><blockquote><p>layer1.0.weight tensor([[[[[ 0.0622,  0.1044],<br>                    [ 0.0046,  0.0056]],<br>                    [[ 0.0011, -0.1298],<br>                    [ 0.0423, -0.0172]]]]])<br>layer1.0.bias tensor([-1.8626e-09])<br>layer2.0.weight None<br>layer2.0.bias None</p><p>layer1.0.weight tensor([[[[[ 0.0438,  0.0806],<br>                    [ 0.0495, -0.0116]],<br>                    [[ 0.0808, -0.0380],<br>                    [ 0.0780,  0.0077]]]]])<br>layer1.0.bias tensor([1.1176e-08])<br>layer2.0.weight tensor([[[[[ 0.2026,  0.1759],<br>                    [-0.0217,  0.1291]],<br>                    [[ 0.0584,  0.1224],<br>                    [ 0.0403,  0.1459]]]]])<br>layer2.0.bias tensor([3.2596e-09])</p><p>layer1.0.weight tensor([[[[[ 0.1061,  0.1850],<br>                    [ 0.0541, -0.0060]],<br>                    [[ 0.0819, -0.1678],<br>                    [ 0.1203, -0.0095]]]]])<br>layer1.0.bias tensor([3.7253e-09])<br>layer2.0.weight tensor([[[[[ 0.2026,  0.1759],<br>                    [-0.0217,  0.1291]],<br>                    [[ 0.0584,  0.1224],<br>                    [ 0.0403,  0.1459]]]]])<br>layer2.0.bias tensor([3.2596e-09])</p></blockquote><h1 id="综上所述："><a href="#综上所述：" class="headerlink" title="综上所述："></a>综上所述：</h1><p>使用cascade net+2个loss, 为了方便单独load已经训练好的模型或者冻结某个网络的参数，推荐使用2个单独的网络，1个优化器，2个loss加和一起回传。</p><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">class</span> <span class="token class-name">Net1</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>layer1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>ConvTranspose3d<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>InstanceNorm3d<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>        <span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> input<span class="token punctuation">)</span><span class="token punctuation">:</span>        layer1 <span class="token operator">=</span> self<span class="token punctuation">.</span>layer1<span class="token punctuation">(</span>input<span class="token punctuation">)</span>        <span class="token keyword">return</span> layer1<span class="token keyword">class</span> <span class="token class-name">Net2</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>layer2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>ConvTranspose3d<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>InstanceNorm3d<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>        <span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> input<span class="token punctuation">)</span><span class="token punctuation">:</span>        layer1 <span class="token operator">=</span> self<span class="token punctuation">.</span>layer2<span class="token punctuation">(</span>input<span class="token punctuation">)</span>        <span class="token keyword">return</span> layer1loss1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>SmoothL1Loss<span class="token punctuation">(</span><span class="token punctuation">)</span>loss2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>SmoothL1Loss<span class="token punctuation">(</span><span class="token punctuation">)</span>net1 <span class="token operator">=</span> Net1<span class="token punctuation">(</span><span class="token punctuation">)</span>net2 <span class="token operator">=</span> Net2<span class="token punctuation">(</span><span class="token punctuation">)</span>input <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span>target1 <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>target2 <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">for</span> param <span class="token keyword">in</span> net2<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    param<span class="token punctuation">.</span>requires_grad <span class="token operator">=</span> <span class="token boolean">False</span>optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>net1<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.001</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># since no param of frozen net2 need to be optimized</span>net1<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>net2<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>output1 <span class="token operator">=</span> net1<span class="token punctuation">(</span>input<span class="token punctuation">)</span>output2 <span class="token operator">=</span> net2<span class="token punctuation">(</span>output1<span class="token punctuation">)</span>loss_output1 <span class="token operator">=</span> loss1<span class="token punctuation">(</span>output1<span class="token punctuation">,</span> target1<span class="token punctuation">)</span>loss_output2 <span class="token operator">=</span> loss2<span class="token punctuation">(</span>output2<span class="token punctuation">,</span> target2<span class="token punctuation">)</span>loss_output <span class="token operator">=</span> loss_output1<span class="token operator">+</span>loss_output2optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>loss_output<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre>]]></content>
      
      
      <categories>
          
          <category> MyResearch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> PyTorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>见不得光的生命</title>
      <link href="/2019/12/28/Diary/2019-12-28-%E8%A7%81%E4%B8%8D%E5%BE%97%E5%85%89%E7%9A%84%E7%94%9F%E5%91%BD/"/>
      <url>/2019/12/28/Diary/2019-12-28-%E8%A7%81%E4%B8%8D%E5%BE%97%E5%85%89%E7%9A%84%E7%94%9F%E5%91%BD/</url>
      
        <content type="html"><![CDATA[<p>昨夜依旧失眠，想了许多不该想的事，流了许多莫须有的眼泪。</p><p>我们的相遇，该从那一天中午说起。小学，某个中午回家吃午饭的时候，看到屋后的邻居鬼鬼祟祟往麦垛里放了一个东西，我当然很好奇，于是邻居前脚刚走，我随后走过去一探究竟。</p><p>麦堆里，是哼哼唧唧不知所措的你，一只略掺杂色的小白狗。我就这样自然而然把你抱回家据为己有了，因为可爱的东西，大家都想拥有。</p><p>吃过午饭，我该上学了，姨说你是瘸子，怪不得没人要呢，顺带让我立马扔掉，我舍不得，故意推脱到我下午放学后再解决。</p><p>下午的第一堂课上，老师让我们列举一下见义勇为的事迹，我大言不惭地说：我捡了一只狗，然后抱回了家。我仍然记得老师那放光地双眼，毫无遮掩地写着：我想要这只狗。然后我话风一转：可惜它是个瘸子。老师地表情瞬间凝固了，开始了一个人的表演。</p><p>我整个下午大概都没好好上课，在同情你的无辜和无助，也在思考放学后的我该如何护你周全。</p><p>你的何去何从问题一直持续到晚饭结束，全家投票决定把你扔出去，当然除却我那黯然失色的一票。就这样，趁着夜黑风高，你回到了白天我抱走你的地方。</p><p>那一晚，我大概没有睡好，在想着如何安得两全法，护你周全不受伤。<br>第二天，我早早起了床，趁着没人注意我的时候，跑过去偷看了你一眼，你还在睡梦里。</p><p>然后，我飞快地蹦回物色好的地方，开始徒手挖坑，挖到容你有余的尺度，垫上草屑和坐垫，把你安顿进去，上面盖一块大石板，天知地知，你知我知。</p><p>从那之后的每一天里，照顾你，成了我每天最大的责任和幸福。我常常在吃饭的时候，抱着没吃完的饭就溜走了，溜到大门外的街角上，嚼碎了喂给你。</p><p>我不知道这样的偷偷摸摸会持续到某年某月，因为我从未预料，终点会突然出现。就在那一天清晨，我起床去看你，没有哼哼唧唧的撒娇，我掀开石板，而你是真的睡去了，倔强地离开了这个自私的世界，再也不愿意为自己的无辜受挫。</p><p>我很难过，装作若无其事的样子对妈妈说：它走了。还好没有哭出来。我知道你所有的家当被一张铁锨抄到了垃圾堆里，但我没有勇气去看。</p><p>从那以后，青石板下没了你的肉体，却永远住着你的灵魂，阳光刺眼的午后，我走过街角，会闻到你的气息，那是我偷牛奶喂你时，留下的味道。</p>]]></content>
      
      
      <categories>
          
          <category> Diary </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Touch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>往事如风,留在心中</title>
      <link href="/2019/12/20/Diary/2019-12-20-%E5%BE%80%E4%BA%8B%E5%A6%82%E9%A3%8E/"/>
      <url>/2019/12/20/Diary/2019-12-20-%E5%BE%80%E4%BA%8B%E5%A6%82%E9%A3%8E/</url>
      
        <content type="html"><![CDATA[<blockquote><p>每次误入阴霾的时候，只是翻看一下曾经的日记，已经足以让我满心欢喜。<br>我知道不是每个昨天都充满快乐，但是我把所有的欢乐都装进了日记里。<br>谢谢笔耕不辍的自己，在这个摇滚年代里依然保持着手写日记的习惯。<br>那些过往但被记忆的曾经，感动着难免感伤的自己，温润了时常受伤的心，守护着一份永远相信温暖的执著，给我继续前行的勇气和力量。<br>经历过多少快乐并不重要，是那些用心珍惜过的瞬间，让昨日充满了温暖和怀念。</p></blockquote><p>回首过去的读博路，大概已经忘记得差不多了。</p><blockquote><p>今天，我更新了天气预报列表，一个是我住的城市，一个是老妈所在的城市。</p></blockquote><p>我想开始攒钱了，想和老妈出去走一走，也许是绿色的森林，也许是热闹的街市。老妈曾说要带我去爬山，可是我们计划了许多年，都未能成行。老妈也曾去过我的学校，但我们一起走过的路却寥寥无几。我不想后悔，也害怕留不住光阴，也担心意外会夺走我爱的人，或者抹去老妈对我的记忆。<br>家里的水电费，每年的保险费，要归于自己的预算了。<br>如果还有余钱，请给自己买架电子琴吧，我已经喜欢好久了。</p><blockquote><p>Unconditioanal Love——请珍惜这段有她陪伴的时光。<br>如果有一天，我身无分文，却依然富有，那一定是我爱的人，相伴左右。</p></blockquote><p>我已经有两年没有回家了，如果不是聪明的妈妈提醒我，回家的路上有凉亭，还有一个石磨，永远也记不住楼号的我，大概已经忘记回家的路。</p><p>我依稀记得上次离家的场景，老妈会提醒我，该买票了。如今的我依稀有些懂得，当老妈说出这句话时，也在提醒自己，女儿又要离家远行了。<br>每当放假临近，老妈也会提醒我，该买票了。如今的我却总说再等等，老妈也会慢慢懂得，再等等，大概会等很长一段时光。</p><p>我很难想象，如果没有那么多意外和曲折，我们的生活会是怎样一番模样。我也很难去计算，如今25岁的我，和老妈在一起的时光，会有10年那么长吗？<br>但所有天灾和人祸掺杂在一起，也许已经注定了，当初的路，必须那样走。世间没有雪中送炭的圣人，我们也没有预见未来的能力，已经发生的，就必须得接受了。</p><p>小时候数日历长大的我，在相聚和离别中相互轮回的我，过早地选择住校地我，迫于自我保护而选择忘记的我，曾经一度认为亲情是弱点和牵绊地我，慢慢地在独立的路上越走越远。<br>我不知道在这条自以为正确的路上收获了多少，但我一定失去了很多和家人相互取暖的机会。</p><p>过去的十几年里，我们保持联络的方式，无非是从电话过渡到了手机，除了语音，加了点视频而已。如今的我，才慢慢懂得，什么叫做 “internet communication cannot replace face-to-face communication” , 这大概是高中晨读课上张口就来一段台词。事实也证明，如果所有的经历没有积累到爆破点，所见所闻远非所得。</p><p>在我去拿快递的路上，还在回想，从什么时候开始，我花在家人身上的时间，已经远小于未曾谋面的陌生人。是家人的心照不宣，已经到了不需要感情维系的地步吗？还是我只会索取，并且到了理所当然的地步呢？我不想承认，并且故意找理由搪塞着不安的内心。</p><p>当我拆开纸箱的那一刻，是五味瓶打翻的瞬间。<br>老妈曾经问我，你要不要看一下我给你带的东西？其实当时的我在实验室里，有些敷衍地说了一句，先不看了吧，开箱有惊喜呀。但是老妈还是耐心地打了一段文字，是很长地一个list，罗列了和我说过的，和没有提起过的，已经装进箱子里的各种东西。当然，我没有细看，唯一的印象是list很长，也很期待开箱有惊喜的时刻。</p><p>箱子很重，老妈却说才只有16斤呢。是的，上次收到老妈的快递是在考研的冬季，我低估了母爱的重力，单身匹马去家属区拿快递，当我抱起箱子的那一刻，是傻眼的。我不知道箱子究竟又多重，却是我难以承受的重量，我慢慢地把箱子从家属区挪到S楼，两只胳膊疼了整整一个星期。老妈几乎把冰箱里所有的珍宝都装进了我的箱子里，还有应景的各色月饼。这次依旧是这样，家里唯一的冰箱收藏着所有想留给女儿的美味，可惜女儿不回家，老妈只好打包寄到了女儿手边。</p><p>老妈说要寄新灌的香肠，四五斤的样子，当我看到一大包香肠的时候，从没有重量概念的我才知道，四五斤原来是这个样子，远非我想象中的四五根。裹了芝麻盐的烘焙煎饼，是我的最爱，足足占据了箱子的半壁江山；来自冰箱的栗子，花生和红枣，还带着冰冻的外壳，彷佛还带着家中冰箱的余温；真空包装的猪肉，鸡肉，老妈说每一包都有不同的来历；炒过的核桃和芝麻盐，。。。</p><p>天知道打开箱子的那一刻，我又多脆弱，在一个人的房间里选择了哭泣。突然间意识到，哪怕是有血缘维系的亲情，也是需要用心经营的，老妈所作的这些努力，着实让我感受到亲情的重要性。<br>放弃遥远的花花世界，选择留在父母身边，真的挺好的，能收到家人的快递已经很幸福，能吃到家里的热饭真的是人间奢侈。<br>人生的勇气，除了自己给给自己，的确有相当一部分来自家人的支持。未来，亲情面前，高楼大厦都会黯然失色，我所想要的，只不过是有一个温馨常伴的小家而已。</p><p>慧玉是老妈的宝贝女儿，我不知道这样的幸福还会有多少日子，我唯一能做的，只有用心珍惜。<br>老妈义无反顾地爱着唯一地珍宝，慧玉也想此生宠爱唯一的老妈。</p><blockquote><p>记忆里的酸枣仁</p></blockquote><p>中午休息时想起来的，想起了小时候的蹦蹦跳跳。小时候常跟着姨去田里，恍惚间已经好多年没有去过了，就连那些颇有创意的地名，也只能想起一个：鼻梁骨。</p><p>鼻梁骨的鼻梁上有一片野果灌木，我姨说那是“吃厘子”，以至于第一次在超市里看到“车厘子”的时候，我以为那是从荒野草丛里盗走的美味。</p><p>在我的记忆里，它算是荒野水果中的贵族，为了尝到第一颗熟透的红果，我足足等了好多年，直到那一片灌木日益茁壮，足以抚育丰满的硕果。</p><p>鼻梁骨的另一端，是惊悚的落崖，落崖上肆意地长满了各种奇珍异树，我种在花园里的红叶树，就是这个落崖上的土著。</p><p>因为鲜有人不顾性命去找落崖的麻烦，此处最壮硕的酸枣树，就生在落崖边上。中午和姨回家，瞅见了那颗挂满酸枣的酸枣王，姨停下脚步，拿起镰刀就拽走了大王的半个脑袋，我在一旁看的目瞪口呆。</p><p>当年的姨，还很年轻，会陪我把北山上的大石头拖着带回家，那真的是货真价实的红石头。姨父说，哥哥也有这样的癖好，把四处搜来的滑石用车载回家。而我呢，四处搜罗奇形怪状的风化石，让姨帮我拉回家。这样，姨家的磨盘下，就成了我的石头山。有两块石头，的确是绝精美的，去年过年的时候想找回来，可惜没寻到。</p><p>姨喜欢养花，家里全是花，“吃的买回来，吃完了就没了，花买回来还可以看呢“ 除了爱花的姨，谁也说不出这样的经典。</p><p>姨把我写过的墨迹视若珍宝，世间再也找不出第二个对我如此用心的人。哪怕是我丢弃的半张纸条，姨也会捡回来，和我确认好，生怕我弃用了不该丢的东西。而现在，自己在家里，已经塞进垃圾桶的东西从来没有心情去翻看第二遍，哪怕丢错了东西，也就认为遗失而已。</p><p>姨是一个自带浪漫的人，你能想到吗？周末的我时常赖床，叫醒我的，会是姨的清晨一吻。现在偶尔在家里赖个床，大多不会被人理会。只要屋外有人，我从来不会出去，但凡听不到其余的声响，出去呷一口桌上的饭菜，再回来继续躺着。</p><p>心灵手巧，除了姨，我再也想不出第二个更适合这个词的人，像刺绣这种精巧的东西，姨一看就会。姨会勾花，会绣花，会把剪纸塞满旧书。我脚下的某一双鞋垫，肯定出自姨的手笔，记得有一次回去，鞋子不合适，姨把自己刚做的鞋垫剪了一圈留给了我，这种毫无保留的给与和温暖，不是任何人都给得了的。</p><p>记忆里，最后一个不是一个人过得生日，肯定是在姨家过的，真的好巧，我的生日，竟然可以恰巧在姨家度过，香煎带鱼，羊肉汤。。。最大的幸福是没有孤单和虚伪，就那种自由自在，无拘无束的滋味，不是在自己家就可以轻易找到的。</p><p>每次去开一开那个近乎和我一样高的小白门，老妈说我还没有记忆的小时候，曾把手塞进了它的门缝里。</p><p>直到去年过年，从相聚到离开，不过短短的半天，那一天的我还买了零食，从小学一年级开始恋上的点心摊，竟然还在那里，只不过当年的叔叔阿姨已经有点白发苍苍。要离开时，姨站在最高的路口上送我回家，我坐在姨父的车上看见和我挥手的姨，在我的远去里变成了模糊的影子。我打那一刻，开始懂得用心画画的意义，开始懂得把生命融进画中，我想画那一副画，我想定格那一瞬间，我想让所以时光，都停留在昨天，所有我爱的人，都不会因为我的成长，而慢慢老去。</p><p>那一刻，我有多害怕离去。你能预料，哪一次离别不会成为永别？离开的是影子，关上的是门，你能料到，下一秒会发生什么？</p><p>回来的路上，哭够了眼泪，是我那一天干的事，后来妈妈上班的时候，从楼梯上看不见身影开始，我会迅速关上门，从餐厅、厨房的窗台上一直追到西面的杂物间。</p><blockquote><p>明天考研, 如果你曾做过研狗, 一路上的风景, 你懂得.<br>眼前的生活总是喜忧参半, 但消逝的过往总能充满美好。<br>想一想美好的过往, 怎舍得辜负半点当下; 往昔所有艰难都已过往, 未来又怎会无法逾越?</p></blockquote><p><img src="/medias/pic_md/Diary/RainyDay.jpg" alt="RainyDay"><br>那时的自己对自己还相当苛刻, 时常与自己过不去, 还不懂得, 宽以待己, 试着原谅自己.<br>自己经常’犯错’, 所以时常惩罚自己,<br>某一年的国庆, 早上刷了一眼建模获奖名单，没有我，意料之中，却还是略带后悔，心有不甘。<br>于是，此后的一天里，都在一发不可收拾的自责和自虐中度过，因为我没有完成既定的目标，犯了不该犯的错。<br>一个人坐在E楼404最后一排的角落里，200人的大教室里只有我一个人，确切地说，那一层，就只有我一个人。<br>窗外下着雨，没完没了地烘托着我心情，我就拍下了这张照片，希望自己永远记得这一天，记得失败之后的失落，尤其是开心到忘乎所以的时候，提醒自己尝一尝失败的滋味。<br>另一张照片是桌上的苹果，灿黄的金帅，连同桌上白色的桌布，都是我每天四处游走寻找自习室的标配。我在固定桌布的胶带上写下了这句话：沉下心来，珍惜身边的爱和温暖。<br>我懂得当时心内的滋味，被孤单沉默的味道，还有面对失败的彷徨。我唯一的对策就是沉下心来，重新面对未来。而“爱和温暖”，对我来说，从来都是稀缺的字眼，可遇而不可求的奢侈，得之我幸，失之我命。<br><img src="/medias/pic_md/Diary/Apple.jpg" alt></p><p><img src="/medias/pic_md/Diary/MyBed.jpg" alt="MyBed"><br>支教时的境况，挣扎，无奈，我行我素。<br>我不擅长处理人际关系，最致命的缺点在这段时光里崭露无遗。<br>我一个人待在一人的办公室里，度过下雪的周末，期待雪晴的日子永远不会到来。<br>为了一点委屈独自一人窝在被窝里落泪，都是在所难免的事情。<br>每天晨昏跑到屋后的篮球场上跑圈，是唯一放飞自我的时刻。<br>同一批的室友去炒大锅菜，我就端着一个小煮锅，自己给自己开小灶，那个时候的自己，就是这样的作风，受不了众口难调的麻烦，能自己解决的事情绝不会麻烦别人。<br>同住的舍友希望早休息，早于我的日常11点，直到有一天，毫无预兆地公然把我所在了门外，就有了我的地铺。<br>吃过晚饭把铺盖卷搬到实验室，学累了倒头就睡，第二天肯定是第一个醒来的人，铺盖卷就挂在晾绳上，毫无违和感。<br>第二批舍友喜欢夜生活，日常K歌秀舞晚于我的11点，我依旧住在机房里。<br>就这样，一共四个月，除了自己之外，没有人知晓谁会每天晒被褥，更不会猜到有人谁在机房里。可我就是这样，宁愿一个人孤独，也不想一起庸俗，四张小板凳就可以搭起地铺上的小蚊帐，我生来就擅长生活，可以享受锦绣华服，也不排斥布裙荆钗，没有什么是我不可面对的生活。</p><p><img src="/medias/pic_md/Diary/BaoMing.jpg" alt></p><p>考研报名的数字，那曾经是我遇见的，世界上最美丽的一串数字。</p><p>我也会永远记得，报名当天，在天桥上和妈妈吵了一架，然后把头发剪短到了极点，自己窝在宿舍里边哭边刷网页，浪费了大半天的时光，结果报名失败，晚上TT从图书馆回来，给我报的名。</p><table><thead><tr><th></th><th></th><th></th></tr></thead><tbody><tr><td><img src="/medias/pic_md/Diary/Jiudian.jpg" alt></td><td><img src="/medias/pic_md/Diary/NuanPing.jpg" alt></td><td><img src="/medias/pic_md/Diary/%E9%85%92%E5%BA%972.jpg" alt></td></tr></tbody></table><p>考研时住的宾馆，第一次住如此奢华的宾馆，第一次自己订宾馆，但仍然没有打破自己打车的特例。</p><p>和TT在一起的时候，出门考试也好，比赛也好，何时出发，怎么出发，住在哪里，从来都不用我操心，我真的是那个被朋友宠坏了的人，连下雨天，几乎不会打伞的自己，也从来不会带伞，但TT，永远会多带一把伞。</p><p>出乎意料地发现，住宾馆的那天，我竟然依旧带着标配的暖瓶，就像平时上自习一样，脚边总会放一把暖瓶，或蓝色，或粉色。</p><p>还记得第一晚，我们一起出门吃饺子，把附近的小店逛了一遍，搜罗了两天的粮草，然后回来躺在床上分享人生，遥想一起北漂的约定。</p><p>晚上的我照旧失眠，一直到凌晨一点，悄悄地出门打电话，妈妈秒接，大概是知道我逢考试必失眠地旧习，把电话放在了枕头边：“妈，我睡不着。”，我忘记了妈妈后来说了什么，但回来就睡着了，唯一后悔的是当时没有早一点打电话。</p><p>第二天回来，依旧是TT打车，到宿舍楼下，已是夜色弥漫，拖着行李箱上五楼，回到阔别了两个夜晚的宿舍，好似离开了整个世纪。打开灯才发现宿舍里空荡荡的没有一个人，打开行李箱，看到码齐的书本，刹那间泪如雨下。风里雨里，披星戴月的日子里，陪我走过四年的书本呀，突然发现有一天要和你说再见，你知道我有多留恋吗？</p><p>从那之后的三天里，没有睡过觉，和哥哥要了vip账号，看完了《漂洋过海来看你》，看完了《欢乐颂》。。。逮住了每一个可以落泪的剧情，好不吝啬地挥霍着廉价的眼泪。</p><p>三天之后下床，恍如另一个生命，开始新的生活，做的第一件事，是和大学里唯一一个暗恋过三年之久的人说了一句：我曾经爱过你。</p><p>而今，往事如梦，消逝风中，过去的不愿再提，记忆也懒得去拾起。唯一怀念的，是当时的潇洒和如今的不在乎，如此，过去的，就真的过去了。</p><h1 id="有你真好，让我所有的努力充满意义。"><a href="#有你真好，让我所有的努力充满意义。" class="headerlink" title="有你真好，让我所有的努力充满意义。"></a>有你真好，让我所有的努力充满意义。</h1><p><img src="/medias/pic_md/Diary/home.jpg" alt><br>图片是18年夏天在家拍的，母亲早上着急上班，让我把发酵好的面做成烙饼。我做了油饼和发面饼，一共8张，各有形状，我最喜欢的就是这张名副其实的手抓饼。<br>转眼间已经一年多没有回家了，偶尔也会想家，但忙起来就淡忘了。<br>我和母亲故事，足够写一本百页的小说，我们就是这样一对母女，经历着世间鲜有的生活，却依然可以幸福安逸。哪怕淡忘了跌跌撞撞的曾经，但骨子里的烙印仍然会提醒我，用心去生活，别对不起昨天的自己。<br>小时候是我坐在夕阳里数挂历，翘首期盼下一次团聚的时间，而现在，是目前不停地提醒我，别忘了买回家的火车票。从我7岁到如今的24岁，我们就像聚少离多的平行线，依靠电话和视频感受彼此的温度。<br>我知道母亲对我最大的期盼，就是一生快乐。可是我时常错解知足常乐的含义，总以为自己喜欢压力，迷恋步履匆忙的日子，习惯不轻易放过自己，也做过自己折磨自己的傻事。我会为了一个小小的比赛错过搬家，会为了几个没有做完的实验错过回家。</p><p>我今天才突然想到把所能想到的，关于母亲的一切都慢慢写下来，为了对抗遗忘，为了收藏温度，为了提醒自己懂得宠你的意义。</p><p>2020/2/11</p><p>醒来看到一条消息，好难过，突然意料到要面对我很排斥的现实。我还是老毛病，不管遇到什么，第一时间想到的是自己的过错，而不是别人的过分。</p><p>心不在焉地看着论文，正好母亲的视频弹了出来。我说我好难过。。。这一次，我才懂得，母亲的信条，就是对女儿好的都是对的，否则全是错的；我才突然预料到，偌大的世界里，也就这一个人，不分时间地点和缘由地宠着我，没有条件地信任着我。</p>]]></content>
      
      
      <categories>
          
          <category> Diary </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Touch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>世界上懂我的你</title>
      <link href="/2019/12/18/Diary/2019-12-18-%E4%B8%96%E7%95%8C%E4%B8%8A%E6%87%82%E6%88%91%E7%9A%84%E4%BD%A0/"/>
      <url>/2019/12/18/Diary/2019-12-18-%E4%B8%96%E7%95%8C%E4%B8%8A%E6%87%82%E6%88%91%E7%9A%84%E4%BD%A0/</url>
      
        <content type="html"><![CDATA[<blockquote><p>我的世界流转变化<br>你却没时差<br>啦啦啦啦 我亲爱的你呀<br>我的心事纷乱复杂<br>你却能解码<br>啦啦啦啦 我亲爱的你呀</p></blockquote><p>我们的故事应该从何说起?</p><p>从见到你第一眼起, 我还在小学里, 而后相继转学, 彼此杳无音讯.</p><p>后来, 中学合校, 我竟会在一个班里看见你. 从那时起, 做过同桌, 一起愉快地度过平凡的周末, 一起做作业, 听海风吹打窗棂的奇妙.一起回归每一个新的周一, 睡在相邻的通铺上, 听你给我讲红楼梦, 讲漂亮朋友, 讲许多许多的睡前故事, 在你乐此不疲的声音里安然入睡. 我们 一起去过我阔别了十多年的老地方, 那是我一个人永远没有勇气和理由回去的地方, 我们看过珍珠鸡, 赏过小鸳鸯, 你送给了我唯一一根孔雀毛, 也是我此生第一次见到货真价实的孔雀毛;  调皮的我们还捡过河蚌, 那是我此生第一次, 也是迄今为止唯一一次尝过如此独特的美味. 我们偷偷爬过人家的杏花树, 在桃花林中寻找春天的味道. </p><p>后来, 我们在一个高中里, 一起开学, 一起去找新的班级和宿舍, 一起开始新的生活. 受了委屈的我, 还会跑到楼上, 和你哭大半个早上.  可你知道吗? 除你之外, 和我从初中到高中的同学, 还没有第二个人见过我的眼泪, 我爱哭, 但很少卸下铠甲真的哭出来.</p><p>后来, 我们一起上大学了, 分别去了不同的地方, 匆忙的四年里, 我别无选择, 若无其事地过着只有自己可以承受的生活, 我知道你的闪耀时刻, 你清楚我奋斗过的旅程, 比我自己更清楚自己, 直到你说我曾一天学习过14h, oh my god, 那是我吗?<br>幸运如我们, 经历了不同的雕琢, 我们有了近乎同样的色彩, 我崇拜那个满身灿烂的你, 那个四年里一直拿第一的你, 不管是成绩还是各种比赛.</p><p>后来, 我们怎么可以如此同步? 我们一起走过支教生活, 只不过我在山东,你在南疆; 我们一起进过辅导班, 你教语文, 我教化学;  但那个把各种offer拿到手软的你呀, 还能让我再仰望一些吗? 我在偷偷自恋, 此生怎可以如此幸运, 天上掉下个天才, 恰巧落到我身边.</p><p>你知道吗? 我从来不敢奢望的, 不敢奢望能有一个陪我走过大半生的你.<br>此生无数波折和转折, 来来回回没有固定的居所. 而我们, 却可以兜兜转转走到一起. 我该如何去感谢上苍的厚爱, 感谢会陪我走完余生的你.</p><p>我们从小学就在一起耶, 天下几人能有此番幸运?<br>而你知道我所有的经历, 无需回忆; 懂我每一个决定, 无需解释.</p><p>其实大学四年里, 我们几乎没有联系的对吗? 纵使经历了不同的风雨,  但我们从未有过时差.<br>回想这过去的半年里,<br>我在操场的屋顶上, 和你说我想要的未来; 在宿舍的走廊里, 和你说我暗恋的他, 满心欢喜听你说我的傻里傻气; 和你在中心花园里, 说我到底有多爱无情的他, 说我会在沉默里爱他直到十年以后. 和你在中教一层, 絮絮叨叨, 没完没了, 有说有笑, 消磨大半个晚上.<br>我们会想起旧时的同窗, 现在大都别番模样, 而我们却和当初一样.<br>我们会期许一个美好的未来, 隐居在荒山野林中, 一起开车出去兜风.<br>那个倔强而又优秀的你呀, 总能在自己的小圈子里做到最好, 就像水到渠成, 无需刻意, 毫不费力.</p><p>我喜欢灿若星辰的你, 带我一起优秀; 喜欢和你聊天时的自己, 轻松自在, 无所顾忌; 喜欢有你的我, 此生不会惧怕孤单, 回家不会百无聊赖, 你知道吗? 你会成为我回家的动力. 如果我妈看到我的偏心和执拗, 不知道会不会吃醋, 她养了20多年的女儿, 好似无牵无挂的过客. 如果我回家后还会一个人孤单, 还会一个人散步, 还会一个人把眼泪留给剧情, 总可以去找你, 看一看不一样的世界.</p><p>你一定知道我是写给你的, 歌词是你告诉我的, 我们刚刚通过电话.<br>我心疼和我一样倔强而又不服输的你, 知道你此刻仍然在寒夜里苦读, 所以我捧起书本, 去了自己该去的地方, 陪你一起感受奋斗的力量.<br>我等你, 等你来到我身边, 我会陪你走一走我疯跑过的操场, 指着9楼上的一扇窗告诉你, 看那个像城堡的地方, 我会每晚9点出现在那里, 一点一点靠近我的梦想, 拥抱我们想要的未来.</p>]]></content>
      
      
      <categories>
          
          <category> Diary </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Love </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Python读写pdf：茫茫辞海里，寻找我想要的你</title>
      <link href="/2019/12/09/Tools/2019-12-9-Python%E8%AF%BB%E5%86%99pdf%EF%BC%9A%E8%8C%AB%E8%8C%AB%E8%BE%9E%E6%B5%B7%E9%87%8C%EF%BC%8C%E5%AF%BB%E6%89%BE%E6%88%91%E6%83%B3%E8%A6%81%E7%9A%84%E4%BD%A0/"/>
      <url>/2019/12/09/Tools/2019-12-9-Python%E8%AF%BB%E5%86%99pdf%EF%BC%9A%E8%8C%AB%E8%8C%AB%E8%BE%9E%E6%B5%B7%E9%87%8C%EF%BC%8C%E5%AF%BB%E6%89%BE%E6%88%91%E6%83%B3%E8%A6%81%E7%9A%84%E4%BD%A0/</url>
      
        <content type="html"><![CDATA[<h3 id="缘起"><a href="#缘起" class="headerlink" title="缘起"></a>缘起</h3><p>需要从某个顶会的pdf论文集中寻找和自己研究方向相关的论文，但是挨个pdf去ctrl+F太浪费生命了。我们尽量用最快捷的办法，解决低秩繁琐的事情，能让程序做的事情，拒绝暴力手工。<br>流程：按照关键词搜索并保存相关页面，这样，我可以顺便读一下摘要，筛选真正想读的论文。</p><h2 id="安装依赖包"><a href="#安装依赖包" class="headerlink" title="安装依赖包"></a>安装依赖包</h2><p>pdfminer3k读取pdf</p><pre class=" language-python"><code class="language-python">pip install pdfminer3k</code></pre><p>PyPDF2保存pdf</p><pre class=" language-python"><code class="language-python">pip install PyPDF2</code></pre><h2 id="走起我的小程序"><a href="#走起我的小程序" class="headerlink" title="走起我的小程序"></a>走起我的小程序</h2><pre class=" language-python"><code class="language-python"><span class="token keyword">from</span> pdfminer<span class="token punctuation">.</span>pdfinterp <span class="token keyword">import</span> PDFResourceManager<span class="token punctuation">,</span> PDFPageInterpreter<span class="token keyword">from</span> pdfminer<span class="token punctuation">.</span>converter <span class="token keyword">import</span> PDFPageAggregator<span class="token keyword">from</span> pdfminer<span class="token punctuation">.</span>layout <span class="token keyword">import</span> LAParams<span class="token keyword">from</span> pdfminer<span class="token punctuation">.</span>pdfdevice <span class="token keyword">import</span> PDFDevice<span class="token keyword">from</span> pdfminer<span class="token punctuation">.</span>pdfparser <span class="token keyword">import</span> PDFParser<span class="token punctuation">,</span> PDFDocument<span class="token keyword">from</span> PyPDF2 <span class="token keyword">import</span> PdfFileReader<span class="token punctuation">,</span> PdfFileWriter<span class="token keyword">import</span> re<span class="token keyword">import</span> os<span class="token keyword">import</span> time<span class="token keyword">def</span> <span class="token function">PDFseeker</span><span class="token punctuation">(</span>fileName<span class="token punctuation">,</span>savedName<span class="token punctuation">,</span>keyWord<span class="token punctuation">)</span><span class="token punctuation">:</span>    pattern <span class="token operator">=</span> re<span class="token punctuation">.</span>compile<span class="token punctuation">(</span>keyWord<span class="token punctuation">)</span><span class="token comment" spellcheck="true">#解析目标关键词</span>    fp<span class="token operator">=</span>open<span class="token punctuation">(</span>fileName<span class="token punctuation">,</span><span class="token string">"rb"</span><span class="token punctuation">)</span>    parser<span class="token operator">=</span>PDFParser<span class="token punctuation">(</span>fp<span class="token punctuation">)</span><span class="token comment" spellcheck="true">#创建一个与文档关联的解释器</span>    doc<span class="token operator">=</span>PDFDocument<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#PDf文档的对象</span>    resource<span class="token operator">=</span>PDFResourceManager<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#创建PDF资源管理器</span>    laparam<span class="token operator">=</span>LAParams<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#参数分析器</span>    device<span class="token operator">=</span>PDFPageAggregator<span class="token punctuation">(</span>resource<span class="token punctuation">,</span>laparams<span class="token operator">=</span>laparam<span class="token punctuation">)</span><span class="token comment" spellcheck="true">#创建一个聚合器</span>    interpreter<span class="token operator">=</span>PDFPageInterpreter<span class="token punctuation">(</span>resource<span class="token punctuation">,</span>device<span class="token punctuation">)</span><span class="token comment" spellcheck="true">#创建PDF页面解释器</span>    <span class="token comment" spellcheck="true">#链接解释器和文档对象</span>    parser<span class="token punctuation">.</span>set_document<span class="token punctuation">(</span>doc<span class="token punctuation">)</span>    doc<span class="token punctuation">.</span>set_parser<span class="token punctuation">(</span>parser<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">#抓取目标页面</span>    pageindex <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    i <span class="token operator">=</span> <span class="token number">0</span>    <span class="token keyword">for</span> page <span class="token keyword">in</span> doc<span class="token punctuation">.</span>get_pages<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token comment" spellcheck="true">#处理每一页</span>        interpreter<span class="token punctuation">.</span>process_page<span class="token punctuation">(</span>page<span class="token punctuation">)</span><span class="token comment" spellcheck="true">#使用页面解释器来读取</span>        layout <span class="token operator">=</span> device<span class="token punctuation">.</span>get_result<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#使用聚合器来获得内容</span>        <span class="token keyword">for</span> out <span class="token keyword">in</span> layout<span class="token punctuation">:</span>            <span class="token keyword">if</span> hasattr<span class="token punctuation">(</span>out<span class="token punctuation">,</span> <span class="token string">'get_text'</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token comment" spellcheck="true">#鉴于PDF既有text也有图片等等，为了确保不出错先判断对象是否具有 get_text()方法</span>                <span class="token keyword">if</span> pattern<span class="token punctuation">.</span>search<span class="token punctuation">(</span>out<span class="token punctuation">.</span>get_text<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>                    pageindex<span class="token punctuation">.</span>append<span class="token punctuation">(</span>i<span class="token punctuation">)</span>        i <span class="token operator">+=</span> <span class="token number">1</span>    <span class="token comment" spellcheck="true">#保存目标页面</span>    <span class="token keyword">if</span> len<span class="token punctuation">(</span>pageindex<span class="token punctuation">)</span> <span class="token operator">></span> <span class="token number">0</span><span class="token punctuation">:</span>        pdfWriter <span class="token operator">=</span> PdfFileWriter<span class="token punctuation">(</span><span class="token punctuation">)</span>        pdfReader <span class="token operator">=</span> PdfFileReader<span class="token punctuation">(</span>fp<span class="token punctuation">)</span>        <span class="token keyword">for</span> j <span class="token keyword">in</span> pageindex<span class="token punctuation">:</span><span class="token comment" spellcheck="true">#获取pdf共用多少页</span>            pdfWriter<span class="token punctuation">.</span>addPage<span class="token punctuation">(</span>pdfReader<span class="token punctuation">.</span>getPage<span class="token punctuation">(</span>j<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">#将一个 PageObject 加入到 PdfFileWriter</span>        final_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>savedName<span class="token punctuation">)</span>        <span class="token keyword">with</span> open<span class="token punctuation">(</span>final_path<span class="token punctuation">,</span> <span class="token string">"wb"</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>            pdfWriter<span class="token punctuation">.</span>write<span class="token punctuation">(</span>f<span class="token punctuation">)</span>    <span class="token keyword">else</span><span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span>keyWord<span class="token punctuation">,</span><span class="token string">'is not found in'</span><span class="token punctuation">,</span>fileName<span class="token punctuation">)</span>    fp<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>    start_time <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>    fileName <span class="token operator">=</span> <span class="token string">"./Test.pdf"</span>      savedName <span class="token operator">=</span> <span class="token string">"./final.pdf"</span>     keyWord <span class="token operator">=</span> <span class="token string">"Huiyu Li"</span>     PDFseeker<span class="token punctuation">(</span>fileName<span class="token punctuation">,</span> savedName<span class="token punctuation">,</span> keyWord<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Time {:.3f} min'</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span><span class="token punctuation">(</span>time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span> start_time<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">60</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>time<span class="token punctuation">.</span>strftime<span class="token punctuation">(</span><span class="token string">'%Y/%m/%d-%H:%M:%S'</span><span class="token punctuation">,</span> time<span class="token punctuation">.</span>localtime<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre>]]></content>
      
      
      <categories>
          
          <category> Tools </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
            <tag> PDF </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>The Conference and Journal of Medical Image</title>
      <link href="/2019/12/04/Medical%20Image/The%20Conference%20and%20Journal%20of%20Medical%20Image/"/>
      <url>/2019/12/04/Medical%20Image/The%20Conference%20and%20Journal%20of%20Medical%20Image/</url>
      
        <content type="html"><![CDATA[<h1 id="Conference"><a href="#Conference" class="headerlink" title="Conference"></a>Conference</h1><h2 id="Conference-Submission-Calendar"><a href="#Conference-Submission-Calendar" class="headerlink" title="Conference Submission Calendar"></a>Conference Submission Calendar</h2><table><thead><tr><th>Month</th><th>Conference</th></tr></thead><tbody><tr><td>January</td><td><strong>ICML</strong>, <strong>ECML</strong>, <strong>IJCAI</strong></td></tr><tr><td>February</td><td><strong>MIDL</strong></td></tr><tr><td>March</td><td><strong>MICCAI</strong>, <strong>ICCV</strong>, ECCV</td></tr><tr><td>April</td><td></td></tr><tr><td>May</td><td></td></tr><tr><td>Jun</td><td></td></tr><tr><td>July</td><td>ACCV</td></tr><tr><td>August</td><td></td></tr><tr><td>September</td><td><strong>AAAI</strong>, <strong>ICLR</strong></td></tr><tr><td>October</td><td><strong>ISBI</strong></td></tr><tr><td>November</td><td><strong>CVPR</strong></td></tr><tr><td>December</td><td><strong>IPMI</strong></td></tr></tbody></table><h2 id="Conference-Reading-Calendar"><a href="#Conference-Reading-Calendar" class="headerlink" title="Conference Reading Calendar"></a>Conference Reading Calendar</h2><table><thead><tr><th>January</th><th>February</th><th>March</th><th>April</th><th>May</th><th>Jun</th></tr></thead><tbody><tr><td></td><td><strong>CVPR</strong>, <strong>AAAI</strong></td><td><strong>IPMI</strong></td><td><strong>ISBI</strong></td><td><strong>ICLR</strong></td><td></td></tr><tr><td><strong>July</strong></td><td><strong>August</strong></td><td><strong>September</strong></td><td><strong>October</strong></td><td><strong>November</strong></td><td><strong>December</strong></td></tr><tr><td><strong>ICML</strong></td><td>ECCV, <strong>MIDL</strong>,<strong>IJCAI</strong></td><td><strong>ECML</strong></td><td><strong>MICCAI</strong>, <strong>ICCV</strong></td><td>ACCV</td><td><strong>NeurIPS</strong></td></tr></tbody></table><h2 id="Level-1"><a href="#Level-1" class="headerlink" title="Level 1"></a>Level 1</h2><h4 id="IPMI-Information-Processing-in-Medical-Imaging"><a href="#IPMI-Information-Processing-in-Medical-Imaging" class="headerlink" title="IPMI (Information Processing in Medical Imaging)"></a>IPMI (Information Processing in Medical Imaging)</h4><p>顶级会议，两年召开一次，nature，science级别，一个非常小圈子的会。</p><h4 id="MICCAI-International-Conference-on-Medical-Image-Computing-and-Computer-Assisted-Intervention"><a href="#MICCAI-International-Conference-on-Medical-Image-Computing-and-Computer-Assisted-Intervention" class="headerlink" title="MICCAI (International Conference on Medical Image Computing and Computer Assisted Intervention)"></a>MICCAI (International Conference on Medical Image Computing and Computer Assisted Intervention)</h4><p>顶尖年会，接受论文较多，长文被SCI收录，短文不被SCI收录，Springer出版。</p><h4 id="ICML"><a href="#ICML" class="headerlink" title="ICML"></a>ICML</h4><p>CCF A, 机器学习方面最好的会议之一. 现在是IMLS主办, 每年举行. </p><h4 id="ECML"><a href="#ECML" class="headerlink" title="ECML"></a>ECML</h4><p>机器学习方面仅次于ICML的会议, 欧洲人极力捧场</p><h4 id="CVPR-Computer-Vision-and-Pattern-Recognition"><a href="#CVPR-Computer-Vision-and-Pattern-Recognition" class="headerlink" title="CVPR (Computer Vision and Pattern Recognition)"></a>CVPR (Computer Vision and Pattern Recognition)</h4><p>CCF A, CV顶会，有一个专题为Medical Image Analysis，基于图像分析的思路处理三维医学图像的特别有意义的结果可以投这个会议，EI收录。### ECCV (European Conference on Computer Vision)</p><h4 id="ICCV-（IEEE-International-Conference-on-Computer-Vision）"><a href="#ICCV-（IEEE-International-Conference-on-Computer-Vision）" class="headerlink" title="ICCV （IEEE International Conference on Computer Vision）"></a>ICCV （IEEE International Conference on Computer Vision）</h4><p>CCF A, CV顶会，EI收录。三维医学图像分析的很好结果可以投这个会议。</p><h4 id="AAAI"><a href="#AAAI" class="headerlink" title="AAAI"></a>AAAI</h4><p>CCF A, 美国人工智能学会AAAI的年会。</p><h4 id="ISBI-International-Symposium-on-Biomedical-Imaging"><a href="#ISBI-International-Symposium-on-Biomedical-Imaging" class="headerlink" title="ISBI (International Symposium on Biomedical Imaging)"></a>ISBI (International Symposium on Biomedical Imaging)</h4><p>新贵，oral talk的会议录用率在20%左右.</p><h4 id="MIDL-Medical-Imaging-with-Deep-Learning"><a href="#MIDL-Medical-Imaging-with-Deep-Learning" class="headerlink" title="MIDL (Medical Imaging with Deep Learning)"></a>MIDL (Medical Imaging with Deep Learning)</h4><h4 id="ICLR-International-Conference-on-Learning-Representations"><a href="#ICLR-International-Conference-on-Learning-Representations" class="headerlink" title="ICLR (International Conference on Learning Representations)"></a>ICLR (International Conference on Learning Representations)</h4><p>（国际学习表征会议），2013 年才刚刚成立了第一届。被认为「深度学习的顶级会议」</p><h4 id="NeurIPS"><a href="#NeurIPS" class="headerlink" title="NeurIPS"></a>NeurIPS</h4><p>CCF A, 神经计算方面最好的会议之一,  每年举行。</p><h4 id="IJCAI"><a href="#IJCAI" class="headerlink" title="IJCAI"></a>IJCAI</h4><p>CCF A, AI最好的综合性会议, 1969年开始, 每两年开一次, 奇数年开. </p><h1 id="Journal"><a href="#Journal" class="headerlink" title="Journal"></a>Journal</h1><h2 id="Level-1-1"><a href="#Level-1-1" class="headerlink" title="Level 1"></a>Level 1</h2><h4 id="MIA-Medical-Image-Analysis"><a href="#MIA-Medical-Image-Analysis" class="headerlink" title="MIA (Medical Image Analysis)"></a>MIA (Medical Image Analysis)</h4><p>计算机1区, 医学2区, 平均5.0个月</p><h4 id="IEEE-TMI（IEEE-Transactions-on-Medical-Imaging）"><a href="#IEEE-TMI（IEEE-Transactions-on-Medical-Imaging）" class="headerlink" title="IEEE TMI（IEEE Transactions on Medical Imaging）"></a>IEEE TMI（IEEE Transactions on Medical Imaging）</h4><p>医学图像处理顶级的杂志,生物医学图像。<br>平均审稿速度： 5.4个月；平均录用比例：很难</p><h4 id="TPAMI"><a href="#TPAMI" class="headerlink" title="TPAMI"></a>TPAMI</h4><p>CCF A,计算机视觉及模式识别领域最顶尖的SCI期刊</p><h4 id="Nature-Reviews-Cardiology"><a href="#Nature-Reviews-Cardiology" class="headerlink" title="Nature Reviews Cardiology"></a>Nature Reviews Cardiology</h4><h4 id="Cancer-Research"><a href="#Cancer-Research" class="headerlink" title="Cancer Research"></a>Cancer Research</h4><h4 id="Radiology"><a href="#Radiology" class="headerlink" title="Radiology"></a>Radiology</h4><h4 id="Proceedings-of-the-IEEE"><a href="#Proceedings-of-the-IEEE" class="headerlink" title="Proceedings of the IEEE"></a>Proceedings of the IEEE</h4><h4 id="Foundations-of-Computational-Mathematics"><a href="#Foundations-of-Computational-Mathematics" class="headerlink" title="Foundations of Computational Mathematics"></a>Foundations of Computational Mathematics</h4><h4 id="Journal-of-Thoracic-Oncology"><a href="#Journal-of-Thoracic-Oncology" class="headerlink" title="Journal of Thoracic Oncology"></a>Journal of Thoracic Oncology</h4><h4 id="European-Journal-of-Nuclear-Medicine-and-Molecular-Imaging"><a href="#European-Journal-of-Nuclear-Medicine-and-Molecular-Imaging" class="headerlink" title="European Journal of Nuclear Medicine and Molecular Imaging"></a>European Journal of Nuclear Medicine and Molecular Imaging</h4><h2 id="Level-2"><a href="#Level-2" class="headerlink" title="Level 2"></a>Level 2</h2><h4 id="NeuroImage-sci2"><a href="#NeuroImage-sci2" class="headerlink" title="NeuroImage_sci2"></a>NeuroImage_sci2</h4><h4 id="Neurocomputing-sci2"><a href="#Neurocomputing-sci2" class="headerlink" title="Neurocomputing_sci2"></a>Neurocomputing_sci2</h4><h4 id="European-Radiology-sci2"><a href="#European-Radiology-sci2" class="headerlink" title="European Radiology_sci2"></a>European Radiology_sci2</h4><h4 id="Frontiers-in-Cardiovascular-Medicine-sci2"><a href="#Frontiers-in-Cardiovascular-Medicine-sci2" class="headerlink" title="Frontiers in Cardiovascular Medicine_sci2"></a>Frontiers in Cardiovascular Medicine_sci2</h4><h4 id="Cancers-sci2"><a href="#Cancers-sci2" class="headerlink" title="Cancers_sci2"></a>Cancers_sci2</h4><h4 id="Heart-Rhythm-sci2"><a href="#Heart-Rhythm-sci2" class="headerlink" title="Heart Rhythm_sci2"></a>Heart Rhythm_sci2</h4><h4 id="Journal-of-Neurosurgery-sci2"><a href="#Journal-of-Neurosurgery-sci2" class="headerlink" title="Journal of Neurosurgery_sci2"></a>Journal of Neurosurgery_sci2</h4><h4 id="IEEE-Transactions-on-Biomedical-Engineering-sci2-3"><a href="#IEEE-Transactions-on-Biomedical-Engineering-sci2-3" class="headerlink" title="IEEE Transactions on Biomedical Engineering_sci2_3"></a>IEEE Transactions on Biomedical Engineering_sci2_3</h4><h4 id="IEEE-Journal-of-Biomedical-and-Health-Informatics-sci2"><a href="#IEEE-Journal-of-Biomedical-and-Health-Informatics-sci2" class="headerlink" title="IEEE Journal of Biomedical and Health Informatics_sci2"></a>IEEE Journal of Biomedical and Health Informatics_sci2</h4><h4 id="IEEE-journal-of-translational-engineering-in-health-and-medicine-sci2"><a href="#IEEE-journal-of-translational-engineering-in-health-and-medicine-sci2" class="headerlink" title="IEEE journal of translational engineering in health and medicine_sci2"></a>IEEE journal of translational engineering in health and medicine_sci2</h4><h4 id="Statistics-and-Computing-sci2"><a href="#Statistics-and-Computing-sci2" class="headerlink" title="Statistics and Computing_sci2"></a>Statistics and Computing_sci2</h4><h4 id="ACM-Transactions-on-Graphics-sci2"><a href="#ACM-Transactions-on-Graphics-sci2" class="headerlink" title="ACM Transactions on Graphics_sci2"></a>ACM Transactions on Graphics_sci2</h4><h1 id="Useful-Links"><a href="#Useful-Links" class="headerlink" title="Useful Links:"></a>Useful Links:</h1><h4 id="Top-Conferences-By-Deadlines"><a href="#Top-Conferences-By-Deadlines" class="headerlink" title="Top Conferences By Deadlines"></a><a href="https://www.guide2research.com/topconf/" target="_blank" rel="noopener">Top Conferences By Deadlines</a></h4><h4 id="Top-Journals-with-Impact-Factor"><a href="#Top-Journals-with-Impact-Factor" class="headerlink" title="Top Journals with Impact Factor"></a><a href="https://www.guide2research.com/special-issues/" target="_blank" rel="noopener">Top Journals with Impact Factor</a></h4><h4 id="Top-1000-Scientist-for-Computer-Science"><a href="#Top-1000-Scientist-for-Computer-Science" class="headerlink" title="Top 1000 Scientist  for Computer Science"></a><a href="https://www.guide2research.com/scientists/" target="_blank" rel="noopener">Top 1000 Scientist  for Computer Science</a></h4><h4 id="University-Ranking-for-Computer-Science"><a href="#University-Ranking-for-Computer-Science" class="headerlink" title="University Ranking for Computer Science"></a><a href="https://www.guide2research.com/ranking/" target="_blank" rel="noopener">University Ranking for Computer Science</a></h4>]]></content>
      
      
      <categories>
          
          <category> Medical Image </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Conference and Journal </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>常用的医学图像阅读器</title>
      <link href="/2019/12/01/Tools/2019-12-1-%E5%B8%B8%E7%94%A8%E7%9A%84%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F%E6%B5%8F%E8%A7%88%E5%99%A8/"/>
      <url>/2019/12/01/Tools/2019-12-1-%E5%B8%B8%E7%94%A8%E7%9A%84%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F%E6%B5%8F%E8%A7%88%E5%99%A8/</url>
      
        <content type="html"><![CDATA[<h1 id="RadiAnt"><a href="#RadiAnt" class="headerlink" title="RadiAnt"></a><a href="https://www.radiantviewer.com/en/" target="_blank" rel="noopener">RadiAnt</a></h1><p>中文主页：<a href="http://www.radiantviewer.com/zh/。" target="_blank" rel="noopener">http://www.radiantviewer.com/zh/。</a></p><p>专业的<strong>DICOM阅读器</strong>, 灵活、简单、快速, 读入CT图片后可以自动调节窗宽窗位.</p><h1 id="ITKsnap"><a href="#ITKsnap" class="headerlink" title="ITKsnap"></a><a href="http://www.itksnap.org/pmwiki/pmwiki.php" target="_blank" rel="noopener">ITKsnap</a></h1><p>相较于RadiAnt, ITKsnap可以识别多种类型的医学图像, 可以进行病灶的勾画和标注.</p><p>官网有详细的<a href="http://www.itksnap.org/pmwiki/pmwiki.php?n=Documentation.SNAP3" target="_blank" rel="noopener">配套教程</a>.</p>]]></content>
      
      
      <categories>
          
          <category> Tools </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Medical Image </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Distance Transform</title>
      <link href="/2019/11/29/Knowledge/2019-11-29-Distance-Map/"/>
      <url>/2019/11/29/Knowledge/2019-11-29-Distance-Map/</url>
      
        <content type="html"><![CDATA[<p>写在前面：近几天研究处于卡壳状态，疯狂地Coding，无奈的失败。。。<br>感觉老师说得特别对。一项研究开始之前，要不断地思考，先明确它的物理意义，然后再去动手实现。而不是像我这样，不管三七二十一，先去实现，结果不好，废铜烂铁。<br>一场有深度，有价值的思考，可以给自己接下来的实验省去许多不必要的麻烦。一个新的想法，如果理论上说不通，基本上没什么存活的意义。遇事多问为什么？<br>我为什么要这这样做？<br>它的作用是什么？<br>它的物理意义是什么？</p><h1 id="Distance-Transform"><a href="#Distance-Transform" class="headerlink" title="Distance Transform"></a>Distance Transform</h1><p>先了解一下什么是Distance Transform？它的物理意是什么？<br><a href="https://blog.csdn.net/weixin_44058333/article/details/100186066" target="_blank" rel="noopener">Distance transform(距离变换)</a></p><h1 id="Matlab-计算Distance-Transform"><a href="#Matlab-计算Distance-Transform" class="headerlink" title="Matlab 计算Distance Transform"></a>Matlab 计算Distance Transform</h1><p>bwdist()会将前景置零，计算背景像素点的Distance Transform。</p><pre class=" language-malab"><code class="language-malab">input = [[0,1,1,1,1,0];         [0,1,1,1,1,0];         [0,0,0,1,1,0];         [0,0,0,1,1,0];         [0,0,0,1,1,0]];output = bwdist(input);disp(output);</code></pre><p>output：默认计算背景的Distance Transform</p><blockquote><p>1.0000         0         0         0         0    1.0000<br>1.0000         0         0         0         0    1.0000<br>1.4142    1.0000    1.0000         0         0    1.0000<br>2.2361    2.0000    1.0000         0         0    1.0000<br>3.0000    2.0000    1.0000         0         0    1.0000</p></blockquote><h1 id="Python-计算Distance-Transform"><a href="#Python-计算Distance-Transform" class="headerlink" title="Python 计算Distance Transform"></a>Python 计算Distance Transform</h1><p><a href="https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.ndimage.morphology.distance_transform_edt.html" target="_blank" rel="noopener">distance_transform_edt</a>会将背景置零，计算前景的Distance Transform（和matlab的计算结果正好相反）。使用np.logical_not()可以得到前景的Distance Transform。</p><pre class=" language-pytho"><code class="language-pytho">from scipy.ndimage import distance_transform_edtimport numpy as npimport matplotlib.pyplot as pltinput = np.array([[0,1,1,1,1,0],                   [0,1,1,1,1,0],                   [0,0,0,1,1,0],                   [0,0,0,1,1,0],                   [0,0,0,1,1,0]])out0 = distance_transform_edt(np.logical_not(input))out1 = distance_transform_edt(input)print(out0)print(out1)</code></pre><p>out0:背景的Distance Transform</p><blockquote><p>[[1.         0.         0.         0.         0.         1.        ]<br>[1.         0.         0.         0.         0.         1.        ]<br>[1.41421356 1.         1.         0.         0.         1.        ]<br>[2.23606798 2.         1.         0.         0.         1.        ]<br>[3.         2.         1.         0.         0.         1.        ]]</p></blockquote><p>out1:默认计算前景的Distance Transform</p><blockquote><p>[[0.         1.         2.         2.         1.         0.        ]<br>[0.         1.         1.         1.41421356 1.         0.        ]<br>[0.         0.         0.         1.         1.         0.        ]<br>[0.         0.         0.         1.         1.         0.        ]<br>[0.         0.         0.         1.         1.         0.        ]]</p></blockquote><p>out0+out1</p><blockquote><p>[[1.         1.         2.         2.         1.         1.        ]<br>[1.         1.         1.         1.41421356 1.         1.        ]<br>[1.41421356 1.         1.         1.         1.         1.        ]<br>[2.23606798 2.         1.         1.         1.         1.        ]<br>[3.         2.         1.         1.         1.         1.        ]]</p></blockquote><table><thead><tr><th><img src="/medias/pic_md/Knowledge/DistanceMap2.png" alt="binaryMap"></th><th><img src="/medias/pic_md/Knowledge/DistanceMap3.png" alt="binaryMap"></th></tr></thead><tbody><tr><td></td><td></td></tr></tbody></table><p>综上，前景和背景的Distance Transform不可共存，到底选用哪一款，当然看你的实验需要。</p>]]></content>
      
      
      <categories>
          
          <category> Knowledge </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Distance Transform </tag>
            
            <tag> Matlab </tag>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Activation and Loss</title>
      <link href="/2019/11/28/MyResearch/2019-11-28-Activation,%20Label%20and%20Loss/"/>
      <url>/2019/11/28/MyResearch/2019-11-28-Activation,%20Label%20and%20Loss/</url>
      
        <content type="html"><![CDATA[<p>应用场景：医学图像的分割<br>分割结果由神经网络给出，所以，神经网络的最后一层决定了输出的特性。</p><h2 id="激活函数"><a href="#激活函数" class="headerlink" title="激活函数"></a>激活函数</h2><p>此处先介绍三组具有代表性的激活函数：</p><table><thead><tr><th>$$Softmax(x_i) = \frac{exp(x_i)}{\sum\nolimits_jexp(x_j)}$$</th><th>$$Sigmoid(x) = \frac{1}{1+exp(-x)}$$</th></tr></thead><tbody><tr><td></td><td><img src="/medias/pic_md/MyResearch/Sigmoid.png" width="200" hegiht="100" align="center"></td></tr></tbody></table><table><thead><tr><th>$$ReLU(x) = max(0,x)$$</th><th>PReLU</th></tr></thead><tbody><tr><td><img src="/medias/pic_md/MyResearch/Relu.jpg" width="200" hegiht="100" align="center"></td><td><img src="/medias/pic_md/MyResearch/PRelu.jpg" width="200" hegiht="100" align="center"></td></tr></tbody></table><table><thead><tr><th>Tanh</th><th>HardTanh</th><th>SoftShrink</th><th>TanhShrink</th></tr></thead><tbody><tr><td><img src="/medias/pic_md/MyResearch/Tanh.jpg" width="200" hegiht="100" align="center"></td><td><img src="/medias/pic_md/MyResearch/Hardtanh.png" width="200" hegiht="100" align="center/"></td><td><img src="/medias/pic_md/MyResearch/SoftShrink.jpg" width="200" hegiht="100" align="center"></td><td><img src="/medias/pic_md/MyResearch/TanhShrink.jpg" width="200" hegiht="100" align="center"></td></tr></tbody></table><h1 id="Loss"><a href="#Loss" class="headerlink" title="Loss"></a>Loss</h1><h2 id="Regression-Segmentation"><a href="#Regression-Segmentation" class="headerlink" title="Regression Segmentation"></a>Regression Segmentation</h2><h3 id="1-L1-Loss"><a href="#1-L1-Loss" class="headerlink" title="1. L1 Loss"></a>1. L1 Loss</h3><p>$${L_1} = \left| {p - g} \right|$$</p><h3 id="2-smooth-L1-Loss"><a href="#2-smooth-L1-Loss" class="headerlink" title="2. smooth L1 Loss"></a>2. smooth L1 Loss</h3><p>$$Smooth\ {L_1} = \left{ {\begin{array}{*{20}{c}}<br>{0.5{x^2},\ \left|x \right| &lt; 1}\<br>{\left| x \right| - 0.5,\ x &lt;  - 1\ or\ x &gt; 1}<br>\end{array}} \right.$$</p><h3 id="3-L2-loss"><a href="#3-L2-loss" class="headerlink" title="3. L2 loss"></a>3. L2 loss</h3><p>$${L_2} = {\left| {p - g} \right|^2}$$</p><h3 id="4-Ridge-regression"><a href="#4-Ridge-regression" class="headerlink" title="4. Ridge regression"></a>4. Ridge regression</h3><p>$$Rige = MSE(p,g;\theta ) + \alpha \frac{1}{2}\sum\nolimits_i {\theta _i^2} $$</p><h3 id="5-LASSO"><a href="#5-LASSO" class="headerlink" title="5. LASSO"></a>5. LASSO</h3><p>$$LASSO = MSE(p,g;\theta ) + \alpha \sum\nolimits_i {\left| {\theta _i} \right|}$$</p><p>参考：<br><a href="https://blog.csdn.net/weixin_44058333/article/details/103205940" target="_blank" rel="noopener">L1 loss VS L2 loss； L1 regularization VS L2 regularization</a></p>]]></content>
      
      
      <categories>
          
          <category> MyResearch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Segmentation </tag>
            
            <tag> Regression </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>玉言又止</title>
      <link href="/2019/11/27/Diary/2019-11-27-%E7%8E%89%E8%A8%80%E5%8F%88%E6%AD%A2/"/>
      <url>/2019/11/27/Diary/2019-11-27-%E7%8E%89%E8%A8%80%E5%8F%88%E6%AD%A2/</url>
      
        <content type="html"><![CDATA[<p>往昔太美好，让我舍不得去辜负。<br>我从未预料到，写日记，会成为我一生的习惯；写博客，会成为此生最美好的事情。<br>文字，作为最能穿透心灵的载体，帮我收藏了险些被遗忘的过往，也收录了我过去的跌跌撞撞。<br>重读曾经的日记，回首远去的曾经，我在和昨天共舞的同时，重拾勇气和动力。</p><blockquote><p>只有经历过美好，才知道幸福的样子</p></blockquote><blockquote><p>我爱Ta, 是因为Ta没有那么简单；比翼齐飞的陪伴，让昨日变得无比留恋。</p><p>因为有你，我想遇见更好的自己。</p></blockquote><blockquote><p>当我有了在意的人和事，整个世界都变得轻快明亮了。因为我有足够的勇气去忽略无关紧要，可以目标明确地去聚焦，也有足够的胆量去保卫我的疆域。</p><p>Ta也许是一个人，也许是一件事，也许是我窗台上的玫瑰，予我多年陪伴的仙人掌，我守护多年的花园。。。只因独一无二的存在，刻骨铭心的陪伴，让原本平凡的日子变得无与伦比。</p></blockquote><blockquote><p>只要心是明朗的，所见之处阳光满溢。</p></blockquote><p>这里写下的，都是某个时刻，关于某次遇见，恰到好处的突发奇想，承载了我日常的可遇而不可求。</p><blockquote><p>我希望自己永远记得:<br>有慧玉，就会有奇迹；<br>慧玉值得世间所有美好；</p><p>我不知道未来究竟会如何，我只知道，不管我选择那一条路，都会遇见无限可能。<br>我从未如此自信过，自信地站在了这个时刻的人生巅峰。<br>我知道未来依旧会有艰难险阻，但我已经有足够的勇气去相信，挑战和机遇并存。</p></blockquote><blockquote><p>今天在电闪雷鸣中玩命一样地疯跑了5圈，依靠心肺炸裂的感觉回归淡定<br>狂奔的感觉注定不会很舒服，但突破极限后的感觉让一切都值得<br>我不知道昨天的自己究竟付出了多少，才换来了今天的无限可能<br>我不知道明天的自己是否记得远去的曾经，相信自己就是无限可能<br>在我心底，人生就像一场800米，不论长路漫漫有多煎熬，不管冲刺的刹那有多惨烈，我永远无法拒绝心跳加速的快感</p></blockquote><blockquote><p>有那么一段时间，天堂和地狱的差别，仅需要一封新消息提醒。<br>茫茫人海里，有多人在负重前行，谁又能理解谁的无奈和愁容？</p></blockquote><blockquote><p>每个人要走的路，都是不一样的，所有人的明天，都充满未知，也无所参照，所以，知道自己到底想要什么，是一件很重要的事情。</p></blockquote><blockquote><p>不要把未来寄希望于某个人，或者把某个追求具象到某个人，除非，那个人是你自己。<br>与其把赌注下在别人身上，不如自己掌控主动。</p></blockquote><blockquote><p>做自己的国王，懂得独立，拥有自由，是一件很了不起的事情。<br>也许艰难些，但不要对自己丧失信心。<br>也许，有一天，我会一无所有，只剩下内心的火热来驱赶平凡。<br>哪怕你只剩美好的追求，相对正确的坚持，我想，都是一件值得骄傲的事情。</p></blockquote><blockquote><p>好论文需要细细品，如此才能品出好味道。</p></blockquote><blockquote><p>勇敢，聚焦；由简入繁，not由繁化简<br>我不再好奇为什么Pro们能按时昨晚当天的工作，因为那不过是些“文书”的工作，而且我也可以做到。<br>效率和能力，以及对计划的把控，都要不断在战场中得到锻炼。<br>所有的挑战，只会让一个人更强大；逃避和拖延，才会打垮一个人。张开怀抱，你会收获更多的人生体验；立即开始，你会拥有更多自信，从容和力量。<br>小时候读过的一篇文章如是说：<br>我曾经因为有几个大学生登山迷途丧生，而访问某位登山专家。其中一个问题是：”如果我们在半山腰，突然遇到大雨，应该怎么办？”<br>登山专家说：”你应该向山顶走。”<br>“为什么不往山下跑？山顶风雨不是更大吗？”我怀疑地问。<br>“往山顶走，固然风雨可能更大，却不足以威胁你的生命。至于向山下跑，看来风雨小些，似乎比较安全，但却可能遇到暴发的山洪而被活活淹死。”登山专家严肃地说：”对于风雨，逃避它，你只有被卷入洪流；迎向它，你却能获得生存！”<br>It’s totally true, 迎向风雨，获得生存。</p></blockquote><blockquote><p>当时光成为雕刻机，对钻石来说，是一件幸福的事情。<br>时间，充满神奇和魔力，<br>它既可以让病树化为朽木，也可以让新芽长成参天大树。<br>它既彰显公允，也充满残酷，是强压之下的抛光机，普通日子里的美工笔，也是，一不留神，无法掌控的杀猪刀。</p></blockquote><blockquote><p>我在恍如夏日的冬阳里瞥见了冬初写给自己的一句话：日日是好日。它出自文偃禅师，是沥川口中的台词，也是树木希林主演的茶道电影。这，是它的来由。它之所以跃然我的纸上，是因为我在那个时段里，连每一口呼吸，都充满压力。<br>如今想一想远去的昨天，不禁恍然大悟，是呀，一切都会过去的。痛苦不会很长久，幸福会很短暂，就连严冬都来去匆匆。<br>不管外界如何，关键是要有一颗稳定的心；如果蹦极失败，自己就是最好的缓冲。<br>还有，该来的总会来的，这句话是一位朋友告诉我的。所以，不要为了未知的困难，而阻挡了眼前的脚步，你需要勇敢一些，再勇敢一些，做一个勇敢的赛车手。而且，人生的许多赛程，你完全可以依靠自己扭转战局。</p></blockquote><blockquote><p>爱，让一切不同。<br>这是我爱上一个人，爱上一件事之后的切身体验，融化的心，无尽的勇气， 和不知疲倦的狂热，哪怕未来积毁销骨，都无法抹除曾经拥有。</p></blockquote><blockquote><p>洗澡的空隙，厕所中的片刻，这些短暂的放空或逃离，帮我理清了许多事。<br>我不再纠结考试或保送，不在为自己没有坐上第一趟列车而懊悔不已。不管徒步，单车，还是私家车，我们的交通工具是不一样，但沿途看到的风景也截然不同。<br>我不再艳羡一生无忧的人有多幸福，因为形形色色的经历，会让我懂得很多。<br>我做的每一次选择，都是在给自己一个新的机会，去遇见新的成长，拥有新的经历。<br>尽管明天依旧充满未知，但我已经拥有勇气，而且懂得聚焦，这是我此番旅途的意外至宝。</p></blockquote><blockquote><p>善良，仅仅是众多选择中的一种而已。<br>你可以选择做一个好女儿，好妻子，好母亲，也可以选择去做它的反义词。只是一种选择而已。<br>而我选择善良，屏蔽丑恶，大概不是因为一直活在温室里，而是因为我遇见过很多，从此几乎认为，除了能夺走我生命的东西，四舍五入，都可以认为是nice的事情。仅此而已。</p></blockquote><blockquote><p>用心，是开启一切的钥匙。<br>有一个未来目标，总能让我欢欣鼓舞，只知道，确定了就义无反顾/<br>就像飞向火光的灰蛾，甘愿做烈焰的俘虏/<br>在一往情深的日子里，要输就输给追求，要嫁就嫁给幸福。</p></blockquote><blockquote><p>试问岭南应不好。却道。此心安处是吾乡。==我喜欢的，就是最好的。<br>一首《定风波》道出了我这一年最想说的一句话。也许，久经波折的人，才值得:<br>万里归来颜愈少。微笑。笑时犹带岭梅香。</p></blockquote><blockquote><p>人生很重要的是态度，处事的态度，待人的态度。暂且不去想手头的某件事能给自己带来什么，首先要有做下去的意义，要有说服自己的理由。<br>如果能时刻保持清醒，不轻易随波逐流，不强迫自己去适应某些不舒服不正常的环境，自是人生一大幸事。就像慢慢地我们会懂得，一时的新鲜感会随着时间的推移产生厌恶，一时赚足眼球的事物时间久了会褪色。就像你升学，升职，登上了某一个更高的舞台，并不意味着段位越高就越顺利，平台越低就越难生存，事在人为，所有的一切都永远都掌握在自己手中。<br>月有阴晴圆缺，人有旦夕祸福。没有永恒的幸福和痛苦，颠峰和低估。没有必要为了闪耀的星光灼伤眼睛，也没有必要对暗夜中的萤火冷嘲热讽，不以物喜，不以己悲，宁静透彻，方为佳选。</p></blockquote><blockquote><p>是寻一座灯塔聊做依傍，还是相信心中的光芒？<br>是缺少遇见未来的力量，还是不敢坚持孤独的向往？<br>不止为何缘故，想到了Monet，也许是我迷上了其中的色彩，也许是因为Titanic中Rose的一句话，也许是因为说不出来的其他原因。<br>深夜里，想到了蔚蓝星空下的坠树；想到了金色余晖下的森林；想到了穷困的画家和平凡的建筑系学生一起追逐梦想的故事；想到了放手去追逐，去勾勒，去寻找自己真正喜欢的东西；想到了西装，剧本，音乐，绘画的未知殿堂。<br>老师说，人生就像loss寻优，如果不能到达最优，次优也是好的。<br>如果我不能去追逐自己想要的东西，认真做好当下的事，大概也是好的。<br>我也喜欢去相信，越努力，越幸运。</p></blockquote><blockquote><p>每一个当下，都有值得去追逐，去付出的东西。不知道远方在哪里，就先把脚下的路做到最好。<br>斯人若彩虹，遇上方知有。还是那句话，去遇见彩虹一样的灵魂，去成为这样的彩虹，以后要培养这样的彩虹。<br>登山之路千万条，你不是要走最光彩照人的那一条，而是要走最适合自己的那一条。</p></blockquote><blockquote><p>睡前在纠结要不要考博，梦里一个女孩把一片沙漠种成了绿洲，想风一样快乐：“我喜欢把不确定的事，变得确定一些。”我想这大概就是她想和我说的话。</p></blockquote><blockquote><p>如果你对未知未来充满恐惧和担心，可能是你对无法handle当下的影射，与其焦虑并不太可能发生的祸患，倒不如用心走好当先。如果每一个当下你都可以完美应对，未来还有什么好担心的。</p></blockquote><blockquote><p>人生在世，怎么可能不经历几场大的磨难，也许是天灾，也许是人祸，无法避免也好，尽量规避也罢，你都得学会勇敢面对。</p></blockquote><blockquote><p>人生最安全的方式，就是无论何时何地，都能过得精彩绝伦。</p></blockquote><blockquote><p>有很多你没有经历的事，显得很孤独，告诉自己，这是一件很平常的事情。如果有一个人能做到，你一定也可以做到，如果没有人做到，你就去做第一个。</p></blockquote><blockquote><p><strong>自己的路自己走，一个人去面对所有。</strong>所谓钱可以解决的问题，从来都不是问题，所谓朋友的帮助可以度过的难关，从来都不是难关。<br>一个人，走着走着，总要遇见一些困难，足够的金钱和朋友的帮助都无济于事。<br>首先告诉自己，这很正常，是个人总要遇见。<br>然后，自己一个人安安静静，平平稳稳地度过这些磨难。<br>不论遇见什么，都要看到阳光的那一面，用最快的时间找到正确的打开方式。</p></blockquote><blockquote><p><em>不轻易去麻烦别人，是应有的修养之一。*</em>每个人的时间和精力都很宝贵，每个人在自私的同时，要懂得去尊重别人的自由和安排。<br>为人处世最好不要精打细算，考虑着每一份付出都要获得应有的回报，这样自己会心累，甚至会心碎；每个人都不傻，当别人看穿你的“交易”，当是转身离去的时刻。</p></blockquote><blockquote><p><strong>真正的快乐，从来和金钱无关，最宝贵的，从来都是时间。</strong>金钱买不来快乐，也守不住真正的安全感，不要让金钱成为枷锁。拮据的时候就过紧凑的日子，富有的时候去享受可及的奢华，任何时候，都享受和拥抱当下的生活。</p></blockquote><blockquote><p><strong>时间的沉淀可以帮你甄别好坏。</strong>有些灰暗的模糊，不要着急去下定义，有些灿烂的心动，不要着急去奋不顾身，迟钝一些，可以交给时间的东西就不要着急去做决断。</p></blockquote><blockquote><p>*<em>希望你有所爱，有所期待。 *</em></p></blockquote><blockquote><p>*<em>不要认为自己很惨，惊喜，很可能就在下一秒。 *</em></p></blockquote><blockquote><p><strong>就当所有的困难都是为了遇见你，所必须经历的旅程。</strong>我知道你也会迷茫，也会恐惧，也会担心，告诉自己 ，这些都很正常。看一看窗前有故事的栀子花，欣欣然绿意渐浓，似乎没有什么可以阻挡成长和繁盛的脚步。</p></blockquote><blockquote><p>一个人身上珍贵的品质是善良，她可以愚钝，但绝不可以不择手段；<br>一个人身上闪光的特质是追求，目标清晰，爱己所爱，无怨无悔，那最好不过。</p></blockquote><blockquote><p>人与人之间最大的区别，是思想的错位。</p></blockquote><blockquote><p>常说目光要长远，殊不知，每一步的脚踏实地，才是长远之道的根本。</p></blockquote><blockquote><p>“U” are master of your own world. 所以，自己的事情靠自己去主宰，自己的问题靠自己去寻找出路，其他的一切，都只能是辅助。</p></blockquote><blockquote><p>不要妄想去读最好的书，以最快的方式滋养灵魂。接触高质量的东西的确可以在一定程度上减少生命的浪费，却并不意味着生命的成长，因为生命的成长需要你的“独立思考”，所以，食糟粕不一定成侏儒，享精华未必能成巨人。</p></blockquote><blockquote><p>我会懂得这个世界的残酷，也愿意去相信美好依然存在。</p></blockquote><blockquote><p>总是当局者迷，尤其是在黑白交错的灰色地带，没有绝对的对与错，也许应该相信我认为，我认为正确的事情就去追，不管结局如何，起码收获成长。</p><p>任何事情，都可能有“例外”不是吗？也许大千世界平平无奇，偏偏唯独这一件会成为例外。</p></blockquote><blockquote><p>许多的人和事，真正的放下不过是三个字“不在乎”。从此我的脑海里，不再有你的专属领地，从此你的存在对我来说平淡无奇。我不再手足无措，也不会故作冷漠。</p></blockquote><p>我喜欢的词句——每一句话都有故事</p><p>《定风波·南海归赠王定国侍人寓娘》：宋-苏轼<br>常羡人间琢玉郎，天应乞与点酥娘。尽道清歌传皓齿，风起，雪飞炎海变清凉。<br>万里归来颜愈少，微笑，笑时犹带岭梅香。试问岭南应不好，却道：此心安处是吾乡。</p><blockquote><p>那一天读论文，像乌龟一样逐字逐句的耐心品味，那一刻，时间的奢侈以及内心的宁静，赋予了内心强大的安全感。就在那一瞬间，我相信，不会再有外物可以伤害到我，哪怕是在空闲时间里占满我心灵的Scarecrow。</p></blockquote><blockquote><p>那一刻，慢慢懂得，所谓世间宁静，不若心灵的安静，人生在世，总能寻一方心灵的净土，感受时间停滞的永恒。</p></blockquote><blockquote><p>是谁说，世间没有永恒？差点让我相信了这诡异的谎言。</p></blockquote><blockquote><p>“此心安处，便是吾乡”。料想柔奴定是人间佳丽，得遇王巩；人品高洁，方成佳话。再附一曲，聊表思绪：</p></blockquote><p>云伯《颐道堂文集》中，有《与姬人采鸾书》云：“十年以前，慕君之色；十年以后，爱君之才。经岁以来，感君之情；一夕之谈，重君之德。湖山之友，闺房之侣，向惟鸥波，今则停云，不图此生，乃兼二妙。新诗在袖，别泪在襟，言念君子，如何勿思？奉别以来，风餐水宿，舟行六日，始达邗江，小住浃旬，当至袁浦。小诗一律，聊志别怀。花气侵人，不宜起早，月痕感梦，莫爱眠迟。寒暖自珍，起居无恙。临楮怅怅，不知所云。”</p><p>《喜欢一个人》吴桂君<br>伤害你的不是对方的绝情，而是你心存幻想的坚持。<br>爱情永远是两个人的努力，而不是一个人的委屈求全。<br>喜欢一个人，<br>始于颜值，陷于才华，<br>忠于人品，痴于肉体，<br>迷于声音，醉于深情。<br>这样在一起，<br>才是嫁给了爱情，<br>愿你遇到一个成熟的爱人，<br>愿你执迷不悟时少受点伤，<br>愿你幡然醒悟时还赶得上。</p><p>多谢你如此精彩耀眼，做我平淡岁月里星辰</p><p>我们首先要明白这么一件事，在自由恋爱，信息对称的当下，每个人都喜欢择优而从之。你喜欢的人，一般不会只有你才喜欢，而有一个喜欢你的人说明你很幸运。</p><p>《为学》彭端淑<br>天下事有难易乎？为之，则难者亦易矣；不为，则易者亦难矣。人之为学有难易乎？学之，则难者亦易矣；不学，则易者亦难矣。<br>吾资之昏，不逮人也，吾材之庸，不逮人也；旦旦而学之，久而不怠焉，迄乎成，而亦不知其昏与庸也。吾资之聪，倍人也，吾材之敏，倍人也；屏弃而不用，其与昏与庸无以异也。圣人之道，卒于鲁也传之。然则昏庸聪敏之用，岂有常哉？<br>蜀之鄙有二僧：其一贫，其一富。贫者语于富者曰：“吾欲之南海，何如？”富者曰：“子何恃而往？”曰：“吾一瓶一钵足矣。”富者曰：“吾数年来欲买舟而下，犹未能也。子何恃而往！”越明年，贫者自南海还，以告富者，富者有惭色。<br>西蜀之去南海，不知几千里也，僧富者不能至而贫者至焉。人之立志，顾不如蜀鄙之僧哉?是故聪与敏，可恃而不可恃也；自恃其聪与敏而不学者，自败者也。昏与庸，可限而不可限也；不自限其昏与庸，而力学不倦者，自力者也。</p><p>送东阳马生序》明-宋濂<br>余幼时即嗜学。家贫，无从致书以观，每假借于藏书之家，手自笔录，计日以还。天大寒，砚冰坚，手指不可屈伸，弗之怠。录毕，走送之，不敢稍逾约。以是人多以书假余，余因得遍观群书。</p><p>既加冠，益慕圣贤之道，又患无硕师、名人与游，尝趋百里外，从乡之先达执经叩问。先达德隆望尊，门人弟子填其室，未尝稍降辞色。余立侍左右，援疑质理，俯身倾耳以请；或遇其叱咄，色愈恭，礼愈至，不敢出一言以复；俟其欣悦，则又请焉。故余虽愚，卒获有所闻。</p><p>当余之从师也，尝负笈曳屣，行深山巨谷中。穷冬烈风，大雪深数尺，足肤皲裂而不知。至舍，四肢僵劲不能动，媵人持汤沃灌，以衾拥覆，久而乃和。寓逆旅，主人日再食，无鲜肥滋味之享。同舍生皆被绮绣，戴珠缨宝饰之帽，腰白玉之环，左佩刀，右备容臭，煜然若神人。余则缊袍敝衣处其间，略无慕艳意。以中有足乐者，不知口体之奉不若人也。盖余之勤且艰若此。今虽耄老，未有所成，犹幸预君子之列，而承天子之宠光，缀公卿之后，日侍坐备顾问，四海亦谬称其氏名，况才之过于余者乎？</p><p>今诸生学于太学，县官日有廪稍之供，父母岁有裘葛之遗，无冻馁之患矣；坐大厦之下而诵《诗》《书》，无奔走之劳矣；有司业、博士为之师，未有问而不告、求而不得者也；凡所宜有之书，皆集于此，不必若余之手录、假诸人而后见也。其业有不精、德有不成者，非天质之卑，则心不若余之专耳，岂他人之过哉！</p><p>东阳马生君则，在太学已二年，流辈甚称其贤。余朝京师，生以乡人子谒余，撰长书以为贽，辞甚畅达；与之论辩，言和而色夷。自谓少时用心于学甚劳，是可谓善学者矣。其将归见其亲也，余故道为学之难以告之。谓余勉乡人以学者，余之志也；诋我夸际遇之盛而骄乡人者，岂知余者哉！</p><p>战国时期荀子的《劝学》 唐代韩愈的《师说》 清代彭端的《为学》</p><blockquote><p>我本期望此生得以早些遇见最大的伤害，如此余生便不再畏惧，其实，当自己的心底有了真正的勇气，同样可以无惧人任何伤害。</p></blockquote><blockquote><p>我希望可以永远保持住自己的骨气和纯净，因为那是我独树一帜的底气。</p></blockquote><blockquote><p>慢慢地了解自己，学会和自己相处<br>我希望你可以尊重自己内心，做自己喜欢的事情，爱自己喜欢的人。</p></blockquote><blockquote><p>我发现自己成长了许多，我还记得去年的0510，拐弯去二食堂的路上，S问我喜不喜欢现在的方向。我当时坚信任何一个方向往深了走，都会遇见困难；我喜欢日久生情，每一个方向，时间久了，付出的心血多了，我都会喜欢上它。所以，对我来说，没有特殊的喜好，选择哪个一并不重要，我会等，等到某个方向我走来。<br>而现在呢，开始学着照顾自己的特殊偏好，希望未来的自己有足够的能力，去保护和尊重内心最真实的想法，做自己最喜欢的事情，爱自己最喜欢的人。</p></blockquote><blockquote><p>既然喜欢仍在，就好好去爱。<br>不管是为一个人，还是对一件事，只需要这唯一理由，就不要轻言放弃。<br>能如此执着的爱上一个人，这本身恐怕就是件了不起的事。——村上春树</p></blockquote><p>作家柏邦妮曾采访袁泉，并评价说：“她有绝顶的才华，绝顶的敏感，也有绝顶的骄傲，这些东西揉合在一起，她的一生不会是容易的。十年之后，她好像还像我初见她的时候一样，始终没有大红大紫，却是沉金冷玉那样的女演员，她每次出场，哪怕只有一个镜头，却如此隽永难忘。她的柔弱和强韧，就像一株风中的芦苇，随时都会折断，却永远不。她的冷香和热毒，就像一味珍稀的丸药，你可以治好自己，但舍不得。”</p><blockquote><p>认真，永远不失真<br>认真对待有关自己的每个决定，对自己的行为负责，独自承担所有后果。</p></blockquote><p>心将流水同清净，身与浮云无是非</p><p>胜，不妄喜；败，不遑馁；胸有激雷而面如平湖者，可拜上将军。</p><p>世上没有最正确无误的决定，所谓正确的决定，一定是“亦余心之所善兮”的向往。</p><p>扎扎实实地做好当下的事，是治愈迷茫最好的方式</p><p>川北悦吏子曾说，生命不必每时每刻都要冲刺，低沉时就当作放了一个悠长的假期。</p><p>爱上一个人，愿意为其倾尽所有；爱上一件事，愿意为它熬尽所有的心血。这时，这件事不仅仅是职业，更是事业。<br>心灵不在它生活的地方，而在它所爱的地方。</p><blockquote><p>夜空中，总有一颗最亮的星辰，对不同的人而言有着独特的意义。<br>中学时代，我发现了这个秘密，就一颗星，镶在我窗框里，陪我度过每一个孤单而又无助的夜晚。<br>高中时代，搬家到千里之外，书桌前的窗框里，依旧只有一颗星，陪我收藏点点滴滴的努力，度过跌跌撞撞的日子。<br>大学毕业，搬家到马路的那一边，闺房的窗框里，还是那颗最闪亮的星，陪我度过每一段思念和忧伤，迎接意想不到的惊喜。<br>读研时代，校园的上空，就是那颗最亮的星辰，见证我的每一段绝望，无助，痛苦，开心，以及成长，在我肆意奔跑的时候，在我夜归的路上。<br>我知道，夜空中，总有一颗最亮的星辰，对不同的人而言有着独特的意义。对我而言，My Brilliant Start， 它意味着跨越生死界限的陪伴，给我无声的守护和永恒的支持。<br>当我找到我爱的他，我会跑到星空之下告诉你，我相信的美好依然存在。</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> Diary </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Heartbeats </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>让谷歌搜索到自己在GitHub上的博客</title>
      <link href="/2019/11/27/Tools/2019-11-27-%E8%AE%A9%E8%B0%B7%E6%AD%8C%E6%90%9C%E7%B4%A2%E5%88%B0%E8%87%AA%E5%B7%B1%E5%86%8DGitHub%E4%B8%8A%E7%9A%84%E5%8D%9A%E5%AE%A2/"/>
      <url>/2019/11/27/Tools/2019-11-27-%E8%AE%A9%E8%B0%B7%E6%AD%8C%E6%90%9C%E7%B4%A2%E5%88%B0%E8%87%AA%E5%B7%B1%E5%86%8DGitHub%E4%B8%8A%E7%9A%84%E5%8D%9A%E5%AE%A2/</url>
      
        <content type="html"><![CDATA[<p>许久不写博客了，假借CSDN的便捷和随性，其实是因为自己的懒伞，打算从今天起重新拾起自己的私人博客。<br>还是那句话，因为喜欢就好好去爱。不管是为一个人，还是对一件事，很多时候我们贪恋的，都是当初那份恰如其分的感觉，时间走过，当初的那份记忆和感觉，便很难再找回来了。世间有太多的可遇而不可求对吗？下一秒会发生什么，我们都无法预料。<br>期望自己能够早日拥有让自己真心喜欢的博文。</p><h2 id="Step0-why"><a href="#Step0-why" class="headerlink" title="Step0: why ?"></a>Step0: why ?</h2><p>网站在没有提交搜索引擎收录之前，直接搜索你网站的内容是搜不到的，因为搜索引擎不会去检索你的Github仓库。遇到这个问题怎么办呢？本文教你用Hexo在Github Pages上搭建的博客如何能被Google搜索到。</p><h2 id="Step1-验证网站是否被Google收录"><a href="#Step1-验证网站是否被Google收录" class="headerlink" title="Step1: 验证网站是否被Google收录"></a>Step1: 验证网站是否被Google收录</h2><p>打开谷歌搜索，在搜索框中输入</p><p>site:<a href="https://Huiyu-Li.github.io/">https://Huiyu-Li.github.io/</a> ( 注意将Huiyu-Li替换为你自己的)</p><p>如果提示说：找不到和您查询的“site:<a href="https://maxwellyue.github.io”" target="_blank" rel="noopener">https://maxwellyue.github.io”</a> 相符的内容或信息，说明未被收录。</p><p>如果搜索结果的第一条就是你的博客站点，说明已被收录，不用再继续看下面的内容了。</p><h2 id="Step2-提交谷歌搜索"><a href="#Step2-提交谷歌搜索" class="headerlink" title="Step2:提交谷歌搜索"></a>Step2:提交谷歌搜索</h2><p>进入Google Web Master <a href="https://search.google.com/search-console?hl=zh-CN&utm_source=wmx&utm_medium=deprecation-pane&utm_content=home&resource_id=https://huiyu-li.github.io/" target="_blank" rel="noopener">Search Console</a>，登录之后提交你的博客网址：<br><img src="/medias/pic_md/Tools/SubmitGoogle1.png" alt="SubmitGoogle1"><br>这里需要验证网站所有权，网站给我们提示了一个推荐验证方法是通过在你的网站上添加一个它提供的HTML文件来验证，按照步骤依次操作即可。在设置中看到下图所示场景，即为验证成功。<br><img src="/medias/pic_md/Tools/SubmitGoogle2.png" alt="SubmitGoogle2"></p><h2 id="Step3-添加站点地图"><a href="#Step3-添加站点地图" class="headerlink" title="Step3:添加站点地图"></a>Step3:添加站点地图</h2><p>站点地图(Site Map)是用来注明网站结构的文件，我们希望搜索引擎的爬虫了解我们的网站结构，以便于高效爬取内容，快速建立索引。</p><h4 id="安装插件"><a href="#安装插件" class="headerlink" title="安装插件"></a>安装插件</h4><p>首先为Hexo安装hexo-generator-sitemap和hexo-generator-baidu-sitemap插件，在Hexo博客目录下运行：</p><pre class=" language-bash"><code class="language-bash"><span class="token function">npm</span> <span class="token function">install</span> hexo-generator-sitemap --save</code></pre><h4 id="修改配置文件"><a href="#修改配置文件" class="headerlink" title="修改配置文件"></a>修改配置文件</h4><p>打开博客根目录下的_config.yml文件，添加如下字段:</p><pre class=" language-bash"><code class="language-bash">sitemap:    path: sitemap.xml</code></pre><p>然后重新生成博客文件，运行<br>hexo clean<br>hexo g<br>此时应该可以在public目录下看到sitemap.xml文件了。</p><h4 id="添加-测试站点地图"><a href="#添加-测试站点地图" class="headerlink" title="添加/测试站点地图"></a>添加/测试站点地图</h4><p>回到之前提交搜索资源的页面，在左边侧边栏找到“站点地图”,点击“添加/测试站点地图”，将<a href="https://xxxx.github.io/sitemap.xml" target="_blank" rel="noopener">https://xxxx.github.io/sitemap.xml</a> 提交并刷新，就可以看到博客的网站结构了。<br>如果没有什么问题的话，到这里就结束了，但是现在用Google还不能立即查到博客的内容，要等到搜索引擎下一次更新检索时才会有显示。</p><p>参考：<br><a href="https://blog.csdn.net/weixin_44058333/article/details/100165245" target="_blank" rel="noopener">让Google搜索到GitHub上的个人博客</a></p>]]></content>
      
      
      <categories>
          
          <category> Website </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hexo </tag>
            
            <tag> Google </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>传统的图像分割方法</title>
      <link href="/2019/08/05/Knowledge/2019-2-10-%E4%BC%A0%E7%BB%9F%E7%9A%84%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2%E6%96%B9%E6%B3%95/"/>
      <url>/2019/08/05/Knowledge/2019-2-10-%E4%BC%A0%E7%BB%9F%E7%9A%84%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2%E6%96%B9%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<p>图像分割(image segmentation)是指将图像分成若干具有相似性质的区域的过程.传统的图像分割方法主要有:</p><h4 id="1-基于阈值的分割"><a href="#1-基于阈值的分割" class="headerlink" title="1. 基于阈值的分割"></a>1. 基于阈值的分割</h4><p>阈值法的基本思想是基于图像的灰度特征来计算一个或多个灰度阈值，并将图像中每个像素的灰度值与阈值相比较，最后将像素根据比较结果分到合适的类别中。因此，该类方法最为关键的一步就是按照某个准则函数来求解最佳灰度阈值。</p><p>阈值法特别适用于目标和背景占据不同灰度级范围的图。</p><p>图像若只有目标和背景两大类，那么只需要选取一个阈值进行分割，此方法成为单阈值分割；但是如果图像中有多个目标需要提取，单一阈值的分割就会出现作物，在这种情况下就需要选取多个阈值将每个目标分隔开，这种分割方法相应的成为多阈值分割。</p><p>阀值分割方法的优缺点：</p><p>计算简单，效率较高；</p><p>只考虑像素点灰度值本身的特征，一般不考虑空间特征，因此对噪声比较敏感，鲁棒性不高。</p><p>从前面的介绍里我们可以看出，阈值分割方法的最关键就在于阈值的选择。若将智能遗传算法应用在阀值筛选上，选取能最优分割图像的阀值，这可能是基于阀值分割的图像分割法的发展趋势。</p><h5 id="1-1-固定阈值分割"><a href="#1-1-固定阈值分割" class="headerlink" title="1.1 固定阈值分割"></a>1.1 固定阈值分割</h5><p>固定某像素值为分割点。</p><h5 id="1-2-直方图双峰法："><a href="#1-2-直方图双峰法：" class="headerlink" title="1.2 直方图双峰法："></a>1.2 直方图双峰法：</h5><p>Prewitt 等人于六十年代中期提出的直方图双峰法(也称 mode 法) 是典型的全局单阈值分割方法。</p><p>该方法的基本思想是：假设图像中有明显的目标和背景，则其灰度直方图呈双峰分布，当灰度级直方图具有双峰特性时，选取两峰之间的谷对应的灰度级作为阈值。如果背景的灰度值在整个图像中可以合理地看作为恒定，而且所有物体与背景都具有几乎相同的对比度，那么，选择一个正确的、固定的全局阈值会有较好的效果.</p><p>算法实现：找到第一个峰值和第二个峰值,再找到第一和第二个峰值之间的谷值，谷值就是那个阀值。</p><h5 id="1-3-迭代阈值图像分割"><a href="#1-3-迭代阈值图像分割" class="headerlink" title="1.3 迭代阈值图像分割:"></a>1.3 迭代阈值图像分割:</h5><p>Step 1．统计图像灰度直方图,求出图像的最大灰度值和最小灰度值，分别记为$Z_{max}$和$Z_{min}$，令初始阈值$T_0 =  (Z_{min}+Z_{max})/2$；</p><p>Step 2． 根据阈值$T_k$将图象分割为前景和背景，计算小于$T_k$所有灰度的均值$Z_{min}$，和大于$T_k$的所有灰度的均值$Z_{max}$。</p><p>Step 3． 求出新阈值$T_{k+1} = (Z_{min}+Z_{max})/2$；</p><p>Step 4． 若$T_k == T_{k+1}$，则所得即为阈值；否则转2，迭代计算。</p><h5 id="1-4-自适应阈值图像分割"><a href="#1-4-自适应阈值图像分割" class="headerlink" title="1.4 自适应阈值图像分割:"></a>1.4 自适应阈值图像分割:</h5><p>有时候物体和背景的对比度在图像中不是处处一样的，普通阈值分割难以起作用。这时候可以根据图像的局部特征分别采用不同的阈值进行分割。只要我们将图像分为几个区域，分别选择阈值，或动态地根据一定邻域范围选择每点处的阈值，从而进行图像分割。</p><h5 id="1-5-大津法OTSU-最大类间方差法-："><a href="#1-5-大津法OTSU-最大类间方差法-：" class="headerlink" title="1.5 大津法OTSU (最大类间方差法)："></a>1.5 大津法OTSU (最大类间方差法)：</h5><p>日本学者大津在1979年提出的自适应阈值确定方法。 按照图像的灰度特性，将图像分为背景和目标两部分。背景和目标之间的类间方差越大,说明构成图像的2部分的差别越大,当部分目标错分为背景或部分背景错分为目标都会导致2部分差别变小。因此,使类间方差最大的分割意味着错分概率最小。</p><h5 id="1-6-均值法"><a href="#1-6-均值法" class="headerlink" title="1.6 均值法:"></a>1.6 均值法:</h5><p>把图像分成m*n块子图，求取每一块子图的灰度均值, 将所有像素灰度值之和除以像素点的数量，这个均值就是阈值了。这种方法明显不比大津法好，因为均值法和大津法都是从图像整体来考虑阈值的，但是大津法找了一个类间方差最大值来求出最佳阈值的；这两种方法子图越多应该分割效果会好一点，但效率可能会变慢。</p><h5 id="1-7-最佳阈值"><a href="#1-7-最佳阈值" class="headerlink" title="1.7 最佳阈值:"></a>1.7 最佳阈值:</h5><p>阈值选择需要根据具体问题来确定，一般通过实验来确定。如对某类图片，可以分析其直方图等。</p><h4 id="2-基于边缘的分割方法"><a href="#2-基于边缘的分割方法" class="headerlink" title="2. 基于边缘的分割方法"></a>2. 基于边缘的分割方法</h4><p>图像中两个不同区域的边界线上连续的像素点的集合，是图像局部特征不连续性的反映，体现了灰度、颜色、纹理等图像特性的突变。通常情况下，基于边缘的分割方法指的是基于灰度值的边缘检测，它是建立在边缘灰度值会呈现出阶跃型或屋顶型变化这一观测基础上的方法。阶跃型边缘两边像素点的灰度值存在着明显的差异，而屋顶型边缘则位于灰度值上升或下降的转折处。如果将图片从空间域通过傅里叶变换到频率域，边缘就对应着高频部分，这是一种非常简单的边缘检测算法。最简单的边缘检测方法是微分算子法，即使用一阶导数的极值与二阶导数的零点来确定边缘，具体实现时可以使用<strong>图像与模板进行卷积</strong>来完成。</p><p>   边缘检测的优缺点：</p><ol><li>边缘定位准确；</li><li>速度快；</li><li>不能保证边缘的连续性和封闭性；</li><li>在高细节区域存在大量的碎边缘，难以形成一个大区域，但是又不宜将高细节区域分成小碎片；</li></ol><p>由于上述的3,4两个难点，边缘检测只能产生边缘点，而非完整意义上的图像分割过程。这也就是说，在边缘点信息获取到之后还需要后续的处理或者其他相关算法相结合才能完成分割任务。<br>在以后的研究当中，用于提取初始边缘点的自适应阈值选取、用于图像的层次分割的更大区域的选取以及如何确认重要边缘以去除假边缘将变得非常重要。</p><p>边缘角点和兴趣点的检测器有：</p><h5 id="2-1-Canny边缘检测器："><a href="#2-1-Canny边缘检测器：" class="headerlink" title="2.1 Canny边缘检测器："></a>2.1 Canny边缘检测器：</h5><p>将图像P模糊化，然后与一堆正交微分滤波器（如Prewitt滤波器）做<strong>卷积</strong>生成分别包括水平和垂直方向上的导数的图像H和V，对像素(i,j)计算其梯度方向和幅度。若幅度超过临界值就分配一条边缘（此处称为阈值法，但效果不佳）。canny使用非极大抑制的方法对那些不需要响应的进行删除。</p><h5 id="2-2-Harris角点检测器："><a href="#2-2-Harris角点检测器：" class="headerlink" title="2.2 Harris角点检测器："></a>2.2 Harris角点检测器：</h5><p>对每个点周围的水平方向垂直方向的据ubu梯度进行考虑。目的在于找到图像中亮度在两个方向上均发生变化的点，而非一个方向（一条边缘）或者零个方向（平坦区域）。Harris角点检测器是基于对图像结构张量的决策。</p><h5 id="2-3-SIFT检测器"><a href="#2-3-SIFT检测器" class="headerlink" title="2.3 SIFT检测器:"></a>2.3 SIFT检测器:</h5><p>尺度不变特征转换，检测是用来识别兴趣点的第二中方法。不同与Harris角点检测器，SIFT将尺度和方向与结果中的兴趣点相关联。为了找到兴趣点，交替使用多种算子。</p><h5 id="2-4-SURF检测器"><a href="#2-4-SURF检测器" class="headerlink" title="2.4 SURF检测器"></a>2.4 SURF检测器</h5><p>SIFT的改进版。</p><h5 id="基于小波分析和小波变换的图像分割方法"><a href="#基于小波分析和小波变换的图像分割方法" class="headerlink" title="基于小波分析和小波变换的图像分割方法"></a>基于小波分析和小波变换的图像分割方法</h5><p>小波变换是近年来得到的广泛应用的数学工具，也是现在数字图像处理必学部分，它在时间域和频率域上都有量高的局部化性质，能将时域和频域统一于一体来研究信号。而且小波变换具有多尺度特性，能够在不同尺度上对信号进行分析，因此在图像分割方面的得到了应用。</p><p>二进小波变换具有检测二元函数的局部突变能力，因此可作为图像边缘检测工具。图像的边缘出现在图像局部灰度不连续处，对应于二进小波变换的模极大值点。通过检测小波变换模极大值点可以确定图像的边缘小波变换位于各个尺度上，而每个尺度上的小波变换都能提供一定的边缘信息，因此可进行多尺度边缘检测来得到比较理想的图像边缘。</p><p>另外，将小波和其他方法结合起来处理图像分割的问题也得到了广泛研究，比如一种局部自适应阈值法就是将Hilbert图像扫描和小波相结合，从而获得了连续光滑的阈值曲线。</p><h4 id="3-基于区域的分割方法"><a href="#3-基于区域的分割方法" class="headerlink" title="3. 基于区域的分割方法"></a>3. 基于区域的分割方法</h4><p>基于区域的分割方法是以直接寻找区域为基础的分割技术，基于区域提取方法有两种基本形式：一种是区域生长，从单个像素出发，逐步合并以形成所需要的分割区域；另一种是从全局出发，逐步切割至所需的分割区域。</p><h5 id="3-1-种子区域生长法"><a href="#3-1-种子区域生长法" class="headerlink" title="3.1 种子区域生长法"></a>3.1 种子区域生长法</h5><p>区域生长是从一组代表不同生长区域的种子像素开始，接下来将种子像素邻域里符合条件的像素合并到种子像素所代表的生长区域中，并将新添加的像素作为新的种子像素继续合并过程，直到找不到符合条件的新像素为止，该方法的关键是选择合适的初始种子像素以及合理的生长准则。最早的区域生长图像分割方法是由Levine等人提出。</p><p>区域生长算法需要解决的三个问题：</p><ol><li>选择或确定一组能正确代表所需区域的种子像素；</li><li>确定在生长过程中能将相邻像素包括进来的准则；</li><li>指定让生长过程停止的条件或规则。</li></ol><h5 id="3-2-区域分裂合并法"><a href="#3-2-区域分裂合并法" class="headerlink" title="3.2 区域分裂合并法"></a>3.2 区域分裂合并法</h5><p>区域分裂合并法（Gonzalez，2002）可以说是区域生长的逆过程，从整幅图像出发，确定分裂合并的准则，然后将图像任意分成若干互不相交的区域，按准则对这些区域进行分裂合并。</p><p>四叉树分解法就是一种典型的区域分裂合并法，基本算法如下：</p><ol><li>对于任一区域，如果$H(R_i)=FALSE$就将其分裂成不重叠的四等分；</li><li>对相邻的两个区域$R_i$和$R_j$，它们也可以大小不同（即不在同一层），如果条件$H(R_iUR_j)=TURE$满足，就将它们合并起来；</li><li>如果进一步的分裂或合并都不可能，则结束。</li></ol><p>区域分裂合并算法优缺点：</p><ol><li>对复杂图像分割效果好；</li><li>算法复杂，计算量大；</li><li>分裂有可能破怪区域的边界。</li></ol><p>在实际应用当中通常将区域生长算法和区域分裂合并算法结合使用，该类算法对某些复杂物体定义的复杂场景的分割或者对某些自然景物的分割等类似先验知识不足的图像分割效果较为理想。</p><h5 id="3-3-分水岭法"><a href="#3-3-分水岭法" class="headerlink" title="3.3 分水岭法"></a>3.3 分水岭法</h5><p>分水岭分割方法，是一种基于拓扑理论的数学形态学的分割方法，其基本思想是把图像看作是测地学上的拓扑地貌，图像中每一点像素的灰度值表示该点的海拔高度，每一个局部极小值及其影响区域称为集水盆，而集水盆的边界则形成分水岭。分水岭的概念和形成可以通过模拟浸入过程来说明。在每一个局部极小值表面，刺穿一个小孔，然后把整个模型慢慢浸入水中，随着浸入的加深，每一个局部极小值的影响域慢慢向外扩展，在两个集水盆汇合处构筑大坝，即形成分水岭。</p><p>分水岭对微弱边缘具有良好的响应，图像中的噪声、物体表面细微的灰度变化都有可能产生过度分割的现象，但是这也同时能够保证得到封闭连续边缘。同时，分水岭算法得到的封闭的集水盆也为分析图像的区域特征提供了可能。</p><h4 id="4-基于图论的分割方法"><a href="#4-基于图论的分割方法" class="headerlink" title="4. 基于图论的分割方法"></a>4. 基于图论的分割方法</h4><p>此类方法基于图论的方法利用图论领域的理论和方法，将图像映射为带权无向图，把像素视作节点，将图像分割问题看作是图的顶点划分问题，利用最小剪切准则得到图像的最佳分割。此类方法把图像分割问题与图的最小割(MIN-CUT)问题相关联，通常做法是将待分割的图像映射为带权无向图G=(V，E)，其中, $V={ v_{1} ，…， v_{n} }$是顶点的集合，E为边的集合。图中每个节点N∈V对应于图像中的每个像素，每条边∈E连接着一对相邻的像素，边的权值$w( v_{i}，v_{j} )$，其中$ (v_{i}，v_{j})∈E$，表示了相邻像素之间在灰度、颜色或纹理方面的非负相似度。而对图像的一个分割S就是对图的一个剪切，被分割的每个区域C∈S对应着图中的一个子图。</p><p>分割的原则就是使划分后的子图在内部保持相似度最大，而子图之间的相似度保持最小。我们以一个两类的分割为例，把G = (V,E) 分成两个子集A,B,另：$ A\cup B=V$，$A\cap B=\phi$ ，$CUT(A,B) = \Sigma_{\mu\in A，v\in B}w(\mu,v) $, 其中 $w(\mu,v) $, 是权重(weight), 最小割就是让上式的值最小的分割。</p><p>基于图论的代表有NormalizedCut，GraphCut和GrabCut等方法.</p><h5 id="4-1-NormalizedCut"><a href="#4-1-NormalizedCut" class="headerlink" title="4.1 NormalizedCut"></a>4.1 NormalizedCut</h5><p>最小化分割解决了把权重图G分成两部分的任务，但是问题来了，如下图所示，想要的结果是中间实线表示的分割，但是最小化切割却切掉了最边缘的角。这中情况很容易理解，因为最小化切割就是让CUT(A,B)的值最小的情况，而边缘处CUT值确实是最小，因此我们输最小化切割时会有偏差的(bias)。如何去除这种偏差就要引入Normalized Cut算法了。</p><p><img src="/medias/pic_md/Knowledge/ConventioanlSegmentation1.png" alt="Conventioanl Segmentation1"><br>思路很简单，将Cut normalize一下，除以表现顶点集大小的某种量度(如 vol A = 所有A中顶点集的度之和，含义是A中所有点到图中所有点的权重的和)， 也就是$NormalizeCut(A, B) = Cut(A, B) / volA + Cut(A, B) / volB$，通过公式可以很清晰的看到NormalizeCut在追求不同子集间点的权重最小值的同时也追求同一子集间点的权重和最大值。</p><h5 id="4-2-GraphCut-图割"><a href="#4-2-GraphCut-图割" class="headerlink" title="4.2 GraphCut (图割)"></a>4.2 GraphCut (图割)</h5><p>Graph Cuts图是在普通图的基础上多了2个顶点，这2个顶点分别用符号”S”和”T”表示，称为终端顶点。其它所有的顶点都必须和这2个顶点相连形成边集合中的一部分，所以Graph Cuts中有两种顶点，也有两种边，第一种普通顶点对应于图像中的每个像素。每两个邻域顶点的连接就是一条边。这种边也叫n-links。除图像像素外，还有另外两个终端顶点，叫S源点和T汇点。每个普通顶点和这2个终端顶点之间都有连接，组成第二种边,这种边也叫t-links，如下图所示。</p><p><img src="/medias/pic_md/Knowledge/ConventioanlSegmentation2.png" alt="ConventioanlSegmentation2"><br>Graph Cuts中的Cuts是指这样一个边的集合，这些边集合包括了上面定义的2种边，该集合中所有边的断开会导致残留“S”和“T”图的分开，所以就称为“割”。如果一个割，它的边的所有权值之和最小，那么这个就称为最小割，也就是图割的结果。根据网络中最大流和最小割等价的原理，将图像的最优分割问题转化为求解对应图的最小割问题。由Boykov和Kolmogorov发明的max-flow/min-cut算法[1，4]就可以用来获得S-T图的最小割，这个最小割把图的顶点划分为两个不相交的子集S和T，其中s ∈S，t∈ T和S∪T=V 。这两个子集就对应于图像的前景像素集和背景像素集，那就相当于完成了图像分割。</p><h5 id="4-3-GrabCut-分割和抠图"><a href="#4-3-GrabCut-分割和抠图" class="headerlink" title="4.3 GrabCut 分割和抠图"></a>4.3 GrabCut 分割和抠图</h5><p>Graph Cuts 算法利用了图像的像素灰度信息和区域边界信息，代价函数构建在全局最优的框架下，保证了分割效果。但Graph Cuts 是NP 难问题，且分割结果更倾向于具有相同的类内相似度。Rother 等人提出了基于迭代的图割方法，称为Grab Cut 算法。该算法使用高斯混合模型对目标和背景建模，利用了图像的RGB 色彩信息和边界信息，通过少量的用户交互操作得到非常好的分割效果。</p><p>Graph Cuts是Graphcut的改进版，是迭代的GraphCut。改进包括：</p><ol><li>将基于灰度分布的模型替换为高斯混合模型（Gaussian Mixture Model，GMM）以支持彩色图片;</li><li>将能一次性得到结果的算法改成了『强大的』迭代流程；将用户的交互简化到只需要框选前景物体即可。</li></ol><p>与Graph Cut不同处：</p><ol><li>Graph Cut的目标和背景的模型是灰度直方图，Grab Cut取代为RGB三通道的混合高斯模型GMM;</li><li>Graph Cut的能量最小化（分割）是一次达到的，而Grab Cut取代为一个不断进行分割估计和模型参数学习的交互迭代过程;</li><li>Graph Cut需要用户指定目标和背景的一些种子点，但是Grab Cut只需要提供背景区域的像素集就可以了。也就是说你只需要框选目标，那么在方框外的像素全部当成背景，这时候就可以对GMM进行建模和完成良好的分割了。即Grab Cut允许不完全的标注（incomplete labelling）。彩色像素值的稀疏问题比灰度图要严重得多（256 vs 17M），所以，继续使用histogram是不现实的，需要信息压缩得更好一点的模型，作者在这里参考前人，对前景和背景各建了K=5的高斯混合模型。</li><li>GrabCut是按颜色分布和边缘对比度来分割图片的，对一些常见的与此原则相悖的图片，效果确实不好。比如前景人物的帽子、鞋、墨镜，通常颜色跟前景主体有较大区别；再如前景中的孔，有可能由于颜色区分和边缘的对比度不足，导致边缘的惩罚占上风，而没有扣出来背景。所以，GrabCut还是保留了人工修正的操作，定义了两种标记：绝对是背景和可能是前景。对分割错误人工修正后，分割还是可以比较准确的。对自然场景图片的分割，比Bayes matte等方法得到的边缘明显看起来舒服得多。</li></ol><h4 id="5-基于能量泛函的分割方法"><a href="#5-基于能量泛函的分割方法" class="headerlink" title="5. 基于能量泛函的分割方法"></a>5. 基于能量泛函的分割方法</h4><p>该类方法主要指的是活动轮廓模型（active contour model）以及在其基础上发展出来的算法，其基本思想是使用连续曲线来表达目标边缘，并定义一个能量泛函使得其自变量包括边缘曲线，因此分割过程就转变为求解能量泛函的最小值的过程，一般可通过求解函数对应的欧拉(Euler．Lagrange)方程来实现，能量达到最小时的曲线位置就是目标的轮廓所在。</p><p>活动轮廓模型逐渐形成了不同的分类方式，较常见的是根据曲线演化方式的不同，将活动轮廓模型分为基于边界、基于区域和混合型活动轮廓模型。</p><p>按照模型中曲线表达形式的不同，活动轮廓模型可以分为两大类：参数活动轮廓模型（parametric active contour model）和几何活动轮廓模型（geometric active contour model）。</p><h5 id="5-1-参数主动轮廓模型（parametric-active-contour-model）"><a href="#5-1-参数主动轮廓模型（parametric-active-contour-model）" class="headerlink" title="5.1 参数主动轮廓模型（parametric active contour model）:"></a>5.1 参数主动轮廓模型（parametric active contour model）:</h5><p>参数活动轮廓模型基于Lagrange框架，将曲线或曲面的形变以参数化形式表达，最具代表性的是由Kasset a1(1987)所提出的Snake模型。该类模型在早期的生物图像分割领域得到了成功的应用，但其存在着分割结果受初始轮廓的设置影响较大以及难以处理曲线拓扑结构变化等缺点，此外其能量泛函只依赖于曲线参数的选择，与物体的几何形状无关，这也限制了其进一步的应用。</p><p>Snake模型: Michael Kass et al. Snakes: Active contour models. International Journal of Computer Vision, pages 321-331, 1987.</p><p>Snake定义为能量极小化的样条曲线，它在来自曲线自身的内力和来自图像数据的外力的共同作用下移动到感兴趣的边缘，内力用于约束曲线形状，而外力则引导曲线到特征此边缘。参数主动轮廓模型的特点是将初始曲线置于目标区域附近，无需人为设定曲线的的演化是收缩或膨胀，其优点是能够与模型直接进行交互，且模型表达紧凑，实现速度快；其缺点是难以处理模型拓扑结构的变化。比如曲线的合并或分裂等。而使用水平集（level set）的几何活动轮廓方法恰好解决了这一问题。</p><p>基本Snakes模型的能量函数由三项组成，弹性能量和弯曲能量合称内部能量（内部力），用于控制轮廓线的弹性形变，起到保持轮廓连续性和平滑性的作用。而第三项代表外部能量，也被称为图像能量，表示变形曲线与图像局部特征吻合的情况。内部能量仅仅跟snake的形状有关，而跟图像数据无关。而外部能量仅仅跟图像数据有关。在某一点的α和β的值决定曲线可以在这一点伸展和弯曲的程度。最终对图像的分割转化为求解能量函数Etotal(v)极小化（最小化轮廓的能量）。在能量函数极小化过程中，弹性能量迅速把轮廓线压缩成一个光滑的圆，弯曲能量驱使轮廓线成为光滑曲线或直线，而图像力则使轮廓线向图像的高梯度位置靠拢。基本Snakes模型就是在这3个力的联合作用下工作的。</p><p>snake相对于经典的特征提取方法有以下优点：</p><ol><li>通过正确设置和项前系数，可交互方式控制snake;</li><li>容易操控，因为图像力是以直观的方式表现;</li><li>在寻找最小能量状态的时候它们是自主的和自适应的;</li><li>可以通过在图像能量函数中加入高斯平滑而对图像尺度敏感;</li><li>可以用于跟踪时间或者空间维度上的动态目标。</li></ol><p>snake的缺点：</p><ol><li>初始位置不同使得结果不同;</li><li>经常陷入局部最小状态，这也许可以通过使用模拟退火技术来克服，代价就是计算时间增加;</li><li>在最小化整个轮廓路径上的能量过程中经常忽略微小特征;</li><li>精度由能量最小化技术中使用的收敛标准控制；更高的精度要求更严格的收敛标准，因此需要更长的计算时间。</li></ol><h5 id="5-2-ASM-Active-Shape-Model-主动形状模型"><a href="#5-2-ASM-Active-Shape-Model-主动形状模型" class="headerlink" title="5.2 ASM(Active Shape Model)主动形状模型"></a>5.2 ASM(Active Shape Model)主动形状模型</h5><p>Cootes T F, Taylor C J. Active Shape Models — ‘Smart Snakes’[M]// BMVC92. Springer London, 1992:266–275.</p><p>ASM（主动形状模型）是建立在PDM（点分布模型）的基础上，通过训练图像样本获取训练图像样本的特征点分布的统计信息，并且获取特征点允许存在的变化方向，实现在目标图像上寻找对应的特征点的位置。训练样本需要手动的标记所有的特征点的位置，记录特征点的坐标，并且计算每一个特征点对应的局部灰度模型作为局部特征点调整用的特征向量。在将训练好的模型放在目标图像上，寻找每一个特征点的下一个位置的时候，采用局部灰度模型寻找在当前特征点指定方向上局部灰度模型马氏距离最小的特征点作为当前特征点即将移动到的位置，称为suggested point, 找到所有的suggested points就可以获得一个搜索的suggested shape, 然后将当前的模型通过调整参数使得当前的模型最可能相似的调整到suggest shape，重复迭代直到实现收敛。</p><h5 id="5-3-AAM-Active-Appearance-Models"><a href="#5-3-AAM-Active-Appearance-Models" class="headerlink" title="5.3 AAM(Active Appearance Models)"></a>5.3 AAM(Active Appearance Models)</h5><p>Cootes T F, Edwards G J, Taylor C J. Active Appearance Models[C]// European Conference on Computer Vision. Springer Berlin Heidelberg, 1998:484-498.</p><p>ASM是基于统计形状模型的基础上进行的，而AAM则是在ASM的基础上，进一步对纹理（将人脸图像变形到平均形状而得到的形状无关图像）进行统计建模，并将形状和纹理两个统计模型进一步融合为表观模型。</p><p>AAM模型相对于ASM模型的改进为：</p><ol><li>使用两个统计模型融合 取代 ASM的灰度模型。</li><li>主要对特征点的特征描述子进行了改进，增加了描述子的复杂度和鲁棒性</li></ol><h5 id="5-4-CLM-Constrained-local-model-有约束的局部模型"><a href="#5-4-CLM-Constrained-local-model-有约束的局部模型" class="headerlink" title="5.4 CLM(Constrained local model)有约束的局部模型"></a>5.4 CLM(Constrained local model)有约束的局部模型</h5><p>CLM是有约束的局部模型，ASM也属于CLM的一种。CLM通过初始化平均脸的位置，然后让每个平均脸上的特征点在其邻域位置上进行搜索匹配来完成人脸点检测。整个过程分两个阶段：模型构建阶段和点拟合阶段。模型构建阶段又可以细分两个不同模型的构建：</p><p>形状模型构建: 对人脸模型形状进行建模，说白了就是一个ASM的点分布函数（PDM），它描述了形状变化遵循的准则.</p><p>Patch模型构建: 对每个特征点周围邻域进行建模，也就说建立一个特征点匹配准则，怎么判断特征点是最佳匹配.</p><h5 id="5-5-GAC-geometric-active-contour-model-几何主动轮廓模型"><a href="#5-5-GAC-geometric-active-contour-model-几何主动轮廓模型" class="headerlink" title="5.5 GAC(geometric active contour model)几何主动轮廓模型:"></a>5.5 GAC(geometric active contour model)几何主动轮廓模型:</h5><p>S.Osher,J.A.Sethian,Fronts propagating with curvature dependent speed:algorithms basedon Hamilton-Jacobi formulations.Journal of Computational Physics,1988,79:12—49</p><p>几何活动轮廓模型的曲线运动过程是基于曲线的几何度量参数而非曲线的表达参数，因此可以较好地处理拓扑结构的变化，并可以解决参数活动轮廓模型难以解决的问题。而水平集（Level Set）方法（Osher，1988）的引入，则极大地推动了几何活动轮廓模型的发展，因此几何活动轮廓模型一般也可被称为水平集方法。</p><p>几何活动轮廓模型是以曲线演化理论和水平集方法为理论基础,继参数活动轮廓模型后形变模型的又一发展,是图像分割和边界提取的重要工具之一。相对于参数活动轮廓模型,几何活动轮廓模型具有很多优点,如可以处理曲线的拓扑变化、对初始位置不敏感、具有稳定的数值解等.</p><p>几何活动轮廓模型又可分为基于边界的活动轮廓模型、基于区域的活动轮廓模型。基于边界的活动轮廓模型主要依赖图像的边缘信息控制曲线的运动速度。在图像边缘强度较弱或是远离边缘的地方，轮廓曲线运动速度较大，而在图像边缘强度较强的地方，轮廓曲线运动速度较小甚至停止，使得最终的轮廓曲线运动到边缘位置.</p><h4 id="6-基于遗传算法的图像分割"><a href="#6-基于遗传算法的图像分割" class="headerlink" title="6. 基于遗传算法的图像分割"></a>6. 基于遗传算法的图像分割</h4><p>遗传算法（Genetic Algorithms，简称GA）是1973年由美国教授Holland提出的，是一种借鉴生物界自然选择和自然遗传机制的随机化搜索算法。是仿生学在数学领域的应用。其基本思想是，模拟由一些基因串控制的生物群体的进化过程，把该过程的原理应用到搜索算法中，以提高寻优的速度和质量。此算法的搜索过程不直接作用在变量上，而是在参数集进行了编码的个体，这使得遗传算法可直接对结构对象（图像）进行操作。整个搜索过程是从一组解迭代到另一组解，采用同时处理群体中多个个体的方法，降低了陷入局部最优解的可能性，并易于并行化。搜索过程采用概率的变迁规则来指导搜索方向，而不采用确定性搜索规则，而且对搜索空间没有任何特殊要求（如连通性、凸性等），只利用适应性信息，不需要导数等其他辅助信息，适应范围广。</p><p>遗传算法擅长于全局搜索，但局部搜索能力不足，所以常把遗传算法和其他算法结合起来应用。将遗传算法运用到图像处理主要是考虑到遗传算法具有与问题领域无关且快速随机的搜索能力。其搜索从群体出发，具有潜在的并行性，可以进行多个个体的同时比较，能有效的加快图像处理的速度。但是遗传算法也有其缺点：搜索所使用的评价函数的设计、初始种群的选择有一定的依赖性等。要是能够结合一些启发算法进行改进且遗传算法的并行机制的潜力得到充分的利用，这是当前遗传算法在图像处理中的一个研究热点。</p><h4 id="7-基于聚类的图像分割"><a href="#7-基于聚类的图像分割" class="headerlink" title="7. 基于聚类的图像分割"></a>7. 基于聚类的图像分割</h4><p>基于聚类的图像分割将图像分割问题转化为模式识别的聚类分析。  K均值、模糊C-均值算法(Fuzzy C-Means,简称FCM)是最常用的聚类算法。</p><p>K均值算法先选K个初始类均值，然后将每个像素归入均值离它最近的类并计算新的类均值。迭代执行前面的步骤直到新旧类均值之差小于某一阈值。</p><p>模糊C均值算法是在模糊数学基础上对K均值算法的推广，是通过最优化一个模糊目标函数实现聚类，它不像K均值聚类那样认为每个点只能属于某一类，而是赋予每个点一个对各类的隶属度，用隶属度更好地描述边缘像素亦此亦彼的特点，适合处理事物内在的不确定性。利用模糊C均值(FCM)非监督模糊聚类标定的特点进行图像分割，可以减少人为的干预，且较适合图像中存在不确定性和模糊性的特点。</p><p>聚类方法应注意几个问题：</p><ol><li>聚类的类数如何确定。</li><li>怎样确定聚类的有效性准则。</li><li>聚类中心的位置和特性事先不清楚时，如何设置初始值。</li><li>运算的开销。</li></ol><p>并且FCM算法对初始参数极为敏感，有时需要人工干预参数的初始化以接近全局最优解，提高分割速度。另外，传统FCM算法没有考虑空间信息，对噪声和灰度不均匀敏感。</p><p>参考:<br><a href="https://zhuanlan.zhihu.com/p/30732385" target="_blank" rel="noopener">图像分割 传统方法 整理</a><br><a href="https://www.jishuwen.com/d/2Ddq" target="_blank" rel="noopener">最全综述 | 图像分割算法</a><br><a href="https://juejin.im/entry/5bea5e7ef265da61553a5e28" target="_blank" rel="noopener">图像分割技术介绍</a><br>《计算机视觉：模型、学习和推理》</p>]]></content>
      
      
      <categories>
          
          <category> Knowledge </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Segmentation </tag>
            
            <tag> Conventional method </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CRF as RNN</title>
      <link href="/2019/07/15/Knowledge/2020-2-10-CRF%20as%20RNN/"/>
      <url>/2019/07/15/Knowledge/2020-2-10-CRF%20as%20RNN/</url>
      
        <content type="html"><![CDATA[<p><strong>条件随机场(CRF )的概率函数</strong>为$P(X = x|I) = \frac{1}{z}\exp ( - E(x|I))$</p><p><strong>CRF 的能量函数为</strong>$E(x) = \sum\limits_i{\psi_u}({x_i})+\sum\limits_{i&lt;j}{\psi_p}({x_i},{x_j})$<br>其中第一项为数据项，第二项为平滑项，其定义为若干个高斯函数的和，如下公式所示。数据项约束每个像素尽可能分类正确，平滑项约束相邻像素之间的灰度值差异要尽可能小。<br>$$<br>{\psi_p}({x_i},{x_j}) = u({x_i},{x_j})\sum\limits_{m=1}^M{\omega ^{(m)}}{k^{(m)}}({f_i},{f_j}))<br>$$<br><img src="/medias/pic_md/Knowledge/CRFasRNN3.png" alt><br><img src="/medias/pic_md/Knowledge/CRFasRNN2.jpg" alt=" A mean-field iteration as a CNN"><br>参考：<br><a href="https://blog.csdn.net/taigw/article/details/51794283" target="_blank" rel="noopener">CRF as RNN的原理及Caffe实现</a><br><a href="https://www.cv-foundation.org/openaccess/content_iccv_2015/html/Zheng_Conditional_Random_Fields_ICCV_2015_paper.html" target="_blank" rel="noopener">2015_Conditional Random Fields as Recurrent Neural Networks_ICCV</a></p>]]></content>
      
      
      <categories>
          
          <category> Knowledge </category>
          
      </categories>
      
      
        <tags>
            
            <tag> CRF </tag>
            
            <tag> RNN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>水平集-Level Set</title>
      <link href="/2019/07/10/Knowledge/2019-7-10-%E6%B0%B4%E5%B9%B3%E9%9B%86Level%20Set/"/>
      <url>/2019/07/10/Knowledge/2019-7-10-%E6%B0%B4%E5%B9%B3%E9%9B%86Level%20Set/</url>
      
        <content type="html"><![CDATA[<h2 id="水平集（Level-Set）"><a href="#水平集（Level-Set）" class="headerlink" title="水平集（Level Set）"></a>水平集（Level Set）</h2><h4 id="曲线演化的直观解释"><a href="#曲线演化的直观解释" class="headerlink" title="曲线演化的直观解释"></a>曲线演化的直观解释</h4><p>   假设$X(t)$表示一平面曲线，$T$表示切线，$N$表示法线。因为切向量$T$和法向量$N$互相垂直，所以平面上任何曲线都可以用曲线上任何一点的$T$和$N$的线性组合来表示：<br>$$\frac{\partial X}{\partial t} = \alpha T + \beta N$$<br>   如果只考虑几何形状的变化，则曲线变化只跟法线方向的变化有关系:<br>$$\frac{\partial X}{\partial t} = \beta N$$<br>   假设我们有一个3D surface和一个2D plane，如下所示，<br><img src="/medias/pic_md/Knowledge/LevelSet1.png" alt="Level Set1"><br>   我们通过surface与plane的关系来描述curve（surface与plane的交线），通过调整surface来实现curve的变化，这就是level set的基本思想。<br><img src="/medias/pic_md/Knowledge/LevelSet2.png" alt="Level Set2"></p><h4 id="Level-set-的数学定义及运动表示"><a href="#Level-set-的数学定义及运动表示" class="headerlink" title="Level set 的数学定义及运动表示"></a>Level set 的数学定义及运动表示</h4><p>   假设隐函数$φ(X(t),t)$表示一个高维空间的surface，程其在低维空间上的接触面为$φ(X(t),t)=0$<br>   我们按如下方式跟踪surface和curve的演化过程。<br>$$\frac{\partial X}{\partial t} = V(k)N$$<br>其中,$V(k)$称为<strong>速度方程</strong>，$k$表示曲率，$t$表示时间，$N =  - \frac{\nabla \phi }{\left| {\nabla \phi } \right|}$表示surface的内法线。<br>然后对surface对t进行级联求导，<br>$$\phi (X(t),t) = 0$$<br>$$\Rightarrow \nabla \phi {X_t} + {\phi _t} = 0$$<br>$$\Rightarrow {\phi _t} = V(k)\left| {\nabla \phi } \right|$$<br>   由此可知，给定初始的surface$ φ(X(t),t)$以及速度方程$V(k)$，便可以得到任意时刻的surface $φ$。</p><h4 id="Level-Set的数值解法"><a href="#Level-Set的数值解法" class="headerlink" title="Level Set的数值解法"></a>Level Set的数值解法</h4><p>   熟知机器学习同学可能会发现，surface φ的演化过程酷似神经网络中的参数利用梯度下降更新过程。<br>$$\frac{\partial \phi }{\partial t} = \frac{\phi ^{t + \Delta t} - {\phi ^t}}{\Delta t}$$<br>$$\Rightarrow {\phi ^{t + \Delta t}} = {\phi ^t} + {\phi _t}\Delta t = {\phi ^t} + V(k)\left| {\nabla \phi } \right|\Delta t$$</p><p>参考：<br>[1] <a href="https://wiseodd.github.io/techblog/2016/11/05/levelset-method/" target="_blank" rel="noopener">“Level Set Method Part I: Introduction”</a></p>]]></content>
      
      
      <categories>
          
          <category> Knowledge </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Level Set </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>毕业季有感</title>
      <link href="/2019/06/26/Diary/2019-06-26-%E6%AF%95%E4%B8%9A%E5%AD%A3%E6%9C%89%E6%84%9F/"/>
      <url>/2019/06/26/Diary/2019-06-26-%E6%AF%95%E4%B8%9A%E5%AD%A3%E6%9C%89%E6%84%9F/</url>
      
        <content type="html"><![CDATA[<p>第一次遇到BIT的毕业季，颇为壮观，因此感觉异常新鲜和惊奇，毕业竟然可以和入学有着相似的热闹，就像洗礼和葬礼有着相似的仪式感，虽然昭示着截然不同的起点和终点；还有生命中段的婚礼，人生遇到新鲜事，总是可喜可贺的事情。</p><blockquote><p>成长，总在不停地和过去告别，同时去迎接新鲜的未来。</p></blockquote><p> 若想对过去少些遗憾和抱歉，对未来多些确定和希冀。最重要的是确保每时每刻都有一个充实当下。</p><blockquote><p>你认真走过的一点一滴，会让你和不得不离开的昨天有一个体面的告别，和随即到来的明天有个无所畏惧的拥抱。<br>无论何时，无论何地，不遗余力，用心努力。</p></blockquote><p> 要知道，已经走过的，无法回头，对错与否，如果不能化作前进的动力，一切毫无意义。<br> 当下和未来的每一段时光，也会在转瞬即逝中成为过去，所以，在没有机会后悔的世界里，聪明的你要学会和过去和解，选择最聪明的做法：走好当下。</p><ul><li>我希望，在见证别人走进又离开的过程中，你可以懂得珍惜当下的意义。</li><li>我希望，明年或者后年，你可以用自己的努力，去换来一个值得拥抱的未来，让过去的一段时光收获应有的结局。</li><li>我知道，不管未来面对怎样的Next Step，你仍会紧张，仍会忐忑不安，但是没关系的，一个值得拥抱的未来会给你微笑告别过去的勇气，会给你一个崭新的未来。</li></ul>]]></content>
      
      
      <categories>
          
          <category> Diary </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Heartbeats </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
